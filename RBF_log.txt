2020-02-27 09:38:52,072 - RBF - INFO - now initialize the net with para:
2020-02-27 09:38:52,072 - RBF - INFO - clip
2020-02-27 09:38:52,073 - RBF - INFO - 0.05
2020-02-27 09:38:52,073 - RBF - INFO - -----------------------------
2020-02-27 09:38:52,073 - RBF - INFO - CKPT
2020-02-27 09:38:52,073 - RBF - INFO - ckpt
2020-02-27 09:38:52,073 - RBF - INFO - -----------------------------
2020-02-27 09:38:52,073 - RBF - INFO - BATCHSIZE
2020-02-27 09:38:52,073 - RBF - INFO - 1000
2020-02-27 09:38:52,073 - RBF - INFO - -----------------------------
2020-02-27 09:38:52,073 - RBF - INFO - MAX_ITER
2020-02-27 09:38:52,073 - RBF - INFO - 5000
2020-02-27 09:38:52,073 - RBF - INFO - -----------------------------
2020-02-27 09:38:52,073 - RBF - INFO - STEP_EACH_ITER
2020-02-27 09:38:52,074 - RBF - INFO - 500
2020-02-27 09:38:52,074 - RBF - INFO - -----------------------------
2020-02-27 09:38:52,074 - RBF - INFO - STEP_SHOW
2020-02-27 09:38:52,074 - RBF - INFO - 200
2020-02-27 09:38:52,074 - RBF - INFO - -----------------------------
2020-02-27 09:38:52,074 - RBF - INFO - EPOCH_SAVE
2020-02-27 09:38:52,074 - RBF - INFO - 2
2020-02-27 09:38:52,074 - RBF - INFO - -----------------------------
2020-02-27 09:38:52,074 - RBF - INFO - LEARNING_RATE
2020-02-27 09:38:52,074 - RBF - INFO - 5e-05
2020-02-27 09:38:52,074 - RBF - INFO - -----------------------------
2020-02-27 09:38:52,074 - RBF - INFO - bound_weight
2020-02-27 09:38:52,074 - RBF - INFO - 1000
2020-02-27 09:38:52,074 - RBF - INFO - -----------------------------
2020-02-27 09:38:52,074 - RBF - INFO - decay
2020-02-27 09:38:52,074 - RBF - INFO - False
2020-02-27 09:38:52,074 - RBF - INFO - -----------------------------
2020-02-27 09:38:52,074 - RBF - INFO - test_line
2020-02-27 09:38:52,074 - RBF - INFO - False
2020-02-27 09:38:52,075 - RBF - INFO - -----------------------------
2020-02-27 09:38:52,075 - RBF - INFO - is_plot
2020-02-27 09:38:52,075 - RBF - INFO - True
2020-02-27 09:38:52,075 - RBF - INFO - -----------------------------
2020-02-27 09:38:52,114 - RBF - INFO - openning sess
2020-02-27 09:38:54,899 - RBF - INFO - building net
2020-02-27 09:39:02,272 - RBF - INFO - building opt
2020-02-27 09:39:02,743 - RBF - INFO - init from ckpt 
2020-02-27 09:39:02,743 - RBF - INFO - net initializing
2020-02-27 09:39:02,743 - RBF - INFO - train epoch 0 of total 5000 epoches
2020-02-27 09:39:08,122 - RBF - ERROR - loss 3.16284429025453, in epoch 0, in step 199, in global step 2490200, learning rate is 5e-05, taks 5.378999948501587 seconds
2020-02-27 09:39:09,733 - RBF - ERROR - loss 3.1628373924518307, in epoch 0, in step 399, in global step 2490400, learning rate is 5e-05, taks 1.6110000610351562 seconds
2020-02-27 09:39:10,518 - RBF - INFO - train epoch 1 of total 5000 epoches
2020-02-27 09:39:12,080 - RBF - ERROR - loss 3.162832472192311, in epoch 1, in step 199, in global step 2490700, learning rate is 5e-05, taks 2.3469998836517334 seconds
2020-02-27 09:39:13,630 - RBF - ERROR - loss 3.1629453255000217, in epoch 1, in step 399, in global step 2490900, learning rate is 5e-05, taks 1.5500001907348633 seconds
2020-02-27 09:39:34,769 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 1. learning_rate is 5e-05, loss is 3.1623615144523987
2020-02-27 09:39:34,771 - RBF - INFO - train epoch 2 of total 5000 epoches
2020-02-27 09:39:36,144 - RBF - ERROR - loss 3.1628445270345233, in epoch 2, in step 199, in global step 2491200, learning rate is 5e-05, taks 22.513999938964844 seconds
2020-02-27 16:37:06,367 - RBF - INFO - now initialize the net with para:
2020-02-27 16:37:06,388 - RBF - INFO - clip
2020-02-27 16:37:06,388 - RBF - INFO - 0.05
2020-02-27 16:37:06,388 - RBF - INFO - -----------------------------
2020-02-27 16:37:06,388 - RBF - INFO - CKPT
2020-02-27 16:37:06,388 - RBF - INFO - ckpt
2020-02-27 16:37:06,389 - RBF - INFO - -----------------------------
2020-02-27 16:37:06,389 - RBF - INFO - BATCHSIZE
2020-02-27 16:37:06,389 - RBF - INFO - 1000
2020-02-27 16:37:06,389 - RBF - INFO - -----------------------------
2020-02-27 16:37:06,389 - RBF - INFO - MAX_ITER
2020-02-27 16:37:06,389 - RBF - INFO - 5000
2020-02-27 16:37:06,389 - RBF - INFO - -----------------------------
2020-02-27 16:37:06,389 - RBF - INFO - STEP_EACH_ITER
2020-02-27 16:37:06,389 - RBF - INFO - 500
2020-02-27 16:37:06,390 - RBF - INFO - -----------------------------
2020-02-27 16:37:06,390 - RBF - INFO - STEP_SHOW
2020-02-27 16:37:06,390 - RBF - INFO - 200
2020-02-27 16:37:06,390 - RBF - INFO - -----------------------------
2020-02-27 16:37:06,390 - RBF - INFO - EPOCH_SAVE
2020-02-27 16:37:06,390 - RBF - INFO - 2
2020-02-27 16:37:06,390 - RBF - INFO - -----------------------------
2020-02-27 16:37:06,390 - RBF - INFO - LEARNING_RATE
2020-02-27 16:37:06,390 - RBF - INFO - 0.0001
2020-02-27 16:37:06,391 - RBF - INFO - -----------------------------
2020-02-27 16:37:06,391 - RBF - INFO - bound_weight
2020-02-27 16:37:06,391 - RBF - INFO - 10000
2020-02-27 16:37:06,391 - RBF - INFO - -----------------------------
2020-02-27 16:37:06,391 - RBF - INFO - decay
2020-02-27 16:37:06,391 - RBF - INFO - False
2020-02-27 16:37:06,391 - RBF - INFO - -----------------------------
2020-02-27 16:37:06,391 - RBF - INFO - test_line
2020-02-27 16:37:06,391 - RBF - INFO - False
2020-02-27 16:37:06,391 - RBF - INFO - -----------------------------
2020-02-27 16:37:06,391 - RBF - INFO - is_plot
2020-02-27 16:37:06,392 - RBF - INFO - True
2020-02-27 16:37:06,392 - RBF - INFO - -----------------------------
2020-02-27 16:37:06,432 - RBF - INFO - openning sess
2020-02-27 16:37:09,216 - RBF - INFO - building net
2020-02-27 16:37:15,902 - RBF - INFO - building opt
2020-02-27 16:37:16,332 - RBF - INFO - init from ckpt 
2020-02-27 16:37:16,332 - RBF - INFO - net initializing
2020-02-27 16:37:16,333 - RBF - INFO - train epoch 0 of total 5000 epoches
2020-02-27 16:37:20,336 - RBF - ERROR - loss 3.1628688852769034, in epoch 0, in step 199, in global step 1900200, learning rate is 0.0001, taks 4.003000020980835 seconds
2020-02-27 16:37:21,173 - RBF - ERROR - loss 3.162795064709707, in epoch 0, in step 399, in global step 1900400, learning rate is 0.0001, taks 0.8370001316070557 seconds
2020-02-27 16:37:21,541 - RBF - INFO - train epoch 1 of total 5000 epoches
2020-02-27 16:37:22,294 - RBF - ERROR - loss 3.1628602257776857, in epoch 1, in step 199, in global step 1900700, learning rate is 0.0001, taks 1.121000051498413 seconds
2020-02-27 16:37:23,043 - RBF - ERROR - loss 3.162784742948204, in epoch 1, in step 399, in global step 1900900, learning rate is 0.0001, taks 0.748999834060669 seconds
2020-02-27 16:37:32,302 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 1. learning_rate is 0.0001, loss is 3.1632426506286664
2020-02-27 16:37:32,304 - RBF - INFO - train epoch 2 of total 5000 epoches
2020-02-27 16:51:47,918 - RBF - INFO - now initialize the net with para:
2020-02-27 16:51:47,935 - RBF - INFO - clip
2020-02-27 16:51:47,935 - RBF - INFO - 0.05
2020-02-27 16:51:47,935 - RBF - INFO - -----------------------------
2020-02-27 16:51:47,935 - RBF - INFO - CKPT
2020-02-27 16:51:47,935 - RBF - INFO - ckpt
2020-02-27 16:51:47,935 - RBF - INFO - -----------------------------
2020-02-27 16:51:47,935 - RBF - INFO - BATCHSIZE
2020-02-27 16:51:47,935 - RBF - INFO - 1000
2020-02-27 16:51:47,935 - RBF - INFO - -----------------------------
2020-02-27 16:51:47,936 - RBF - INFO - MAX_ITER
2020-02-27 16:51:47,936 - RBF - INFO - 5000
2020-02-27 16:51:47,936 - RBF - INFO - -----------------------------
2020-02-27 16:51:47,936 - RBF - INFO - STEP_EACH_ITER
2020-02-27 16:51:47,936 - RBF - INFO - 500
2020-02-27 16:51:47,936 - RBF - INFO - -----------------------------
2020-02-27 16:51:47,936 - RBF - INFO - STEP_SHOW
2020-02-27 16:51:47,936 - RBF - INFO - 200
2020-02-27 16:51:47,936 - RBF - INFO - -----------------------------
2020-02-27 16:51:47,936 - RBF - INFO - EPOCH_SAVE
2020-02-27 16:51:47,936 - RBF - INFO - 10
2020-02-27 16:51:47,936 - RBF - INFO - -----------------------------
2020-02-27 16:51:47,936 - RBF - INFO - LEARNING_RATE
2020-02-27 16:51:47,936 - RBF - INFO - 5e-05
2020-02-27 16:51:47,936 - RBF - INFO - -----------------------------
2020-02-27 16:51:47,937 - RBF - INFO - bound_weight
2020-02-27 16:51:47,937 - RBF - INFO - 10000
2020-02-27 16:51:47,937 - RBF - INFO - -----------------------------
2020-02-27 16:51:47,937 - RBF - INFO - decay
2020-02-27 16:51:47,937 - RBF - INFO - False
2020-02-27 16:51:47,937 - RBF - INFO - -----------------------------
2020-02-27 16:51:47,937 - RBF - INFO - test_line
2020-02-27 16:51:47,937 - RBF - INFO - False
2020-02-27 16:51:47,937 - RBF - INFO - -----------------------------
2020-02-27 16:51:47,937 - RBF - INFO - is_plot
2020-02-27 16:51:47,937 - RBF - INFO - True
2020-02-27 16:51:47,937 - RBF - INFO - -----------------------------
2020-02-27 16:51:47,956 - RBF - INFO - openning sess
2020-02-27 16:51:49,297 - RBF - INFO - building net
2020-02-27 16:51:53,347 - RBF - INFO - building opt
2020-02-27 16:51:54,026 - RBF - INFO - init from ckpt 
2020-02-27 16:51:54,027 - RBF - INFO - net initializing
2020-02-27 16:51:54,028 - RBF - INFO - train epoch 0 of total 5000 epoches
2020-02-27 16:52:00,205 - RBF - ERROR - loss 3.1629972651445413, in epoch 0, in step 199, in global step 1901200, learning rate is 5e-05, taks 6.177000284194946 seconds
2020-02-27 16:52:01,267 - RBF - ERROR - loss 3.1630531629765164, in epoch 0, in step 399, in global step 1901400, learning rate is 5e-05, taks 1.061999797821045 seconds
2020-02-27 16:52:01,761 - RBF - INFO - train epoch 1 of total 5000 epoches
2020-02-27 16:52:02,561 - RBF - ERROR - loss 3.1627335552831766, in epoch 1, in step 199, in global step 1901700, learning rate is 5e-05, taks 1.2940001487731934 seconds
2020-02-27 16:52:03,282 - RBF - ERROR - loss 3.16271972732503, in epoch 1, in step 399, in global step 1901900, learning rate is 5e-05, taks 0.7209999561309814 seconds
2020-02-27 16:52:03,650 - RBF - INFO - train epoch 2 of total 5000 epoches
2020-02-27 16:52:04,419 - RBF - ERROR - loss 3.1627375387895635, in epoch 2, in step 199, in global step 1902200, learning rate is 5e-05, taks 1.1370000839233398 seconds
2020-02-27 16:52:05,227 - RBF - ERROR - loss 3.1628088481733565, in epoch 2, in step 399, in global step 1902400, learning rate is 5e-05, taks 0.806999921798706 seconds
2020-02-27 16:52:05,608 - RBF - INFO - train epoch 3 of total 5000 epoches
2020-02-27 16:52:06,398 - RBF - ERROR - loss 3.1631826503928506, in epoch 3, in step 199, in global step 1902700, learning rate is 5e-05, taks 1.1710000038146973 seconds
2020-02-27 16:52:07,170 - RBF - ERROR - loss 3.1627220004862706, in epoch 3, in step 399, in global step 1902900, learning rate is 5e-05, taks 0.7720000743865967 seconds
2020-02-27 16:52:07,547 - RBF - INFO - train epoch 4 of total 5000 epoches
2020-02-27 16:52:08,283 - RBF - ERROR - loss 3.1629081420478586, in epoch 4, in step 199, in global step 1903200, learning rate is 5e-05, taks 1.1129999160766602 seconds
2020-02-27 16:52:09,024 - RBF - ERROR - loss 3.1628581845879125, in epoch 4, in step 399, in global step 1903400, learning rate is 5e-05, taks 0.7409999370574951 seconds
2020-02-27 16:52:09,411 - RBF - INFO - train epoch 5 of total 5000 epoches
2020-02-27 16:52:10,198 - RBF - ERROR - loss 3.1629663262733865, in epoch 5, in step 199, in global step 1903700, learning rate is 5e-05, taks 1.1740002632141113 seconds
2020-02-27 16:52:10,977 - RBF - ERROR - loss 3.16316136934071, in epoch 5, in step 399, in global step 1903900, learning rate is 5e-05, taks 0.7790000438690186 seconds
2020-02-27 16:52:11,372 - RBF - INFO - train epoch 6 of total 5000 epoches
2020-02-27 16:52:12,162 - RBF - ERROR - loss 3.1633470110354507, in epoch 6, in step 199, in global step 1904200, learning rate is 5e-05, taks 1.184999942779541 seconds
2020-02-27 16:52:12,958 - RBF - ERROR - loss 3.162915956406672, in epoch 6, in step 399, in global step 1904400, learning rate is 5e-05, taks 0.7960000038146973 seconds
2020-02-27 16:52:13,339 - RBF - INFO - train epoch 7 of total 5000 epoches
2020-02-27 16:52:14,115 - RBF - ERROR - loss 3.1628450131265806, in epoch 7, in step 199, in global step 1904700, learning rate is 5e-05, taks 1.1569998264312744 seconds
2020-02-27 16:52:14,902 - RBF - ERROR - loss 3.163141960601279, in epoch 7, in step 399, in global step 1904900, learning rate is 5e-05, taks 0.7870001792907715 seconds
2020-02-27 16:52:15,296 - RBF - INFO - train epoch 8 of total 5000 epoches
2020-02-27 16:52:16,054 - RBF - ERROR - loss 3.1633686962858305, in epoch 8, in step 199, in global step 1905200, learning rate is 5e-05, taks 1.1519999504089355 seconds
2020-02-27 16:52:16,776 - RBF - ERROR - loss 3.162745678007297, in epoch 8, in step 399, in global step 1905400, learning rate is 5e-05, taks 0.7219998836517334 seconds
2020-02-27 16:52:17,155 - RBF - INFO - train epoch 9 of total 5000 epoches
2020-02-27 16:52:17,933 - RBF - ERROR - loss 3.1627460362961197, in epoch 9, in step 199, in global step 1905700, learning rate is 5e-05, taks 1.1570000648498535 seconds
2020-02-27 16:52:18,693 - RBF - ERROR - loss 3.162909257299602, in epoch 9, in step 399, in global step 1905900, learning rate is 5e-05, taks 0.7599999904632568 seconds
2020-02-27 16:52:40,512 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 9. learning_rate is 5e-05, loss is 3.1630567443229176
2020-02-27 16:52:40,512 - RBF - INFO - train epoch 10 of total 5000 epoches
2020-02-27 16:52:41,229 - RBF - ERROR - loss 3.1629368307896386, in epoch 10, in step 199, in global step 1906200, learning rate is 5e-05, taks 22.53600001335144 seconds
2020-02-27 16:52:41,959 - RBF - ERROR - loss 3.1630177437015408, in epoch 10, in step 399, in global step 1906400, learning rate is 5e-05, taks 0.7300000190734863 seconds
2020-02-27 16:52:42,316 - RBF - INFO - train epoch 11 of total 5000 epoches
2020-02-27 16:52:43,041 - RBF - ERROR - loss 3.1629509014090904, in epoch 11, in step 199, in global step 1906700, learning rate is 5e-05, taks 1.0820000171661377 seconds
2020-02-27 16:52:43,746 - RBF - ERROR - loss 3.162898182543292, in epoch 11, in step 399, in global step 1906900, learning rate is 5e-05, taks 0.7049999237060547 seconds
2020-02-27 16:52:44,092 - RBF - INFO - train epoch 12 of total 5000 epoches
2020-02-27 16:52:44,793 - RBF - ERROR - loss 3.1627815321378114, in epoch 12, in step 199, in global step 1907200, learning rate is 5e-05, taks 1.0460000038146973 seconds
2020-02-27 16:52:45,483 - RBF - ERROR - loss 3.1629203509464077, in epoch 12, in step 399, in global step 1907400, learning rate is 5e-05, taks 0.6899998188018799 seconds
2020-02-27 16:52:45,844 - RBF - INFO - train epoch 13 of total 5000 epoches
2020-02-27 16:52:46,537 - RBF - ERROR - loss 3.1630218762398497, in epoch 13, in step 199, in global step 1907700, learning rate is 5e-05, taks 1.0540001392364502 seconds
2020-02-27 16:52:47,245 - RBF - ERROR - loss 3.16316996280848, in epoch 13, in step 399, in global step 1907900, learning rate is 5e-05, taks 0.7079999446868896 seconds
2020-02-27 16:52:47,588 - RBF - INFO - train epoch 14 of total 5000 epoches
2020-02-27 16:52:48,297 - RBF - ERROR - loss 3.1631183376611247, in epoch 14, in step 199, in global step 1908200, learning rate is 5e-05, taks 1.0520000457763672 seconds
2020-02-27 16:52:49,013 - RBF - ERROR - loss 3.1628973457716336, in epoch 14, in step 399, in global step 1908400, learning rate is 5e-05, taks 0.7160000801086426 seconds
2020-02-27 16:52:49,374 - RBF - INFO - train epoch 15 of total 5000 epoches
2020-02-27 16:52:50,084 - RBF - ERROR - loss 3.1630192924459304, in epoch 15, in step 199, in global step 1908700, learning rate is 5e-05, taks 1.0709996223449707 seconds
2020-02-27 16:52:50,816 - RBF - ERROR - loss 3.1630744110651006, in epoch 15, in step 399, in global step 1908900, learning rate is 5e-05, taks 0.7310001850128174 seconds
2020-02-27 16:52:51,177 - RBF - INFO - train epoch 16 of total 5000 epoches
2020-02-27 16:52:51,897 - RBF - ERROR - loss 3.1629193352544602, in epoch 16, in step 199, in global step 1909200, learning rate is 5e-05, taks 1.0810000896453857 seconds
2020-02-27 16:52:52,606 - RBF - ERROR - loss 3.1627679020372508, in epoch 16, in step 399, in global step 1909400, learning rate is 5e-05, taks 0.7090001106262207 seconds
2020-02-27 16:52:52,955 - RBF - INFO - train epoch 17 of total 5000 epoches
2020-02-27 16:52:53,649 - RBF - ERROR - loss 3.1627586538974004, in epoch 17, in step 199, in global step 1909700, learning rate is 5e-05, taks 1.0429999828338623 seconds
2020-02-27 16:52:54,340 - RBF - ERROR - loss 3.162886537468578, in epoch 17, in step 399, in global step 1909900, learning rate is 5e-05, taks 0.6899998188018799 seconds
2020-02-27 16:52:54,697 - RBF - INFO - train epoch 18 of total 5000 epoches
2020-02-27 16:52:55,396 - RBF - ERROR - loss 3.16294812894596, in epoch 18, in step 199, in global step 1910200, learning rate is 5e-05, taks 1.055999994277954 seconds
2020-02-27 16:52:56,116 - RBF - ERROR - loss 3.1631224746482998, in epoch 18, in step 399, in global step 1910400, learning rate is 5e-05, taks 0.7189998626708984 seconds
2020-02-27 16:52:56,476 - RBF - INFO - train epoch 19 of total 5000 epoches
2020-02-27 16:52:57,202 - RBF - ERROR - loss 3.163074820684437, in epoch 19, in step 199, in global step 1910700, learning rate is 5e-05, taks 1.0860002040863037 seconds
2020-02-27 16:52:57,925 - RBF - ERROR - loss 3.1632372543886156, in epoch 19, in step 399, in global step 1910900, learning rate is 5e-05, taks 0.7230000495910645 seconds
2020-02-27 16:53:06,920 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 19. learning_rate is 5e-05, loss is 3.1632719656510835
2020-02-27 16:53:06,921 - RBF - INFO - train epoch 20 of total 5000 epoches
2020-02-27 16:53:07,704 - RBF - ERROR - loss 3.163155074633853, in epoch 20, in step 199, in global step 1911200, learning rate is 5e-05, taks 9.77899980545044 seconds
2020-02-27 16:53:08,436 - RBF - ERROR - loss 3.1632383515125553, in epoch 20, in step 399, in global step 1911400, learning rate is 5e-05, taks 0.7319998741149902 seconds
2020-02-27 16:53:08,806 - RBF - INFO - train epoch 21 of total 5000 epoches
2020-02-27 23:17:51,002 - RBF - INFO - now initialize the net with para:
2020-02-27 23:17:51,004 - RBF - INFO - clip
2020-02-27 23:17:51,004 - RBF - INFO - 0.05
2020-02-27 23:17:51,004 - RBF - INFO - -----------------------------
2020-02-27 23:17:51,004 - RBF - INFO - CKPT
2020-02-27 23:17:51,004 - RBF - INFO - ckpt
2020-02-27 23:17:51,004 - RBF - INFO - -----------------------------
2020-02-27 23:17:51,004 - RBF - INFO - BATCHSIZE
2020-02-27 23:17:51,004 - RBF - INFO - 1000
2020-02-27 23:17:51,004 - RBF - INFO - -----------------------------
2020-02-27 23:17:51,004 - RBF - INFO - MAX_ITER
2020-02-27 23:17:51,004 - RBF - INFO - 5000
2020-02-27 23:17:51,005 - RBF - INFO - -----------------------------
2020-02-27 23:17:51,005 - RBF - INFO - STEP_EACH_ITER
2020-02-27 23:17:51,005 - RBF - INFO - 500
2020-02-27 23:17:51,005 - RBF - INFO - -----------------------------
2020-02-27 23:17:51,005 - RBF - INFO - STEP_SHOW
2020-02-27 23:17:51,005 - RBF - INFO - 200
2020-02-27 23:17:51,005 - RBF - INFO - -----------------------------
2020-02-27 23:17:51,005 - RBF - INFO - EPOCH_SAVE
2020-02-27 23:17:51,005 - RBF - INFO - 2
2020-02-27 23:17:51,005 - RBF - INFO - -----------------------------
2020-02-27 23:17:51,005 - RBF - INFO - LEARNING_RATE
2020-02-27 23:17:51,005 - RBF - INFO - 0.0005
2020-02-27 23:17:51,005 - RBF - INFO - -----------------------------
2020-02-27 23:17:51,005 - RBF - INFO - bound_weight
2020-02-27 23:17:51,005 - RBF - INFO - 10000
2020-02-27 23:17:51,005 - RBF - INFO - -----------------------------
2020-02-27 23:17:51,006 - RBF - INFO - step_unbound
2020-02-27 23:17:51,006 - RBF - INFO - 5
2020-02-27 23:17:51,006 - RBF - INFO - -----------------------------
2020-02-27 23:17:51,006 - RBF - INFO - decay
2020-02-27 23:17:51,006 - RBF - INFO - False
2020-02-27 23:17:51,006 - RBF - INFO - -----------------------------
2020-02-27 23:17:51,006 - RBF - INFO - test_line
2020-02-27 23:17:51,006 - RBF - INFO - False
2020-02-27 23:17:51,006 - RBF - INFO - -----------------------------
2020-02-27 23:17:51,006 - RBF - INFO - is_plot
2020-02-27 23:17:51,006 - RBF - INFO - True
2020-02-27 23:17:51,006 - RBF - INFO - -----------------------------
2020-02-27 23:17:51,031 - RBF - INFO - openning sess
2020-02-27 23:17:52,485 - RBF - INFO - building net
2020-02-27 23:17:54,805 - RBF - INFO - building opt
2020-02-27 23:17:55,052 - RBF - INFO - net initializing
2020-02-27 23:17:55,053 - RBF - INFO - train epoch 0 of total 5000 epoches
2020-02-27 23:17:56,505 - RBF - ERROR - loss 8123.308584152341, in epoch 0, in step 199, in global step 200, learning rate is 0.0005, taks 1.4530000686645508 seconds
2020-02-27 23:17:57,032 - RBF - ERROR - loss 6667.402708602402, in epoch 0, in step 399, in global step 400, learning rate is 0.0005, taks 0.5260000228881836 seconds
2020-02-27 23:17:57,272 - RBF - INFO - train epoch 1 of total 5000 epoches
2020-02-27 23:17:57,781 - RBF - ERROR - loss 5418.464386826891, in epoch 1, in step 199, in global step 700, learning rate is 0.0005, taks 0.749000072479248 seconds
2020-02-27 23:17:58,287 - RBF - ERROR - loss 4679.605383661024, in epoch 1, in step 399, in global step 900, learning rate is 0.0005, taks 0.5059998035430908 seconds
2020-02-27 23:18:01,387 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 1. learning_rate is 0.0005, loss is 4.845849083048275
2020-02-27 23:18:01,388 - RBF - INFO - train epoch 2 of total 5000 epoches
2020-02-27 23:18:01,884 - RBF - ERROR - loss 3688.895237627533, in epoch 2, in step 199, in global step 1200, learning rate is 0.0005, taks 3.5970001220703125 seconds
2020-02-27 23:18:02,358 - RBF - ERROR - loss 3098.496671005201, in epoch 2, in step 399, in global step 1400, learning rate is 0.0005, taks 0.47299981117248535 seconds
2020-02-27 23:18:02,598 - RBF - INFO - train epoch 3 of total 5000 epoches
2020-02-27 23:18:03,077 - RBF - ERROR - loss 2311.3939446720606, in epoch 3, in step 199, in global step 1700, learning rate is 0.0005, taks 0.7190001010894775 seconds
2020-02-27 23:18:03,564 - RBF - ERROR - loss 1852.3924260488793, in epoch 3, in step 399, in global step 1900, learning rate is 0.0005, taks 0.4869997501373291 seconds
2020-02-27 23:18:05,829 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 3. learning_rate is 0.0005, loss is 5.961455361290579
2020-02-27 23:18:05,829 - RBF - INFO - train epoch 4 of total 5000 epoches
2020-02-27 23:18:06,349 - RBF - ERROR - loss 1260.4785803186403, in epoch 4, in step 199, in global step 2200, learning rate is 0.0005, taks 2.7850003242492676 seconds
2020-02-27 23:18:06,852 - RBF - ERROR - loss 929.7998197988481, in epoch 4, in step 399, in global step 2400, learning rate is 0.0005, taks 0.5029997825622559 seconds
2020-02-27 23:18:07,084 - RBF - INFO - train epoch 5 of total 5000 epoches
2020-02-27 23:18:07,561 - RBF - ERROR - loss 528.667539414309, in epoch 5, in step 199, in global step 2700, learning rate is 0.0005, taks 0.7090001106262207 seconds
2020-02-27 23:18:08,034 - RBF - ERROR - loss 324.51237962683456, in epoch 5, in step 399, in global step 2900, learning rate is 0.0005, taks 0.4720001220703125 seconds
2020-02-27 23:18:09,939 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 5. learning_rate is 0.0005, loss is 7.98810040190954
2020-02-27 23:18:09,939 - RBF - INFO - train epoch 6 of total 5000 epoches
2020-02-27 23:18:10,448 - RBF - ERROR - loss 113.30493874006368, in epoch 6, in step 199, in global step 3200, learning rate is 0.0005, taks 2.4129998683929443 seconds
2020-02-27 23:18:10,934 - RBF - ERROR - loss 36.028298530789, in epoch 6, in step 399, in global step 3400, learning rate is 0.0005, taks 0.48600006103515625 seconds
2020-02-27 23:18:11,173 - RBF - INFO - train epoch 7 of total 5000 epoches
2020-02-27 23:18:11,656 - RBF - ERROR - loss 9.630750498416228, in epoch 7, in step 199, in global step 3700, learning rate is 0.0005, taks 0.7219998836517334 seconds
2020-02-27 23:18:12,138 - RBF - ERROR - loss 9.566352528154725, in epoch 7, in step 399, in global step 3900, learning rate is 0.0005, taks 0.48200011253356934 seconds
2020-02-27 23:18:14,147 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 7. learning_rate is 0.0005, loss is 9.541689591571872
2020-02-27 23:18:14,148 - RBF - INFO - train epoch 8 of total 5000 epoches
2020-02-27 23:18:14,662 - RBF - ERROR - loss 9.51526707105604, in epoch 8, in step 199, in global step 4200, learning rate is 0.0005, taks 2.5230002403259277 seconds
2020-02-27 23:18:15,149 - RBF - ERROR - loss 9.48522286226386, in epoch 8, in step 399, in global step 4400, learning rate is 0.0005, taks 0.4869999885559082 seconds
2020-02-27 23:18:15,391 - RBF - INFO - train epoch 9 of total 5000 epoches
2020-02-27 23:18:15,871 - RBF - ERROR - loss 9.467983126534508, in epoch 9, in step 199, in global step 4700, learning rate is 0.0005, taks 0.7219998836517334 seconds
2020-02-27 23:18:16,366 - RBF - ERROR - loss 9.458201515840567, in epoch 9, in step 399, in global step 4900, learning rate is 0.0005, taks 0.49500012397766113 seconds
2020-02-27 23:18:26,176 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 9. learning_rate is 0.0005, loss is 9.445820674308273
2020-02-27 23:18:26,176 - RBF - INFO - train epoch 10 of total 5000 epoches
2020-02-27 23:18:26,727 - RBF - ERROR - loss 9.445606642910768, in epoch 10, in step 199, in global step 5200, learning rate is 0.0005, taks 10.360999822616577 seconds
2020-02-27 23:18:27,303 - RBF - ERROR - loss 9.43997332909474, in epoch 10, in step 399, in global step 5400, learning rate is 0.0005, taks 0.5759999752044678 seconds
2020-02-27 23:18:27,579 - RBF - INFO - train epoch 11 of total 5000 epoches
2020-02-27 23:18:28,129 - RBF - ERROR - loss 9.429537165877678, in epoch 11, in step 199, in global step 5700, learning rate is 0.0005, taks 0.8260002136230469 seconds
2020-02-27 23:18:28,664 - RBF - ERROR - loss 9.446134499032544, in epoch 11, in step 399, in global step 5900, learning rate is 0.0005, taks 0.5349998474121094 seconds
2020-02-27 23:18:30,987 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 11. learning_rate is 0.0005, loss is 9.424392092515046
2020-02-27 23:18:30,987 - RBF - INFO - train epoch 12 of total 5000 epoches
2020-02-27 23:18:31,532 - RBF - ERROR - loss 9.422739040853099, in epoch 12, in step 199, in global step 6200, learning rate is 0.0005, taks 2.868000030517578 seconds
2020-02-27 23:18:32,083 - RBF - ERROR - loss 9.423755432910102, in epoch 12, in step 399, in global step 6400, learning rate is 0.0005, taks 0.5509998798370361 seconds
2020-02-27 23:18:32,357 - RBF - INFO - train epoch 13 of total 5000 epoches
2020-02-27 23:18:32,895 - RBF - ERROR - loss 9.416866858527355, in epoch 13, in step 199, in global step 6700, learning rate is 0.0005, taks 0.812000036239624 seconds
2020-02-27 23:18:33,436 - RBF - ERROR - loss 9.434686039475359, in epoch 13, in step 399, in global step 6900, learning rate is 0.0005, taks 0.5409998893737793 seconds
2020-02-27 23:18:36,655 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 13. learning_rate is 0.0005, loss is 9.40914931367666
2020-02-27 23:18:36,656 - RBF - INFO - train epoch 14 of total 5000 epoches
2020-02-27 23:18:37,287 - RBF - ERROR - loss 9.418993292816719, in epoch 14, in step 199, in global step 7200, learning rate is 0.0005, taks 3.8510000705718994 seconds
2020-02-27 23:18:37,845 - RBF - ERROR - loss 9.415793009538183, in epoch 14, in step 399, in global step 7400, learning rate is 0.0005, taks 0.5580003261566162 seconds
2020-02-27 23:18:38,109 - RBF - INFO - train epoch 15 of total 5000 epoches
2020-02-27 23:18:38,634 - RBF - ERROR - loss 9.454288278954191, in epoch 15, in step 199, in global step 7700, learning rate is 0.0005, taks 0.7889997959136963 seconds
2020-02-27 23:18:39,162 - RBF - ERROR - loss 9.41833875872454, in epoch 15, in step 399, in global step 7900, learning rate is 0.0005, taks 0.5270001888275146 seconds
2020-02-27 23:18:42,284 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 15. learning_rate is 0.0005, loss is 9.419824347973746
2020-02-27 23:18:42,284 - RBF - INFO - train epoch 16 of total 5000 epoches
2020-02-27 23:18:42,848 - RBF - ERROR - loss 9.41291757251554, in epoch 16, in step 199, in global step 8200, learning rate is 0.0005, taks 3.685999870300293 seconds
2020-02-27 23:18:43,378 - RBF - ERROR - loss 9.41263731062739, in epoch 16, in step 399, in global step 8400, learning rate is 0.0005, taks 0.5289998054504395 seconds
2020-02-27 23:18:43,659 - RBF - INFO - train epoch 17 of total 5000 epoches
2020-02-27 23:18:44,230 - RBF - ERROR - loss 9.413123899392161, in epoch 17, in step 199, in global step 8700, learning rate is 0.0005, taks 0.8519999980926514 seconds
2020-02-27 23:18:44,758 - RBF - ERROR - loss 9.415065822238464, in epoch 17, in step 399, in global step 8900, learning rate is 0.0005, taks 0.5280001163482666 seconds
2020-02-27 23:18:48,263 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 17. learning_rate is 0.0005, loss is 9.416443883470317
2020-02-27 23:18:48,263 - RBF - INFO - train epoch 18 of total 5000 epoches
2020-02-27 23:18:48,815 - RBF - ERROR - loss 9.415676513187137, in epoch 18, in step 199, in global step 9200, learning rate is 0.0005, taks 4.056999921798706 seconds
2020-02-27 23:18:49,312 - RBF - ERROR - loss 9.41516504186934, in epoch 18, in step 399, in global step 9400, learning rate is 0.0005, taks 0.49699997901916504 seconds
2020-02-27 23:18:49,554 - RBF - INFO - train epoch 19 of total 5000 epoches
2020-02-27 23:18:50,026 - RBF - ERROR - loss 9.414902672182256, in epoch 19, in step 199, in global step 9700, learning rate is 0.0005, taks 0.7139999866485596 seconds
2020-02-27 23:18:50,515 - RBF - ERROR - loss 9.412058952062518, in epoch 19, in step 399, in global step 9900, learning rate is 0.0005, taks 0.4890000820159912 seconds
2020-02-27 23:19:01,338 - RBF - INFO - now initialize the net with para:
2020-02-27 23:19:01,338 - RBF - INFO - clip
2020-02-27 23:19:01,338 - RBF - INFO - 0.05
2020-02-27 23:19:01,338 - RBF - INFO - -----------------------------
2020-02-27 23:19:01,338 - RBF - INFO - CKPT
2020-02-27 23:19:01,338 - RBF - INFO - ckpt
2020-02-27 23:19:01,338 - RBF - INFO - -----------------------------
2020-02-27 23:19:01,338 - RBF - INFO - BATCHSIZE
2020-02-27 23:19:01,338 - RBF - INFO - 1000
2020-02-27 23:19:01,338 - RBF - INFO - -----------------------------
2020-02-27 23:19:01,338 - RBF - INFO - MAX_ITER
2020-02-27 23:19:01,338 - RBF - INFO - 5000
2020-02-27 23:19:01,338 - RBF - INFO - -----------------------------
2020-02-27 23:19:01,339 - RBF - INFO - STEP_EACH_ITER
2020-02-27 23:19:01,339 - RBF - INFO - 500
2020-02-27 23:19:01,339 - RBF - INFO - -----------------------------
2020-02-27 23:19:01,339 - RBF - INFO - STEP_SHOW
2020-02-27 23:19:01,339 - RBF - INFO - 200
2020-02-27 23:19:01,339 - RBF - INFO - -----------------------------
2020-02-27 23:19:01,339 - RBF - INFO - EPOCH_SAVE
2020-02-27 23:19:01,339 - RBF - INFO - 2
2020-02-27 23:19:01,339 - RBF - INFO - -----------------------------
2020-02-27 23:19:01,339 - RBF - INFO - LEARNING_RATE
2020-02-27 23:19:01,339 - RBF - INFO - 0.0005
2020-02-27 23:19:01,339 - RBF - INFO - -----------------------------
2020-02-27 23:19:01,339 - RBF - INFO - bound_weight
2020-02-27 23:19:01,339 - RBF - INFO - 1
2020-02-27 23:19:01,339 - RBF - INFO - -----------------------------
2020-02-27 23:19:01,339 - RBF - INFO - step_unbound
2020-02-27 23:19:01,340 - RBF - INFO - 5
2020-02-27 23:19:01,340 - RBF - INFO - -----------------------------
2020-02-27 23:19:01,340 - RBF - INFO - decay
2020-02-27 23:19:01,340 - RBF - INFO - False
2020-02-27 23:19:01,340 - RBF - INFO - -----------------------------
2020-02-27 23:19:01,340 - RBF - INFO - test_line
2020-02-27 23:19:01,340 - RBF - INFO - False
2020-02-27 23:19:01,340 - RBF - INFO - -----------------------------
2020-02-27 23:19:01,340 - RBF - INFO - is_plot
2020-02-27 23:19:01,340 - RBF - INFO - True
2020-02-27 23:19:01,340 - RBF - INFO - -----------------------------
2020-02-27 23:19:01,359 - RBF - INFO - openning sess
2020-02-27 23:19:03,139 - RBF - INFO - building net
2020-02-27 23:19:06,475 - RBF - INFO - building opt
2020-02-27 23:19:06,773 - RBF - INFO - init from ckpt 
2020-02-27 23:19:06,773 - RBF - INFO - net initializing
2020-02-27 23:19:06,774 - RBF - INFO - train epoch 0 of total 5000 epoches
2020-02-27 23:19:08,772 - RBF - ERROR - loss 8.301615428137428, in epoch 0, in step 199, in global step 10200, learning rate is 0.0005, taks 1.997999906539917 seconds
2020-02-27 23:19:09,381 - RBF - ERROR - loss 7.291698850070211, in epoch 0, in step 399, in global step 10400, learning rate is 0.0005, taks 0.6079998016357422 seconds
2020-02-27 23:19:09,675 - RBF - INFO - train epoch 1 of total 5000 epoches
2020-02-27 23:19:10,282 - RBF - ERROR - loss 6.086268321900008, in epoch 1, in step 199, in global step 10700, learning rate is 0.0005, taks 0.9010000228881836 seconds
2020-02-27 23:19:10,895 - RBF - ERROR - loss 5.4799853959836575, in epoch 1, in step 399, in global step 10900, learning rate is 0.0005, taks 0.6129999160766602 seconds
2020-02-27 23:19:14,014 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 1. learning_rate is 0.0005, loss is 5.008605909236824
2020-02-27 23:19:14,014 - RBF - INFO - train epoch 2 of total 5000 epoches
2020-02-27 23:19:14,537 - RBF - ERROR - loss 4.849754536825266, in epoch 2, in step 199, in global step 11200, learning rate is 0.0005, taks 3.641000270843506 seconds
2020-02-27 23:19:15,058 - RBF - ERROR - loss 4.605124813672437, in epoch 2, in step 399, in global step 11400, learning rate is 0.0005, taks 0.5209999084472656 seconds
2020-02-27 23:19:15,326 - RBF - INFO - train epoch 3 of total 5000 epoches
2020-02-27 23:19:15,835 - RBF - ERROR - loss 4.481309853441728, in epoch 3, in step 199, in global step 11700, learning rate is 0.0005, taks 0.7769999504089355 seconds
2020-02-27 23:19:16,343 - RBF - ERROR - loss 4.480360987454516, in epoch 3, in step 399, in global step 11900, learning rate is 0.0005, taks 0.5079998970031738 seconds
2020-02-27 23:19:18,783 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 3. learning_rate is 0.0005, loss is 3.886478758332668
2020-02-27 23:19:18,784 - RBF - INFO - train epoch 4 of total 5000 epoches
2020-02-27 23:19:19,332 - RBF - ERROR - loss 4.4794683577292504, in epoch 4, in step 199, in global step 12200, learning rate is 0.0005, taks 2.9880001544952393 seconds
2020-02-27 23:19:19,860 - RBF - ERROR - loss 4.478887337464151, in epoch 4, in step 399, in global step 12400, learning rate is 0.0005, taks 0.5279998779296875 seconds
2020-02-27 23:19:20,161 - RBF - INFO - train epoch 5 of total 5000 epoches
2020-02-27 23:19:20,667 - RBF - ERROR - loss 4.478092721765391, in epoch 5, in step 199, in global step 12700, learning rate is 0.0005, taks 0.8059999942779541 seconds
2020-02-27 23:19:21,237 - RBF - ERROR - loss 4.477660217843415, in epoch 5, in step 399, in global step 12900, learning rate is 0.0005, taks 0.570000171661377 seconds
2020-02-27 23:19:23,470 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 5. learning_rate is 0.0005, loss is 3.8836305043038832
2020-02-27 23:19:23,472 - RBF - INFO - train epoch 6 of total 5000 epoches
2020-02-27 23:19:23,995 - RBF - ERROR - loss 4.477219531638226, in epoch 6, in step 199, in global step 13200, learning rate is 0.0005, taks 2.757999897003174 seconds
2020-02-27 23:19:24,514 - RBF - ERROR - loss 4.477042116060021, in epoch 6, in step 399, in global step 13400, learning rate is 0.0005, taks 0.5190000534057617 seconds
2020-02-27 23:19:24,776 - RBF - INFO - train epoch 7 of total 5000 epoches
2020-02-27 23:19:25,289 - RBF - ERROR - loss 4.476855210953426, in epoch 7, in step 199, in global step 13700, learning rate is 0.0005, taks 0.7739996910095215 seconds
2020-02-27 23:19:25,807 - RBF - ERROR - loss 4.476747053742183, in epoch 7, in step 399, in global step 13900, learning rate is 0.0005, taks 0.5179996490478516 seconds
2020-02-27 23:19:28,234 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 7. learning_rate is 0.0005, loss is 3.8826100707259528
2020-02-27 23:19:28,235 - RBF - INFO - train epoch 8 of total 5000 epoches
2020-02-27 23:19:28,743 - RBF - ERROR - loss 4.476583352956074, in epoch 8, in step 199, in global step 14200, learning rate is 0.0005, taks 2.93500018119812 seconds
2020-02-27 23:19:29,219 - RBF - ERROR - loss 4.476466039622319, in epoch 8, in step 399, in global step 14400, learning rate is 0.0005, taks 0.4760000705718994 seconds
2020-02-27 23:19:29,452 - RBF - INFO - train epoch 9 of total 5000 epoches
2020-02-27 23:19:29,927 - RBF - ERROR - loss 4.476266892252507, in epoch 9, in step 199, in global step 14700, learning rate is 0.0005, taks 0.7070000171661377 seconds
2020-02-27 23:19:30,398 - RBF - ERROR - loss 4.47611064188545, in epoch 9, in step 399, in global step 14900, learning rate is 0.0005, taks 0.47099995613098145 seconds
2020-02-27 23:19:32,674 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 9. learning_rate is 0.0005, loss is 3.8820729091994974
2020-02-27 23:19:32,675 - RBF - INFO - train epoch 10 of total 5000 epoches
2020-02-27 23:19:33,177 - RBF - ERROR - loss 4.4758243894874585, in epoch 10, in step 199, in global step 15200, learning rate is 0.0005, taks 2.7790000438690186 seconds
2020-02-27 23:19:33,648 - RBF - ERROR - loss 4.475592157618308, in epoch 10, in step 399, in global step 15400, learning rate is 0.0005, taks 0.4699997901916504 seconds
2020-02-27 23:19:33,891 - RBF - INFO - train epoch 11 of total 5000 epoches
2020-02-27 23:19:34,381 - RBF - ERROR - loss 4.475198461269755, in epoch 11, in step 199, in global step 15700, learning rate is 0.0005, taks 0.7330000400543213 seconds
2020-02-27 23:19:34,857 - RBF - ERROR - loss 4.474941986758219, in epoch 11, in step 399, in global step 15900, learning rate is 0.0005, taks 0.4760000705718994 seconds
2020-02-27 23:19:37,184 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 11. learning_rate is 0.0005, loss is 3.88111596296829
2020-02-27 23:19:37,184 - RBF - INFO - train epoch 12 of total 5000 epoches
2020-02-27 23:19:37,758 - RBF - ERROR - loss 4.474633227472403, in epoch 12, in step 199, in global step 16200, learning rate is 0.0005, taks 2.9010000228881836 seconds
2020-02-27 23:19:38,259 - RBF - ERROR - loss 4.474487619814614, in epoch 12, in step 399, in global step 16400, learning rate is 0.0005, taks 0.500999927520752 seconds
2020-02-27 23:19:38,494 - RBF - INFO - train epoch 13 of total 5000 epoches
2020-02-27 23:19:38,988 - RBF - ERROR - loss 4.474327053083824, in epoch 13, in step 199, in global step 16700, learning rate is 0.0005, taks 0.7279999256134033 seconds
2020-02-27 23:19:39,466 - RBF - ERROR - loss 4.47422000355944, in epoch 13, in step 399, in global step 16900, learning rate is 0.0005, taks 0.4780001640319824 seconds
2020-02-27 23:19:41,687 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 13. learning_rate is 0.0005, loss is 3.8804692067211066
2020-02-27 23:19:41,688 - RBF - INFO - train epoch 14 of total 5000 epoches
2020-02-27 23:19:42,248 - RBF - ERROR - loss 4.473238934429298, in epoch 14, in step 199, in global step 17200, learning rate is 0.0005, taks 2.7819998264312744 seconds
2020-02-27 23:19:42,730 - RBF - ERROR - loss 4.385128062486221, in epoch 14, in step 399, in global step 17400, learning rate is 0.0005, taks 0.48200011253356934 seconds
2020-02-27 23:19:42,975 - RBF - INFO - train epoch 15 of total 5000 epoches
2020-02-27 23:19:43,447 - RBF - ERROR - loss 3.848469543600558, in epoch 15, in step 199, in global step 17700, learning rate is 0.0005, taks 0.7170000076293945 seconds
2020-02-27 23:19:43,926 - RBF - ERROR - loss 3.564568524211848, in epoch 15, in step 399, in global step 17900, learning rate is 0.0005, taks 0.4790000915527344 seconds
2020-02-27 23:19:46,533 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 15. learning_rate is 0.0005, loss is 2.576467579085203
2020-02-27 23:19:46,534 - RBF - INFO - train epoch 16 of total 5000 epoches
2020-02-27 23:19:47,074 - RBF - ERROR - loss 3.4572560193212265, in epoch 16, in step 199, in global step 18200, learning rate is 0.0005, taks 3.1470000743865967 seconds
2020-02-27 23:19:47,550 - RBF - ERROR - loss 3.441468326404787, in epoch 16, in step 399, in global step 18400, learning rate is 0.0005, taks 0.4760000705718994 seconds
2020-02-27 23:19:47,785 - RBF - INFO - train epoch 17 of total 5000 epoches
2020-02-27 23:19:48,253 - RBF - ERROR - loss 3.4244824366956674, in epoch 17, in step 199, in global step 18700, learning rate is 0.0005, taks 0.7030000686645508 seconds
2020-02-27 23:19:48,731 - RBF - ERROR - loss 3.4162524224305963, in epoch 17, in step 399, in global step 18900, learning rate is 0.0005, taks 0.4779996871948242 seconds
2020-02-27 23:19:51,291 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 17. learning_rate is 0.0005, loss is 2.4269053756054664
2020-02-27 23:19:51,292 - RBF - INFO - train epoch 18 of total 5000 epoches
2020-02-27 23:19:51,884 - RBF - ERROR - loss 3.4067561906206776, in epoch 18, in step 199, in global step 19200, learning rate is 0.0005, taks 3.1530001163482666 seconds
2020-02-27 23:19:52,357 - RBF - ERROR - loss 3.4017244931671273, in epoch 18, in step 399, in global step 19400, learning rate is 0.0005, taks 0.47300004959106445 seconds
2020-02-27 23:19:52,587 - RBF - INFO - train epoch 19 of total 5000 epoches
2020-02-27 23:19:53,062 - RBF - ERROR - loss 3.395512285829062, in epoch 19, in step 199, in global step 19700, learning rate is 0.0005, taks 0.7049999237060547 seconds
2020-02-27 23:19:53,526 - RBF - ERROR - loss 3.3920405147914523, in epoch 19, in step 399, in global step 19900, learning rate is 0.0005, taks 0.46399998664855957 seconds
2020-02-27 23:19:55,937 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 19. learning_rate is 0.0005, loss is 2.3990531613911856
2020-02-27 23:19:55,938 - RBF - INFO - train epoch 20 of total 5000 epoches
2020-02-27 23:19:56,447 - RBF - ERROR - loss 3.387583444009583, in epoch 20, in step 199, in global step 20200, learning rate is 0.0005, taks 2.9210000038146973 seconds
2020-02-27 23:19:56,936 - RBF - ERROR - loss 3.3850047900181996, in epoch 20, in step 399, in global step 20400, learning rate is 0.0005, taks 0.4889998435974121 seconds
2020-02-27 23:19:57,180 - RBF - INFO - train epoch 21 of total 5000 epoches
2020-02-27 23:19:57,650 - RBF - ERROR - loss 3.3815722494399836, in epoch 21, in step 199, in global step 20700, learning rate is 0.0005, taks 0.7140002250671387 seconds
2020-02-27 23:19:58,147 - RBF - ERROR - loss 3.3794764592711073, in epoch 21, in step 399, in global step 20900, learning rate is 0.0005, taks 0.49699997901916504 seconds
2020-02-27 23:20:01,213 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 21. learning_rate is 0.0005, loss is 2.384167561752267
2020-02-27 23:20:01,214 - RBF - INFO - train epoch 22 of total 5000 epoches
2020-02-27 23:20:01,765 - RBF - ERROR - loss 3.3765581466261714, in epoch 22, in step 199, in global step 21200, learning rate is 0.0005, taks 3.618000030517578 seconds
2020-02-27 23:20:02,234 - RBF - ERROR - loss 3.374980651837828, in epoch 22, in step 399, in global step 21400, learning rate is 0.0005, taks 0.4679999351501465 seconds
2020-02-27 23:20:02,465 - RBF - INFO - train epoch 23 of total 5000 epoches
2020-02-27 23:20:02,940 - RBF - ERROR - loss 3.372912660373791, in epoch 23, in step 199, in global step 21700, learning rate is 0.0005, taks 0.7059998512268066 seconds
2020-02-27 23:20:03,399 - RBF - ERROR - loss 3.3716939565229342, in epoch 23, in step 399, in global step 21900, learning rate is 0.0005, taks 0.4589998722076416 seconds
2020-02-27 23:20:06,613 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 23. learning_rate is 0.0005, loss is 2.375178598875027
2020-02-27 23:20:06,613 - RBF - INFO - train epoch 24 of total 5000 epoches
2020-02-27 23:20:07,124 - RBF - ERROR - loss 3.3700427232007, in epoch 24, in step 199, in global step 22200, learning rate is 0.0005, taks 3.7250001430511475 seconds
2020-02-27 23:20:07,603 - RBF - ERROR - loss 3.3690259904372573, in epoch 24, in step 399, in global step 22400, learning rate is 0.0005, taks 0.4789998531341553 seconds
2020-02-27 23:20:07,839 - RBF - INFO - train epoch 25 of total 5000 epoches
2020-02-27 23:20:08,331 - RBF - ERROR - loss 3.3677150899354946, in epoch 25, in step 199, in global step 22700, learning rate is 0.0005, taks 0.7280001640319824 seconds
2020-02-27 23:20:08,864 - RBF - ERROR - loss 3.3669560959680105, in epoch 25, in step 399, in global step 22900, learning rate is 0.0005, taks 0.5329999923706055 seconds
2020-02-27 23:20:13,269 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 25. learning_rate is 0.0005, loss is 2.3694839534924172
2020-02-27 23:20:13,270 - RBF - INFO - train epoch 26 of total 5000 epoches
2020-02-27 23:20:13,857 - RBF - ERROR - loss 3.3659276237044953, in epoch 26, in step 199, in global step 23200, learning rate is 0.0005, taks 4.993000030517578 seconds
2020-02-27 23:20:14,346 - RBF - ERROR - loss 3.365280959869447, in epoch 26, in step 399, in global step 23400, learning rate is 0.0005, taks 0.4890000820159912 seconds
2020-02-27 23:20:14,586 - RBF - INFO - train epoch 27 of total 5000 epoches
2020-02-27 23:20:15,071 - RBF - ERROR - loss 3.3592822871589485, in epoch 27, in step 199, in global step 23700, learning rate is 0.0005, taks 0.7249999046325684 seconds
2020-02-27 23:20:15,549 - RBF - ERROR - loss 3.261649701494611, in epoch 27, in step 399, in global step 23900, learning rate is 0.0005, taks 0.4780001640319824 seconds
2020-02-27 23:20:18,414 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 27. learning_rate is 0.0005, loss is 2.231979731037304
2020-02-27 23:20:18,415 - RBF - INFO - train epoch 28 of total 5000 epoches
2020-02-27 23:20:19,010 - RBF - ERROR - loss 2.7836852711482365, in epoch 28, in step 199, in global step 24200, learning rate is 0.0005, taks 3.4609997272491455 seconds
2020-02-27 23:20:19,497 - RBF - ERROR - loss 2.311309887440822, in epoch 28, in step 399, in global step 24400, learning rate is 0.0005, taks 0.48600006103515625 seconds
2020-02-27 23:20:19,743 - RBF - INFO - train epoch 29 of total 5000 epoches
2020-02-27 23:20:20,233 - RBF - ERROR - loss 1.599663328263533, in epoch 29, in step 199, in global step 24700, learning rate is 0.0005, taks 0.7359998226165771 seconds
2020-02-27 23:20:20,718 - RBF - ERROR - loss 1.1970467687321067, in epoch 29, in step 399, in global step 24900, learning rate is 0.0005, taks 0.4850001335144043 seconds
2020-02-27 23:20:22,997 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 29. learning_rate is 0.0005, loss is 0.7292933171941558
2020-02-27 23:20:22,997 - RBF - INFO - train epoch 30 of total 5000 epoches
2020-02-27 23:20:23,532 - RBF - ERROR - loss 0.7357209056910534, in epoch 30, in step 199, in global step 25200, learning rate is 0.0005, taks 2.813999891281128 seconds
2020-02-27 23:20:24,031 - RBF - ERROR - loss 0.5160013731243723, in epoch 30, in step 399, in global step 25400, learning rate is 0.0005, taks 0.49900007247924805 seconds
2020-02-27 23:20:24,281 - RBF - INFO - train epoch 31 of total 5000 epoches
2020-02-27 23:20:24,755 - RBF - ERROR - loss 0.2906581919976413, in epoch 31, in step 199, in global step 25700, learning rate is 0.0005, taks 0.7230000495910645 seconds
2020-02-27 23:20:25,234 - RBF - ERROR - loss 0.1951109436114944, in epoch 31, in step 399, in global step 25900, learning rate is 0.0005, taks 0.4790000915527344 seconds
2020-02-27 23:20:27,468 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 31. learning_rate is 0.0005, loss is 0.12359693691402966
2020-02-27 23:20:27,468 - RBF - INFO - train epoch 32 of total 5000 epoches
2020-02-27 23:20:28,020 - RBF - ERROR - loss 0.10784322679988155, in epoch 32, in step 199, in global step 26200, learning rate is 0.0005, taks 2.7859997749328613 seconds
2020-02-27 23:20:28,491 - RBF - ERROR - loss 0.06956011446090143, in epoch 32, in step 399, in global step 26400, learning rate is 0.0005, taks 0.47099995613098145 seconds
2020-02-27 23:20:28,737 - RBF - INFO - train epoch 33 of total 5000 epoches
2020-02-27 23:20:29,205 - RBF - ERROR - loss 0.03380086585633618, in epoch 33, in step 199, in global step 26700, learning rate is 0.0005, taks 0.7140002250671387 seconds
2020-02-27 23:20:29,673 - RBF - ERROR - loss 0.02087399692923305, in epoch 33, in step 399, in global step 26900, learning rate is 0.0005, taks 0.4679999351501465 seconds
2020-02-27 23:20:32,502 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 33. learning_rate is 0.0005, loss is 0.01720226755899806
2020-02-27 23:20:32,502 - RBF - INFO - train epoch 34 of total 5000 epoches
2020-02-27 23:20:33,045 - RBF - ERROR - loss 0.013743081902083858, in epoch 34, in step 199, in global step 27200, learning rate is 0.0005, taks 3.371999979019165 seconds
2020-02-27 23:20:33,541 - RBF - ERROR - loss 0.01212546642405168, in epoch 34, in step 399, in global step 27400, learning rate is 0.0005, taks 0.49500012397766113 seconds
2020-02-27 23:20:33,797 - RBF - INFO - train epoch 35 of total 5000 epoches
2020-02-27 23:20:34,331 - RBF - ERROR - loss 0.010910040289471477, in epoch 35, in step 199, in global step 27700, learning rate is 0.0005, taks 0.7899999618530273 seconds
2020-02-27 23:20:34,849 - RBF - ERROR - loss 0.01034505387836691, in epoch 35, in step 399, in global step 27900, learning rate is 0.0005, taks 0.5180001258850098 seconds
2020-02-27 23:20:38,424 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 35. learning_rate is 0.0005, loss is 0.008040510889418949
2020-02-27 23:20:38,424 - RBF - INFO - train epoch 36 of total 5000 epoches
2020-02-27 23:20:38,978 - RBF - ERROR - loss 0.009590147250370941, in epoch 36, in step 199, in global step 28200, learning rate is 0.0005, taks 4.128999948501587 seconds
2020-02-27 23:20:39,458 - RBF - ERROR - loss 0.0091112972335983, in epoch 36, in step 399, in global step 28400, learning rate is 0.0005, taks 0.48000001907348633 seconds
2020-02-27 23:20:39,702 - RBF - INFO - train epoch 37 of total 5000 epoches
2020-02-27 23:20:40,194 - RBF - ERROR - loss 0.008418464389127718, in epoch 37, in step 199, in global step 28700, learning rate is 0.0005, taks 0.7359998226165771 seconds
2020-02-27 23:20:40,698 - RBF - ERROR - loss 0.00797406640717186, in epoch 37, in step 399, in global step 28900, learning rate is 0.0005, taks 0.504000186920166 seconds
2020-02-27 23:20:42,926 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 37. learning_rate is 0.0005, loss is 0.0061243007330712695
2020-02-27 23:20:42,926 - RBF - INFO - train epoch 38 of total 5000 epoches
2020-02-27 23:20:43,469 - RBF - ERROR - loss 0.0073357546709349915, in epoch 38, in step 199, in global step 29200, learning rate is 0.0005, taks 2.7709999084472656 seconds
2020-02-27 23:20:43,972 - RBF - ERROR - loss 0.0069299400106498776, in epoch 38, in step 399, in global step 29400, learning rate is 0.0005, taks 0.5029997825622559 seconds
2020-02-27 23:20:44,216 - RBF - INFO - train epoch 39 of total 5000 epoches
2020-02-27 23:20:44,686 - RBF - ERROR - loss 0.006351646282546888, in epoch 39, in step 199, in global step 29700, learning rate is 0.0005, taks 0.7140002250671387 seconds
2020-02-27 23:20:45,177 - RBF - ERROR - loss 0.005986582079584979, in epoch 39, in step 399, in global step 29900, learning rate is 0.0005, taks 0.4909999370574951 seconds
2020-02-27 23:20:48,269 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 39. learning_rate is 0.0005, loss is 0.0046267736781751955
2020-02-27 23:20:48,269 - RBF - INFO - train epoch 40 of total 5000 epoches
2020-02-27 23:20:48,817 - RBF - ERROR - loss 0.005469585759091217, in epoch 40, in step 199, in global step 30200, learning rate is 0.0005, taks 3.640000104904175 seconds
2020-02-27 23:20:49,312 - RBF - ERROR - loss 0.005145139091012066, in epoch 40, in step 399, in global step 30400, learning rate is 0.0005, taks 0.49499988555908203 seconds
2020-02-27 23:20:49,558 - RBF - INFO - train epoch 41 of total 5000 epoches
2020-02-27 23:20:50,053 - RBF - ERROR - loss 0.0046883221252824354, in epoch 41, in step 199, in global step 30700, learning rate is 0.0005, taks 0.7410001754760742 seconds
2020-02-27 23:20:50,553 - RBF - ERROR - loss 0.004403307270118284, in epoch 41, in step 399, in global step 30900, learning rate is 0.0005, taks 0.5 seconds
2020-02-27 23:20:52,679 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 41. learning_rate is 0.0005, loss is 0.0034121062310223205
2020-02-27 23:20:52,680 - RBF - INFO - train epoch 42 of total 5000 epoches
2020-02-27 23:20:53,196 - RBF - ERROR - loss 0.00400426966634121, in epoch 42, in step 199, in global step 31200, learning rate is 0.0005, taks 2.6419997215270996 seconds
2020-02-27 23:20:53,685 - RBF - ERROR - loss 0.0037567232208923014, in epoch 42, in step 399, in global step 31400, learning rate is 0.0005, taks 0.4890003204345703 seconds
2020-02-27 23:20:53,928 - RBF - INFO - train epoch 43 of total 5000 epoches
2020-02-27 23:20:54,408 - RBF - ERROR - loss 0.0034120684836055504, in epoch 43, in step 199, in global step 31700, learning rate is 0.0005, taks 0.7229998111724854 seconds
2020-02-27 23:20:54,895 - RBF - ERROR - loss 0.003199411628638541, in epoch 43, in step 399, in global step 31900, learning rate is 0.0005, taks 0.4869999885559082 seconds
2020-02-27 23:20:57,906 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 43. learning_rate is 0.0005, loss is 0.0024867975706087428
2020-02-27 23:20:57,912 - RBF - INFO - train epoch 44 of total 5000 epoches
2020-02-27 23:20:59,256 - RBF - ERROR - loss 0.0029049279742525426, in epoch 44, in step 199, in global step 32200, learning rate is 0.0005, taks 4.361000061035156 seconds
2020-02-27 23:21:00,276 - RBF - ERROR - loss 0.0027242446205746583, in epoch 44, in step 399, in global step 32400, learning rate is 0.0005, taks 1.0189998149871826 seconds
2020-02-27 23:21:00,734 - RBF - INFO - train epoch 45 of total 5000 epoches
2020-02-27 23:21:01,521 - RBF - ERROR - loss 0.0024754610754368802, in epoch 45, in step 199, in global step 32700, learning rate is 0.0005, taks 1.2450001239776611 seconds
2020-02-27 23:21:02,262 - RBF - ERROR - loss 0.0023237056628127384, in epoch 45, in step 399, in global step 32900, learning rate is 0.0005, taks 0.7400000095367432 seconds
2020-02-27 23:21:05,688 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 45. learning_rate is 0.0005, loss is 0.0018164789537723262
2020-02-27 23:21:05,689 - RBF - INFO - train epoch 46 of total 5000 epoches
2020-02-27 23:21:06,172 - RBF - ERROR - loss 0.002115941447055398, in epoch 46, in step 199, in global step 33200, learning rate is 0.0005, taks 3.9089999198913574 seconds
2020-03-23 16:02:11,957 - RBF - INFO - now initialize the net with para:
2020-03-23 16:02:11,957 - RBF - INFO - clip
2020-03-23 16:02:11,957 - RBF - INFO - False
2020-03-23 16:02:11,957 - RBF - INFO - -----------------------------
2020-03-23 16:02:11,957 - RBF - INFO - CKPT
2020-03-23 16:02:11,957 - RBF - INFO - ckpt
2020-03-23 16:02:11,957 - RBF - INFO - -----------------------------
2020-03-23 16:02:11,957 - RBF - INFO - BATCHSIZE
2020-03-23 16:02:11,957 - RBF - INFO - 1000
2020-03-23 16:02:11,957 - RBF - INFO - -----------------------------
2020-03-23 16:02:11,957 - RBF - INFO - MAX_ITER
2020-03-23 16:02:11,957 - RBF - INFO - 5000
2020-03-23 16:02:11,957 - RBF - INFO - -----------------------------
2020-03-23 16:02:11,957 - RBF - INFO - STEP_EACH_ITER
2020-03-23 16:02:11,957 - RBF - INFO - 500
2020-03-23 16:02:11,957 - RBF - INFO - -----------------------------
2020-03-23 16:02:11,957 - RBF - INFO - STEP_SHOW
2020-03-23 16:02:11,957 - RBF - INFO - 200
2020-03-23 16:02:11,957 - RBF - INFO - -----------------------------
2020-03-23 16:02:11,957 - RBF - INFO - EPOCH_SAVE
2020-03-23 16:02:11,957 - RBF - INFO - 20
2020-03-23 16:02:11,957 - RBF - INFO - -----------------------------
2020-03-23 16:02:11,957 - RBF - INFO - LEARNING_RATE
2020-03-23 16:02:11,957 - RBF - INFO - 0.00015
2020-03-23 16:02:11,957 - RBF - INFO - -----------------------------
2020-03-23 16:02:11,957 - RBF - INFO - bound_weight
2020-03-23 16:02:11,957 - RBF - INFO - 1
2020-03-23 16:02:11,957 - RBF - INFO - -----------------------------
2020-03-23 16:02:11,957 - RBF - INFO - step_unbound
2020-03-23 16:02:11,957 - RBF - INFO - 5
2020-03-23 16:02:11,957 - RBF - INFO - -----------------------------
2020-03-23 16:02:11,957 - RBF - INFO - decay
2020-03-23 16:02:11,957 - RBF - INFO - False
2020-03-23 16:02:11,957 - RBF - INFO - -----------------------------
2020-03-23 16:02:11,957 - RBF - INFO - test_line
2020-03-23 16:02:11,957 - RBF - INFO - False
2020-03-23 16:02:11,957 - RBF - INFO - -----------------------------
2020-03-23 16:02:11,957 - RBF - INFO - is_plot
2020-03-23 16:02:11,957 - RBF - INFO - False
2020-03-23 16:02:11,957 - RBF - INFO - -----------------------------
2020-03-23 16:02:11,989 - RBF - INFO - openning sess
2020-03-23 16:02:47,568 - RBF - INFO - now initialize the net with para:
2020-03-23 16:02:47,569 - RBF - INFO - clip
2020-03-23 16:02:47,569 - RBF - INFO - False
2020-03-23 16:02:47,569 - RBF - INFO - -----------------------------
2020-03-23 16:02:47,569 - RBF - INFO - CKPT
2020-03-23 16:02:47,569 - RBF - INFO - ckpt
2020-03-23 16:02:47,569 - RBF - INFO - -----------------------------
2020-03-23 16:02:47,569 - RBF - INFO - BATCHSIZE
2020-03-23 16:02:47,569 - RBF - INFO - 1000
2020-03-23 16:02:47,569 - RBF - INFO - -----------------------------
2020-03-23 16:02:47,569 - RBF - INFO - MAX_ITER
2020-03-23 16:02:47,569 - RBF - INFO - 5000
2020-03-23 16:02:47,569 - RBF - INFO - -----------------------------
2020-03-23 16:02:47,569 - RBF - INFO - STEP_EACH_ITER
2020-03-23 16:02:47,570 - RBF - INFO - 500
2020-03-23 16:02:47,570 - RBF - INFO - -----------------------------
2020-03-23 16:02:47,570 - RBF - INFO - STEP_SHOW
2020-03-23 16:02:47,570 - RBF - INFO - 200
2020-03-23 16:02:47,570 - RBF - INFO - -----------------------------
2020-03-23 16:02:47,570 - RBF - INFO - EPOCH_SAVE
2020-03-23 16:02:47,570 - RBF - INFO - 20
2020-03-23 16:02:47,570 - RBF - INFO - -----------------------------
2020-03-23 16:02:47,570 - RBF - INFO - LEARNING_RATE
2020-03-23 16:02:47,570 - RBF - INFO - 0.00015
2020-03-23 16:02:47,570 - RBF - INFO - -----------------------------
2020-03-23 16:02:47,570 - RBF - INFO - bound_weight
2020-03-23 16:02:47,570 - RBF - INFO - 1
2020-03-23 16:02:47,570 - RBF - INFO - -----------------------------
2020-03-23 16:02:47,570 - RBF - INFO - step_unbound
2020-03-23 16:02:47,571 - RBF - INFO - 5
2020-03-23 16:02:47,571 - RBF - INFO - -----------------------------
2020-03-23 16:02:47,571 - RBF - INFO - decay
2020-03-23 16:02:47,571 - RBF - INFO - False
2020-03-23 16:02:47,571 - RBF - INFO - -----------------------------
2020-03-23 16:02:47,571 - RBF - INFO - test_line
2020-03-23 16:02:47,571 - RBF - INFO - False
2020-03-23 16:02:47,571 - RBF - INFO - -----------------------------
2020-03-23 16:02:47,571 - RBF - INFO - is_plot
2020-03-23 16:02:47,571 - RBF - INFO - False
2020-03-23 16:02:47,571 - RBF - INFO - -----------------------------
2020-03-23 16:02:47,600 - RBF - INFO - openning sess
2020-03-23 16:02:51,875 - RBF - INFO - building net
2020-03-23 16:02:59,767 - RBF - INFO - building opt
2020-03-23 16:03:00,494 - RBF - INFO - net initializing
2020-03-23 16:03:00,494 - RBF - INFO - train epoch 0 of total 5000 epoches
2020-03-23 16:03:07,176 - RBF - ERROR - loss 1.372530259716259, in epoch 0, in step 199, in global step 200, learning rate is 0.00015, taks 6.682199954986572 seconds
2020-03-23 16:03:09,680 - RBF - ERROR - loss 1.3550030264047137, in epoch 0, in step 399, in global step 400, learning rate is 0.00015, taks 2.504199981689453 seconds
2020-03-23 16:03:10,911 - RBF - INFO - train epoch 1 of total 5000 epoches
2020-03-23 16:03:13,430 - RBF - ERROR - loss 1.342398754351681, in epoch 1, in step 199, in global step 700, learning rate is 0.00015, taks 3.750000238418579 seconds
2020-03-23 16:03:15,900 - RBF - ERROR - loss 1.3364105805049091, in epoch 1, in step 399, in global step 900, learning rate is 0.00015, taks 2.4702000617980957 seconds
2020-03-23 16:03:17,148 - RBF - INFO - train epoch 2 of total 5000 epoches
2020-03-23 16:03:19,684 - RBF - ERROR - loss 1.328813397513142, in epoch 2, in step 199, in global step 1200, learning rate is 0.00015, taks 3.783399820327759 seconds
2020-03-23 16:03:22,176 - RBF - ERROR - loss 1.3248881320472319, in epoch 2, in step 399, in global step 1400, learning rate is 0.00015, taks 2.491600275039673 seconds
2020-03-23 16:03:23,449 - RBF - INFO - train epoch 3 of total 5000 epoches
2020-03-23 16:03:25,937 - RBF - ERROR - loss 1.3205967140187453, in epoch 3, in step 199, in global step 1700, learning rate is 0.00015, taks 3.761199712753296 seconds
2020-03-23 16:03:28,442 - RBF - ERROR - loss 1.3183729217050753, in epoch 3, in step 399, in global step 1900, learning rate is 0.00015, taks 2.5042002201080322 seconds
2020-03-23 16:03:29,707 - RBF - INFO - train epoch 4 of total 5000 epoches
2020-03-23 16:03:32,180 - RBF - ERROR - loss 1.3161387091854841, in epoch 4, in step 199, in global step 2200, learning rate is 0.00015, taks 3.73799991607666 seconds
2020-03-23 16:03:34,726 - RBF - ERROR - loss 1.315073446242558, in epoch 4, in step 399, in global step 2400, learning rate is 0.00015, taks 2.5462000370025635 seconds
2020-03-23 16:03:36,021 - RBF - INFO - train epoch 5 of total 5000 epoches
2020-03-23 16:03:38,535 - RBF - ERROR - loss 1.3137342248814365, in epoch 5, in step 199, in global step 2700, learning rate is 0.00015, taks 3.7934000492095947 seconds
2020-03-23 16:03:41,106 - RBF - ERROR - loss 1.31290541430985, in epoch 5, in step 399, in global step 2900, learning rate is 0.00015, taks 2.571199893951416 seconds
2020-03-23 16:03:42,360 - RBF - INFO - train epoch 6 of total 5000 epoches
2020-03-23 16:03:44,919 - RBF - ERROR - loss 1.3116408014862393, in epoch 6, in step 199, in global step 3200, learning rate is 0.00015, taks 3.8124001026153564 seconds
2020-03-23 16:03:47,497 - RBF - ERROR - loss 1.3107831010626627, in epoch 6, in step 399, in global step 3400, learning rate is 0.00015, taks 2.578000068664551 seconds
2020-03-23 16:03:48,748 - RBF - INFO - train epoch 7 of total 5000 epoches
2020-03-23 16:03:51,336 - RBF - ERROR - loss 1.3095484240648887, in epoch 7, in step 199, in global step 3700, learning rate is 0.00015, taks 3.8389999866485596 seconds
2020-03-23 16:03:53,866 - RBF - ERROR - loss 1.3087972434338428, in epoch 7, in step 399, in global step 3900, learning rate is 0.00015, taks 2.5292000770568848 seconds
2020-03-23 16:03:55,122 - RBF - INFO - train epoch 8 of total 5000 epoches
2020-03-23 16:03:57,663 - RBF - ERROR - loss 1.307842363373711, in epoch 8, in step 199, in global step 4200, learning rate is 0.00015, taks 3.797800064086914 seconds
2020-03-23 16:04:00,141 - RBF - ERROR - loss 1.3072016980388785, in epoch 8, in step 399, in global step 4400, learning rate is 0.00015, taks 2.4772000312805176 seconds
2020-03-23 16:04:01,438 - RBF - INFO - train epoch 9 of total 5000 epoches
2020-03-23 16:04:04,085 - RBF - ERROR - loss 1.3064077301819814, in epoch 9, in step 199, in global step 4700, learning rate is 0.00015, taks 3.944000005722046 seconds
2020-03-23 16:04:06,615 - RBF - ERROR - loss 1.305960211621312, in epoch 9, in step 399, in global step 4900, learning rate is 0.00015, taks 2.530400037765503 seconds
2020-03-23 16:04:07,900 - RBF - INFO - train epoch 10 of total 5000 epoches
2020-03-23 16:04:10,581 - RBF - ERROR - loss 1.30532004801729, in epoch 10, in step 199, in global step 5200, learning rate is 0.00015, taks 3.9659998416900635 seconds
2020-03-23 16:04:13,521 - RBF - ERROR - loss 1.3049620640166084, in epoch 10, in step 399, in global step 5400, learning rate is 0.00015, taks 2.9396002292633057 seconds
2020-03-23 16:04:15,166 - RBF - INFO - train epoch 11 of total 5000 epoches
2020-03-23 16:04:19,727 - RBF - ERROR - loss 1.3044822974353532, in epoch 11, in step 199, in global step 5700, learning rate is 0.00015, taks 6.206799745559692 seconds
2020-03-23 16:04:22,981 - RBF - ERROR - loss 1.3041980097686898, in epoch 11, in step 399, in global step 5900, learning rate is 0.00015, taks 3.254000186920166 seconds
2020-03-23 16:04:24,469 - RBF - INFO - train epoch 12 of total 5000 epoches
2020-03-23 16:04:28,458 - RBF - ERROR - loss 1.3038088013445983, in epoch 12, in step 199, in global step 6200, learning rate is 0.00015, taks 5.476999998092651 seconds
2020-03-23 16:04:31,790 - RBF - ERROR - loss 1.30363913499129, in epoch 12, in step 399, in global step 6400, learning rate is 0.00015, taks 3.3309998512268066 seconds
2020-03-23 16:04:33,322 - RBF - INFO - train epoch 13 of total 5000 epoches
2020-03-23 16:04:37,034 - RBF - ERROR - loss 1.3032656985494486, in epoch 13, in step 199, in global step 6700, learning rate is 0.00015, taks 5.243800163269043 seconds
2020-03-23 16:04:39,912 - RBF - ERROR - loss 1.3030773015034534, in epoch 13, in step 399, in global step 6900, learning rate is 0.00015, taks 2.8774001598358154 seconds
2020-03-23 16:04:41,301 - RBF - INFO - train epoch 14 of total 5000 epoches
2020-03-23 16:04:43,859 - RBF - ERROR - loss 1.3028057252558471, in epoch 14, in step 199, in global step 7200, learning rate is 0.00015, taks 3.94599986076355 seconds
2020-03-23 16:04:46,391 - RBF - ERROR - loss 1.3026220864338118, in epoch 14, in step 399, in global step 7400, learning rate is 0.00015, taks 2.5327999591827393 seconds
2020-03-23 16:04:47,838 - RBF - INFO - train epoch 15 of total 5000 epoches
2020-03-23 16:04:51,049 - RBF - ERROR - loss 1.302371367137614, in epoch 15, in step 199, in global step 7700, learning rate is 0.00015, taks 4.6579999923706055 seconds
2020-03-23 16:04:53,819 - RBF - ERROR - loss 1.302207471503864, in epoch 15, in step 399, in global step 7900, learning rate is 0.00015, taks 2.7699999809265137 seconds
2020-03-23 16:04:55,318 - RBF - INFO - train epoch 16 of total 5000 epoches
2020-03-23 16:04:57,952 - RBF - ERROR - loss 1.301977942209599, in epoch 16, in step 199, in global step 8200, learning rate is 0.00015, taks 4.133000135421753 seconds
2020-03-23 16:05:01,513 - RBF - ERROR - loss 1.3018300638648905, in epoch 16, in step 399, in global step 8400, learning rate is 0.00015, taks 3.5604000091552734 seconds
2020-03-23 16:05:02,761 - RBF - INFO - train epoch 17 of total 5000 epoches
2020-03-23 16:05:05,479 - RBF - ERROR - loss 1.3016466085598024, in epoch 17, in step 199, in global step 8700, learning rate is 0.00015, taks 3.9657998085021973 seconds
2020-03-23 16:05:08,167 - RBF - ERROR - loss 1.301497957961368, in epoch 17, in step 399, in global step 8900, learning rate is 0.00015, taks 2.687999963760376 seconds
2020-03-23 16:05:09,534 - RBF - INFO - train epoch 18 of total 5000 epoches
2020-03-23 16:05:12,046 - RBF - ERROR - loss 1.3013092432602236, in epoch 18, in step 199, in global step 9200, learning rate is 0.00015, taks 3.879000186920166 seconds
2020-03-23 16:05:14,543 - RBF - ERROR - loss 1.301178315620639, in epoch 18, in step 399, in global step 9400, learning rate is 0.00015, taks 2.496000051498413 seconds
2020-03-23 16:05:15,801 - RBF - INFO - train epoch 19 of total 5000 epoches
2020-03-23 16:05:18,293 - RBF - ERROR - loss 1.3009996532142638, in epoch 19, in step 199, in global step 9700, learning rate is 0.00015, taks 3.75 seconds
2020-03-23 16:05:20,783 - RBF - ERROR - loss 1.3008870585204098, in epoch 19, in step 399, in global step 9900, learning rate is 0.00015, taks 2.490000009536743 seconds
2020-03-23 16:05:26,780 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 19. learning_rate is 0.00015, loss is 1.3008383407474575
2020-03-23 16:05:26,781 - RBF - INFO - train epoch 20 of total 5000 epoches
2020-03-23 16:05:32,566 - RBF - ERROR - loss 1.3007428185399226, in epoch 20, in step 199, in global step 10200, learning rate is 0.00015, taks 11.783400058746338 seconds
2020-03-23 16:05:37,830 - RBF - ERROR - loss 1.3006595792331568, in epoch 20, in step 399, in global step 10400, learning rate is 0.00015, taks 5.263999938964844 seconds
2020-03-23 16:05:40,254 - RBF - INFO - train epoch 21 of total 5000 epoches
2020-03-23 16:05:45,138 - RBF - ERROR - loss 1.3005295032876234, in epoch 21, in step 199, in global step 10700, learning rate is 0.00015, taks 7.308000087738037 seconds
2020-03-23 16:05:50,005 - RBF - ERROR - loss 1.3004522443358806, in epoch 21, in step 399, in global step 10900, learning rate is 0.00015, taks 4.865999937057495 seconds
2020-03-23 16:05:52,410 - RBF - INFO - train epoch 22 of total 5000 epoches
2020-03-23 16:05:57,211 - RBF - ERROR - loss 1.3003341155273327, in epoch 22, in step 199, in global step 11200, learning rate is 0.00015, taks 7.204999923706055 seconds
2020-03-23 16:06:02,205 - RBF - ERROR - loss 1.3002704655020272, in epoch 22, in step 399, in global step 11400, learning rate is 0.00015, taks 4.99399995803833 seconds
2020-03-23 16:06:04,679 - RBF - INFO - train epoch 23 of total 5000 epoches
2020-03-23 16:06:09,447 - RBF - ERROR - loss 1.3001596831124438, in epoch 23, in step 199, in global step 11700, learning rate is 0.00015, taks 7.242000102996826 seconds
2020-03-23 16:06:13,955 - RBF - ERROR - loss 1.3000856949860342, in epoch 23, in step 399, in global step 11900, learning rate is 0.00015, taks 4.507999897003174 seconds
2020-03-23 16:06:16,207 - RBF - INFO - train epoch 24 of total 5000 epoches
2020-03-23 16:06:20,743 - RBF - ERROR - loss 1.299987554384974, in epoch 24, in step 199, in global step 12200, learning rate is 0.00015, taks 6.7870001792907715 seconds
2020-03-23 16:06:25,290 - RBF - ERROR - loss 1.2999206592696602, in epoch 24, in step 399, in global step 12400, learning rate is 0.00015, taks 4.546999931335449 seconds
2020-03-23 16:06:27,732 - RBF - INFO - train epoch 25 of total 5000 epoches
2020-03-23 16:06:31,804 - RBF - ERROR - loss 1.2998254427166436, in epoch 25, in step 199, in global step 12700, learning rate is 0.00015, taks 6.51419997215271 seconds
2020-03-23 16:06:35,785 - RBF - ERROR - loss 1.299762725754199, in epoch 25, in step 399, in global step 12900, learning rate is 0.00015, taks 3.9810001850128174 seconds
2020-03-23 16:06:37,710 - RBF - INFO - train epoch 26 of total 5000 epoches
2020-03-23 16:06:41,602 - RBF - ERROR - loss 1.2996715247319341, in epoch 26, in step 199, in global step 13200, learning rate is 0.00015, taks 5.815399885177612 seconds
2020-03-23 16:06:44,823 - RBF - ERROR - loss 1.2996325791262782, in epoch 26, in step 399, in global step 13400, learning rate is 0.00015, taks 3.221400022506714 seconds
2020-03-23 16:06:46,464 - RBF - INFO - train epoch 27 of total 5000 epoches
2020-03-23 16:06:49,685 - RBF - ERROR - loss 1.2995490762344344, in epoch 27, in step 199, in global step 13700, learning rate is 0.00015, taks 4.861400127410889 seconds
2020-03-23 16:06:52,900 - RBF - ERROR - loss 1.2994729272902867, in epoch 27, in step 399, in global step 13900, learning rate is 0.00015, taks 3.21340012550354 seconds
2020-03-23 16:06:54,509 - RBF - INFO - train epoch 28 of total 5000 epoches
2020-03-23 16:06:57,714 - RBF - ERROR - loss 1.2994075334686805, in epoch 28, in step 199, in global step 14200, learning rate is 0.00015, taks 4.813999891281128 seconds
2020-03-23 16:07:00,928 - RBF - ERROR - loss 1.2993570253132511, in epoch 28, in step 399, in global step 14400, learning rate is 0.00015, taks 3.214399814605713 seconds
2020-03-23 16:07:02,538 - RBF - INFO - train epoch 29 of total 5000 epoches
2020-03-23 16:07:05,758 - RBF - ERROR - loss 1.299262746160497, in epoch 29, in step 199, in global step 14700, learning rate is 0.00015, taks 4.830000162124634 seconds
2020-03-23 16:07:08,970 - RBF - ERROR - loss 1.299225692918681, in epoch 29, in step 399, in global step 14900, learning rate is 0.00015, taks 3.211400032043457 seconds
2020-03-23 16:07:10,588 - RBF - INFO - train epoch 30 of total 5000 epoches
2020-03-23 16:07:13,809 - RBF - ERROR - loss 1.2991418567390651, in epoch 30, in step 199, in global step 15200, learning rate is 0.00015, taks 4.83899998664856 seconds
2020-03-23 16:07:17,013 - RBF - ERROR - loss 1.2990986178744937, in epoch 30, in step 399, in global step 15400, learning rate is 0.00015, taks 3.203399896621704 seconds
2020-03-23 16:07:18,632 - RBF - INFO - train epoch 31 of total 5000 epoches
2020-03-23 16:07:21,851 - RBF - ERROR - loss 1.2990305456158828, in epoch 31, in step 199, in global step 15700, learning rate is 0.00015, taks 4.838000297546387 seconds
2020-03-23 16:07:25,048 - RBF - ERROR - loss 1.2989861762166124, in epoch 31, in step 399, in global step 15900, learning rate is 0.00015, taks 3.197399854660034 seconds
2020-03-23 16:07:26,652 - RBF - INFO - train epoch 32 of total 5000 epoches
2020-03-23 16:07:29,862 - RBF - ERROR - loss 1.2989274548510041, in epoch 32, in step 199, in global step 16200, learning rate is 0.00015, taks 4.812999963760376 seconds
2020-03-23 16:07:33,077 - RBF - ERROR - loss 1.2988865795936995, in epoch 32, in step 399, in global step 16400, learning rate is 0.00015, taks 3.214400053024292 seconds
2020-03-23 16:07:34,681 - RBF - INFO - train epoch 33 of total 5000 epoches
2020-03-23 16:07:37,901 - RBF - ERROR - loss 1.298838041564717, in epoch 33, in step 199, in global step 16700, learning rate is 0.00015, taks 4.824000120162964 seconds
2020-03-23 16:07:41,120 - RBF - ERROR - loss 1.2988021643522376, in epoch 33, in step 399, in global step 16900, learning rate is 0.00015, taks 3.219399929046631 seconds
2020-03-23 16:07:42,729 - RBF - INFO - train epoch 34 of total 5000 epoches
2020-03-23 16:07:45,975 - RBF - ERROR - loss 1.2987442151308166, in epoch 34, in step 199, in global step 17200, learning rate is 0.00015, taks 4.853399753570557 seconds
2020-03-23 16:07:49,200 - RBF - ERROR - loss 1.2987123274238945, in epoch 34, in step 399, in global step 17400, learning rate is 0.00015, taks 3.225399971008301 seconds
2020-03-23 16:07:50,815 - RBF - INFO - train epoch 35 of total 5000 epoches
2020-03-23 16:07:54,030 - RBF - ERROR - loss 1.298665198514121, in epoch 35, in step 199, in global step 17700, learning rate is 0.00015, taks 4.830000162124634 seconds
2020-03-23 16:07:57,238 - RBF - ERROR - loss 1.2986349354375535, in epoch 35, in step 399, in global step 17900, learning rate is 0.00015, taks 3.208400011062622 seconds
2020-03-23 16:07:58,848 - RBF - INFO - train epoch 36 of total 5000 epoches
2020-03-23 16:08:02,067 - RBF - ERROR - loss 1.2985903354887705, in epoch 36, in step 199, in global step 18200, learning rate is 0.00015, taks 4.828999757766724 seconds
2020-03-23 16:08:05,283 - RBF - ERROR - loss 1.298562867730136, in epoch 36, in step 399, in global step 18400, learning rate is 0.00015, taks 3.215400218963623 seconds
2020-03-23 16:08:06,886 - RBF - INFO - train epoch 37 of total 5000 epoches
2020-03-23 16:08:10,104 - RBF - ERROR - loss 1.2985250120832965, in epoch 37, in step 199, in global step 18700, learning rate is 0.00015, taks 4.821399927139282 seconds
2020-03-23 16:08:13,318 - RBF - ERROR - loss 1.2985021525249354, in epoch 37, in step 399, in global step 18900, learning rate is 0.00015, taks 3.21340012550354 seconds
2020-03-23 16:08:14,926 - RBF - INFO - train epoch 38 of total 5000 epoches
2020-03-23 16:08:18,156 - RBF - ERROR - loss 1.2984590418089206, in epoch 38, in step 199, in global step 19200, learning rate is 0.00015, taks 4.837800025939941 seconds
2020-03-23 16:08:21,376 - RBF - ERROR - loss 1.2984339402378124, in epoch 38, in step 399, in global step 19400, learning rate is 0.00015, taks 3.219399929046631 seconds
2020-03-23 16:08:22,976 - RBF - INFO - train epoch 39 of total 5000 epoches
2020-03-23 16:08:26,268 - RBF - ERROR - loss 1.2983987807445883, in epoch 39, in step 199, in global step 19700, learning rate is 0.00015, taks 4.891999959945679 seconds
2020-03-23 16:08:29,474 - RBF - ERROR - loss 1.2983749605687285, in epoch 39, in step 399, in global step 19900, learning rate is 0.00015, taks 3.206200122833252 seconds
2020-03-23 16:08:33,320 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 39. learning_rate is 0.00015, loss is 1.2983632900618256
2020-03-23 16:08:33,321 - RBF - INFO - train epoch 40 of total 5000 epoches
2020-03-23 16:08:39,648 - RBF - ERROR - loss 1.2983398695234267, in epoch 40, in step 199, in global step 20200, learning rate is 0.00015, taks 10.173799991607666 seconds
2020-03-23 16:08:45,762 - RBF - ERROR - loss 1.2983226332551445, in epoch 40, in step 399, in global step 20400, learning rate is 0.00015, taks 6.11460018157959 seconds
2020-03-23 16:08:48,529 - RBF - INFO - train epoch 41 of total 5000 epoches
2020-03-23 16:08:54,125 - RBF - ERROR - loss 1.298287238979233, in epoch 41, in step 199, in global step 20700, learning rate is 0.00015, taks 8.36299991607666 seconds
2020-03-23 16:08:59,707 - RBF - ERROR - loss 1.298261879337145, in epoch 41, in step 399, in global step 20900, learning rate is 0.00015, taks 5.580199956893921 seconds
2020-03-23 16:09:02,521 - RBF - INFO - train epoch 42 of total 5000 epoches
2020-03-23 16:09:08,078 - RBF - ERROR - loss 1.2982294346574361, in epoch 42, in step 199, in global step 21200, learning rate is 0.00015, taks 8.370599746704102 seconds
2020-03-23 16:09:13,696 - RBF - ERROR - loss 1.298208419419959, in epoch 42, in step 399, in global step 21400, learning rate is 0.00015, taks 5.6153998374938965 seconds
2020-03-23 16:09:16,466 - RBF - INFO - train epoch 43 of total 5000 epoches
2020-03-23 16:09:22,047 - RBF - ERROR - loss 1.2981796040714209, in epoch 43, in step 199, in global step 21700, learning rate is 0.00015, taks 8.3510000705719 seconds
2020-03-23 16:09:27,633 - RBF - ERROR - loss 1.298156172665666, in epoch 43, in step 399, in global step 21900, learning rate is 0.00015, taks 5.58679986000061 seconds
2020-03-23 16:09:30,402 - RBF - INFO - train epoch 44 of total 5000 epoches
2020-03-23 16:09:35,997 - RBF - ERROR - loss 1.298127808281663, in epoch 44, in step 199, in global step 22200, learning rate is 0.00015, taks 8.363400220870972 seconds
2020-03-23 16:09:41,574 - RBF - ERROR - loss 1.2981059473298673, in epoch 44, in step 399, in global step 22400, learning rate is 0.00015, taks 5.5757997035980225 seconds
2020-03-23 16:09:44,364 - RBF - INFO - train epoch 45 of total 5000 epoches
2020-03-23 16:09:49,983 - RBF - ERROR - loss 1.2980760378403728, in epoch 45, in step 199, in global step 22700, learning rate is 0.00015, taks 8.409199953079224 seconds
2020-03-23 16:09:55,548 - RBF - ERROR - loss 1.2980564708728923, in epoch 45, in step 399, in global step 22900, learning rate is 0.00015, taks 5.565000057220459 seconds
2020-03-23 16:09:58,362 - RBF - INFO - train epoch 46 of total 5000 epoches
2020-03-23 16:10:03,939 - RBF - ERROR - loss 1.298027152321097, in epoch 46, in step 199, in global step 23200, learning rate is 0.00015, taks 8.39140009880066 seconds
2020-03-23 16:10:09,531 - RBF - ERROR - loss 1.2980123819406262, in epoch 46, in step 399, in global step 23400, learning rate is 0.00015, taks 5.592200040817261 seconds
2020-03-23 16:10:12,312 - RBF - INFO - train epoch 47 of total 5000 epoches
2020-03-23 16:10:17,894 - RBF - ERROR - loss 1.2979884089068514, in epoch 47, in step 199, in global step 23700, learning rate is 0.00015, taks 8.361999750137329 seconds
2020-03-23 16:10:23,473 - RBF - ERROR - loss 1.2979598578009193, in epoch 47, in step 399, in global step 23900, learning rate is 0.00015, taks 5.578999757766724 seconds
2020-03-23 16:10:26,268 - RBF - INFO - train epoch 48 of total 5000 epoches
2020-03-23 16:10:31,856 - RBF - ERROR - loss 1.2979316771525882, in epoch 48, in step 199, in global step 24200, learning rate is 0.00015, taks 8.381400108337402 seconds
2020-03-23 16:10:37,447 - RBF - ERROR - loss 1.2979125983223154, in epoch 48, in step 399, in global step 24400, learning rate is 0.00015, taks 5.5908002853393555 seconds
2020-03-23 16:10:40,245 - RBF - INFO - train epoch 49 of total 5000 epoches
2020-03-23 16:10:45,885 - RBF - ERROR - loss 1.2978872968374193, in epoch 49, in step 199, in global step 24700, learning rate is 0.00015, taks 8.43839979171753 seconds
2020-03-23 16:10:51,466 - RBF - ERROR - loss 1.2978664121979875, in epoch 49, in step 399, in global step 24900, learning rate is 0.00015, taks 5.581400156021118 seconds
2020-03-23 16:10:54,276 - RBF - INFO - train epoch 50 of total 5000 epoches
2020-03-23 16:10:59,829 - RBF - ERROR - loss 1.2978416899329392, in epoch 50, in step 199, in global step 25200, learning rate is 0.00015, taks 8.362199783325195 seconds
2020-03-23 16:11:05,423 - RBF - ERROR - loss 1.297821080542401, in epoch 50, in step 399, in global step 25400, learning rate is 0.00015, taks 5.5933997631073 seconds
2020-03-23 16:11:08,227 - RBF - INFO - train epoch 51 of total 5000 epoches
2020-03-23 16:11:13,836 - RBF - ERROR - loss 1.2977938255088604, in epoch 51, in step 199, in global step 25700, learning rate is 0.00015, taks 8.412800073623657 seconds
2020-03-23 16:11:19,419 - RBF - ERROR - loss 1.2977847133023415, in epoch 51, in step 399, in global step 25900, learning rate is 0.00015, taks 5.583199977874756 seconds
2020-03-23 16:11:22,230 - RBF - INFO - train epoch 52 of total 5000 epoches
2020-03-23 16:11:27,803 - RBF - ERROR - loss 1.2977485856664654, in epoch 52, in step 199, in global step 26200, learning rate is 0.00015, taks 8.384000062942505 seconds
2020-03-23 16:11:33,375 - RBF - ERROR - loss 1.2977393699609694, in epoch 52, in step 399, in global step 26400, learning rate is 0.00015, taks 5.57099986076355 seconds
2020-03-23 16:11:36,179 - RBF - INFO - train epoch 53 of total 5000 epoches
2020-03-23 16:11:41,769 - RBF - ERROR - loss 1.2977104221571727, in epoch 53, in step 199, in global step 26700, learning rate is 0.00015, taks 8.393200159072876 seconds
2020-03-23 16:11:47,147 - RBF - ERROR - loss 1.2976891656473022, in epoch 53, in step 399, in global step 26900, learning rate is 0.00015, taks 5.377399921417236 seconds
2020-03-23 16:11:49,559 - RBF - INFO - train epoch 54 of total 5000 epoches
2020-03-23 16:11:54,391 - RBF - ERROR - loss 1.2976701950089407, in epoch 54, in step 199, in global step 27200, learning rate is 0.00015, taks 7.244600057601929 seconds
2020-03-23 16:11:59,199 - RBF - ERROR - loss 1.2976489309676222, in epoch 54, in step 399, in global step 27400, learning rate is 0.00015, taks 4.808000087738037 seconds
2020-03-23 16:12:01,627 - RBF - INFO - train epoch 55 of total 5000 epoches
2020-03-23 16:12:06,444 - RBF - ERROR - loss 1.2976194126536673, in epoch 55, in step 199, in global step 27700, learning rate is 0.00015, taks 7.244800090789795 seconds
2020-03-23 16:12:11,255 - RBF - ERROR - loss 1.2976024368699561, in epoch 55, in step 399, in global step 27900, learning rate is 0.00015, taks 4.811199903488159 seconds
2020-03-23 16:12:13,661 - RBF - INFO - train epoch 56 of total 5000 epoches
2020-03-23 16:12:18,476 - RBF - ERROR - loss 1.297577263109979, in epoch 56, in step 199, in global step 28200, learning rate is 0.00015, taks 7.2209999561309814 seconds
2020-03-23 16:12:23,288 - RBF - ERROR - loss 1.2975616545386364, in epoch 56, in step 399, in global step 28400, learning rate is 0.00015, taks 4.812199831008911 seconds
2020-03-23 16:12:25,793 - RBF - INFO - train epoch 57 of total 5000 epoches
2020-03-23 16:12:30,608 - RBF - ERROR - loss 1.2975352437168257, in epoch 57, in step 199, in global step 28700, learning rate is 0.00015, taks 7.3196001052856445 seconds
2020-03-23 16:12:35,389 - RBF - ERROR - loss 1.2975208299100418, in epoch 57, in step 399, in global step 28900, learning rate is 0.00015, taks 4.781400203704834 seconds
2020-03-23 16:12:37,793 - RBF - INFO - train epoch 58 of total 5000 epoches
2020-03-23 16:12:42,607 - RBF - ERROR - loss 1.2974939767290712, in epoch 58, in step 199, in global step 29200, learning rate is 0.00015, taks 7.217399835586548 seconds
2020-03-23 16:12:47,413 - RBF - ERROR - loss 1.2974765289886891, in epoch 58, in step 399, in global step 29400, learning rate is 0.00015, taks 4.805800199508667 seconds
2020-03-23 16:12:49,844 - RBF - INFO - train epoch 59 of total 5000 epoches
2020-03-23 16:12:54,648 - RBF - ERROR - loss 1.2974527975833625, in epoch 59, in step 199, in global step 29700, learning rate is 0.00015, taks 7.235799789428711 seconds
2020-03-23 16:12:59,477 - RBF - ERROR - loss 1.2974353688714548, in epoch 59, in step 399, in global step 29900, learning rate is 0.00015, taks 4.828200101852417 seconds
2020-03-23 16:13:04,186 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 59. learning_rate is 0.00015, loss is 1.2974315105554874
2020-03-23 16:13:04,186 - RBF - INFO - train epoch 60 of total 5000 epoches
2020-03-23 16:13:10,580 - RBF - ERROR - loss 1.2974176874752619, in epoch 60, in step 199, in global step 30200, learning rate is 0.00015, taks 11.103799819946289 seconds
2020-03-23 16:13:16,675 - RBF - ERROR - loss 1.2974000532787726, in epoch 60, in step 399, in global step 30400, learning rate is 0.00015, taks 6.0950000286102295 seconds
2020-03-23 16:13:19,735 - RBF - INFO - train epoch 61 of total 5000 epoches
2020-03-23 16:13:25,866 - RBF - ERROR - loss 1.2973695296361645, in epoch 61, in step 199, in global step 30700, learning rate is 0.00015, taks 9.19100022315979 seconds
2020-03-23 16:13:31,939 - RBF - ERROR - loss 1.2973528879245355, in epoch 61, in step 399, in global step 30900, learning rate is 0.00015, taks 6.072799921035767 seconds
2020-03-23 16:13:34,982 - RBF - INFO - train epoch 62 of total 5000 epoches
2020-03-23 16:13:41,091 - RBF - ERROR - loss 1.297341538481274, in epoch 62, in step 199, in global step 31200, learning rate is 0.00015, taks 9.152199983596802 seconds
2020-03-23 16:13:47,253 - RBF - ERROR - loss 1.2973167652450426, in epoch 62, in step 399, in global step 31400, learning rate is 0.00015, taks 6.160200119018555 seconds
2020-03-23 16:13:50,301 - RBF - INFO - train epoch 63 of total 5000 epoches
2020-03-23 16:13:56,379 - RBF - ERROR - loss 1.2972894878437597, in epoch 63, in step 199, in global step 31700, learning rate is 0.00015, taks 9.125199794769287 seconds
2020-03-23 16:14:02,515 - RBF - ERROR - loss 1.2972715949832476, in epoch 63, in step 399, in global step 31900, learning rate is 0.00015, taks 6.13640022277832 seconds
2020-03-23 16:14:05,575 - RBF - INFO - train epoch 64 of total 5000 epoches
2020-03-23 16:14:11,671 - RBF - ERROR - loss 1.2972491743156738, in epoch 64, in step 199, in global step 32200, learning rate is 0.00015, taks 9.156199932098389 seconds
2020-03-23 16:14:17,771 - RBF - ERROR - loss 1.2972355942546672, in epoch 64, in step 399, in global step 32400, learning rate is 0.00015, taks 6.098999977111816 seconds
2020-03-23 16:14:20,807 - RBF - INFO - train epoch 65 of total 5000 epoches
2020-03-23 16:14:26,923 - RBF - ERROR - loss 1.2972116599961698, in epoch 65, in step 199, in global step 32700, learning rate is 0.00015, taks 9.15120005607605 seconds
2020-03-23 16:14:33,036 - RBF - ERROR - loss 1.2971956066883028, in epoch 65, in step 399, in global step 32900, learning rate is 0.00015, taks 6.11240029335022 seconds
2020-03-23 16:14:36,087 - RBF - INFO - train epoch 66 of total 5000 epoches
2020-03-23 16:14:42,205 - RBF - ERROR - loss 1.2971735056173268, in epoch 66, in step 199, in global step 33200, learning rate is 0.00015, taks 9.168600082397461 seconds
2020-03-23 16:14:48,310 - RBF - ERROR - loss 1.2971618983128224, in epoch 66, in step 399, in global step 33400, learning rate is 0.00015, taks 6.105799913406372 seconds
2020-03-23 16:14:51,361 - RBF - INFO - train epoch 67 of total 5000 epoches
2020-03-23 16:14:57,485 - RBF - ERROR - loss 1.2971380468069948, in epoch 67, in step 199, in global step 33700, learning rate is 0.00015, taks 9.174999952316284 seconds
2020-03-23 16:15:03,623 - RBF - ERROR - loss 1.2971267189925408, in epoch 67, in step 399, in global step 33900, learning rate is 0.00015, taks 6.135800123214722 seconds
2020-03-23 16:15:06,031 - RBF - INFO - train epoch 68 of total 5000 epoches
2020-03-23 16:15:09,450 - RBF - ERROR - loss 1.2971240798281984, in epoch 68, in step 199, in global step 34200, learning rate is 0.00015, taks 5.827199935913086 seconds
2020-03-23 16:15:12,433 - RBF - ERROR - loss 1.2970897336161076, in epoch 68, in step 399, in global step 34400, learning rate is 0.00015, taks 2.982800006866455 seconds
2020-03-23 16:15:13,931 - RBF - INFO - train epoch 69 of total 5000 epoches
2020-03-23 16:15:16,928 - RBF - ERROR - loss 1.297081456399506, in epoch 69, in step 199, in global step 34700, learning rate is 0.00015, taks 4.494800090789795 seconds
2020-03-23 16:15:19,928 - RBF - ERROR - loss 1.297055985856854, in epoch 69, in step 399, in global step 34900, learning rate is 0.00015, taks 3.0003998279571533 seconds
2020-03-23 16:15:21,419 - RBF - INFO - train epoch 70 of total 5000 epoches
2020-03-23 16:15:24,419 - RBF - ERROR - loss 1.2970365533266766, in epoch 70, in step 199, in global step 35200, learning rate is 0.00015, taks 4.490800142288208 seconds
2020-03-23 16:15:27,418 - RBF - ERROR - loss 1.297024591648425, in epoch 70, in step 399, in global step 35400, learning rate is 0.00015, taks 2.9983999729156494 seconds
2020-03-23 16:15:28,909 - RBF - INFO - train epoch 71 of total 5000 epoches
2020-03-23 16:15:31,898 - RBF - ERROR - loss 1.2970063292873402, in epoch 71, in step 199, in global step 35700, learning rate is 0.00015, taks 4.480000019073486 seconds
2020-03-23 16:15:34,896 - RBF - ERROR - loss 1.2969924064717706, in epoch 71, in step 399, in global step 35900, learning rate is 0.00015, taks 2.9983999729156494 seconds
2020-03-23 16:15:36,395 - RBF - INFO - train epoch 72 of total 5000 epoches
2020-03-23 16:15:39,402 - RBF - ERROR - loss 1.296978376064543, in epoch 72, in step 199, in global step 36200, learning rate is 0.00015, taks 4.506200075149536 seconds
2020-03-23 16:15:42,396 - RBF - ERROR - loss 1.2969604392764225, in epoch 72, in step 399, in global step 36400, learning rate is 0.00015, taks 2.9933998584747314 seconds
2020-03-23 16:15:43,887 - RBF - INFO - train epoch 73 of total 5000 epoches
2020-03-23 16:15:46,895 - RBF - ERROR - loss 1.2969386984393558, in epoch 73, in step 199, in global step 36700, learning rate is 0.00015, taks 4.499000072479248 seconds
2020-03-23 16:15:49,915 - RBF - ERROR - loss 1.296927112986578, in epoch 73, in step 399, in global step 36900, learning rate is 0.00015, taks 3.020400047302246 seconds
2020-03-23 16:15:51,404 - RBF - INFO - train epoch 74 of total 5000 epoches
2020-03-23 16:15:54,396 - RBF - ERROR - loss 1.296908613131103, in epoch 74, in step 199, in global step 37200, learning rate is 0.00015, taks 4.4811999797821045 seconds
2020-03-23 16:15:57,400 - RBF - ERROR - loss 1.296909962185324, in epoch 74, in step 399, in global step 37400, learning rate is 0.00015, taks 3.0034000873565674 seconds
2020-03-23 16:15:58,887 - RBF - INFO - train epoch 75 of total 5000 epoches
2020-03-23 16:16:01,903 - RBF - ERROR - loss 1.2968881263841825, in epoch 75, in step 199, in global step 37700, learning rate is 0.00015, taks 4.503000020980835 seconds
2020-03-23 16:16:04,883 - RBF - ERROR - loss 1.2968819884310188, in epoch 75, in step 399, in global step 37900, learning rate is 0.00015, taks 2.9793999195098877 seconds
2020-03-23 16:16:06,382 - RBF - INFO - train epoch 76 of total 5000 epoches
2020-03-23 16:16:09,374 - RBF - ERROR - loss 1.2968531836286736, in epoch 76, in step 199, in global step 38200, learning rate is 0.00015, taks 4.491199970245361 seconds
2020-03-23 16:16:12,367 - RBF - ERROR - loss 1.2968459765884224, in epoch 76, in step 399, in global step 38400, learning rate is 0.00015, taks 2.9924001693725586 seconds
2020-03-23 16:16:13,867 - RBF - INFO - train epoch 77 of total 5000 epoches
2020-03-23 16:16:16,856 - RBF - ERROR - loss 1.2968443911671017, in epoch 77, in step 199, in global step 38700, learning rate is 0.00015, taks 4.489000082015991 seconds
2020-03-23 16:16:19,852 - RBF - ERROR - loss 1.2968191481345213, in epoch 77, in step 399, in global step 38900, learning rate is 0.00015, taks 2.9963998794555664 seconds
2020-03-23 16:16:21,344 - RBF - INFO - train epoch 78 of total 5000 epoches
2020-03-23 16:16:24,340 - RBF - ERROR - loss 1.2968014885601953, in epoch 78, in step 199, in global step 39200, learning rate is 0.00015, taks 4.487200021743774 seconds
2020-03-23 16:16:27,335 - RBF - ERROR - loss 1.2967983250688258, in epoch 78, in step 399, in global step 39400, learning rate is 0.00015, taks 2.9944000244140625 seconds
2020-03-23 16:16:28,828 - RBF - INFO - train epoch 79 of total 5000 epoches
2020-03-23 16:16:31,821 - RBF - ERROR - loss 1.296777747732565, in epoch 79, in step 199, in global step 39700, learning rate is 0.00015, taks 4.485999822616577 seconds
2020-03-23 16:16:34,823 - RBF - ERROR - loss 1.2967673957916754, in epoch 79, in step 399, in global step 39900, learning rate is 0.00015, taks 3.0013999938964844 seconds
2020-03-23 16:16:38,612 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 79. learning_rate is 0.00015, loss is 1.2967624751350915
2020-03-23 16:16:38,613 - RBF - INFO - train epoch 80 of total 5000 epoches
2020-03-23 16:16:45,550 - RBF - ERROR - loss 1.2967546798075271, in epoch 80, in step 199, in global step 40200, learning rate is 0.00015, taks 10.726999998092651 seconds
2020-03-23 16:16:51,659 - RBF - ERROR - loss 1.2967444272083197, in epoch 80, in step 399, in global step 40400, learning rate is 0.00015, taks 6.108800172805786 seconds
2020-03-23 16:16:54,692 - RBF - INFO - train epoch 81 of total 5000 epoches
2020-03-23 16:17:00,809 - RBF - ERROR - loss 1.296732825221036, in epoch 81, in step 199, in global step 40700, learning rate is 0.00015, taks 9.150399923324585 seconds
2020-03-23 16:17:06,920 - RBF - ERROR - loss 1.2967292430638646, in epoch 81, in step 399, in global step 40900, learning rate is 0.00015, taks 6.1112000942230225 seconds
2020-03-23 16:17:09,971 - RBF - INFO - train epoch 82 of total 5000 epoches
2020-03-23 16:17:16,082 - RBF - ERROR - loss 1.296709567213907, in epoch 82, in step 199, in global step 41200, learning rate is 0.00015, taks 9.16159987449646 seconds
2020-03-23 16:17:22,219 - RBF - ERROR - loss 1.2966999911397306, in epoch 82, in step 399, in global step 41400, learning rate is 0.00015, taks 6.13700008392334 seconds
2020-03-23 16:17:25,276 - RBF - INFO - train epoch 83 of total 5000 epoches
2020-03-23 16:17:31,393 - RBF - ERROR - loss 1.296689181188913, in epoch 83, in step 199, in global step 41700, learning rate is 0.00015, taks 9.174000024795532 seconds
2020-03-23 16:17:37,490 - RBF - ERROR - loss 1.2966776041837798, in epoch 83, in step 399, in global step 41900, learning rate is 0.00015, taks 6.096800088882446 seconds
2020-03-23 16:17:40,544 - RBF - INFO - train epoch 84 of total 5000 epoches
2020-03-23 16:17:46,682 - RBF - ERROR - loss 1.296670848986266, in epoch 84, in step 199, in global step 42200, learning rate is 0.00015, taks 9.19159984588623 seconds
2020-03-23 16:17:52,793 - RBF - ERROR - loss 1.2966589768500096, in epoch 84, in step 399, in global step 42400, learning rate is 0.00015, taks 6.109999895095825 seconds
2020-03-23 16:17:55,842 - RBF - INFO - train epoch 85 of total 5000 epoches
2020-03-23 16:18:01,984 - RBF - ERROR - loss 1.2966490201855314, in epoch 85, in step 199, in global step 42700, learning rate is 0.00015, taks 9.190200090408325 seconds
2020-03-23 16:18:08,086 - RBF - ERROR - loss 1.296645479711507, in epoch 85, in step 399, in global step 42900, learning rate is 0.00015, taks 6.101599931716919 seconds
2020-03-23 16:18:11,151 - RBF - INFO - train epoch 86 of total 5000 epoches
2020-03-23 16:18:17,261 - RBF - ERROR - loss 1.296626832612254, in epoch 86, in step 199, in global step 43200, learning rate is 0.00015, taks 9.174599885940552 seconds
2020-03-23 16:18:23,361 - RBF - ERROR - loss 1.2966182579976735, in epoch 86, in step 399, in global step 43400, learning rate is 0.00015, taks 6.099800109863281 seconds
2020-03-23 16:18:26,413 - RBF - INFO - train epoch 87 of total 5000 epoches
2020-03-23 16:18:32,518 - RBF - ERROR - loss 1.2966064142571403, in epoch 87, in step 199, in global step 43700, learning rate is 0.00015, taks 9.15720009803772 seconds
2020-03-23 16:18:38,635 - RBF - ERROR - loss 1.2965978821562967, in epoch 87, in step 399, in global step 43900, learning rate is 0.00015, taks 6.116199970245361 seconds
2020-03-23 16:18:41,684 - RBF - INFO - train epoch 88 of total 5000 epoches
2020-03-23 16:18:47,809 - RBF - ERROR - loss 1.2965862483611723, in epoch 88, in step 199, in global step 44200, learning rate is 0.00015, taks 9.174200057983398 seconds
2020-03-23 16:18:53,904 - RBF - ERROR - loss 1.2965792695688834, in epoch 88, in step 399, in global step 44400, learning rate is 0.00015, taks 6.094799757003784 seconds
2020-03-23 16:18:56,974 - RBF - INFO - train epoch 89 of total 5000 epoches
2020-03-23 16:19:03,175 - RBF - ERROR - loss 1.2965714154951804, in epoch 89, in step 199, in global step 44700, learning rate is 0.00015, taks 9.269800186157227 seconds
2020-03-23 16:19:09,290 - RBF - ERROR - loss 1.2965653193695594, in epoch 89, in step 399, in global step 44900, learning rate is 0.00015, taks 6.113999843597412 seconds
2020-03-23 16:19:12,339 - RBF - INFO - train epoch 90 of total 5000 epoches
2020-03-23 16:19:18,436 - RBF - ERROR - loss 1.2965549665537668, in epoch 90, in step 199, in global step 45200, learning rate is 0.00015, taks 9.146199703216553 seconds
2020-03-23 16:19:24,535 - RBF - ERROR - loss 1.2965484016485307, in epoch 90, in step 399, in global step 45400, learning rate is 0.00015, taks 6.099200010299683 seconds
2020-03-23 16:19:27,598 - RBF - INFO - train epoch 91 of total 5000 epoches
2020-03-23 16:19:33,710 - RBF - ERROR - loss 1.2965327891511385, in epoch 91, in step 199, in global step 45700, learning rate is 0.00015, taks 9.17520022392273 seconds
2020-03-23 16:19:39,810 - RBF - ERROR - loss 1.2965234894402549, in epoch 91, in step 399, in global step 45900, learning rate is 0.00015, taks 6.1000001430511475 seconds
2020-03-23 16:19:42,872 - RBF - INFO - train epoch 92 of total 5000 epoches
2020-03-23 16:19:48,995 - RBF - ERROR - loss 1.2965136658864205, in epoch 92, in step 199, in global step 46200, learning rate is 0.00015, taks 9.184999942779541 seconds
2020-03-23 16:19:55,124 - RBF - ERROR - loss 1.2965096812075652, in epoch 92, in step 399, in global step 46400, learning rate is 0.00015, taks 6.1285998821258545 seconds
2020-03-23 16:19:58,172 - RBF - INFO - train epoch 93 of total 5000 epoches
2020-03-23 16:20:04,285 - RBF - ERROR - loss 1.2964956963159013, in epoch 93, in step 199, in global step 46700, learning rate is 0.00015, taks 9.16100001335144 seconds
2020-03-23 16:20:10,393 - RBF - ERROR - loss 1.2964888342157577, in epoch 93, in step 399, in global step 46900, learning rate is 0.00015, taks 6.107800006866455 seconds
2020-03-23 16:20:13,451 - RBF - INFO - train epoch 94 of total 5000 epoches
2020-03-23 16:20:19,555 - RBF - ERROR - loss 1.296479166399001, in epoch 94, in step 199, in global step 47200, learning rate is 0.00015, taks 9.162199974060059 seconds
2020-03-23 16:20:25,686 - RBF - ERROR - loss 1.296471532572319, in epoch 94, in step 399, in global step 47400, learning rate is 0.00015, taks 6.130600214004517 seconds
2020-03-23 16:20:28,734 - RBF - INFO - train epoch 95 of total 5000 epoches
2020-03-23 16:20:34,869 - RBF - ERROR - loss 1.2964681485234928, in epoch 95, in step 199, in global step 47700, learning rate is 0.00015, taks 9.183199882507324 seconds
2020-03-23 16:20:40,955 - RBF - ERROR - loss 1.2964640339525972, in epoch 95, in step 399, in global step 47900, learning rate is 0.00015, taks 6.0848000049591064 seconds
2020-03-23 16:20:44,021 - RBF - INFO - train epoch 96 of total 5000 epoches
2020-03-23 16:20:50,173 - RBF - ERROR - loss 1.2964472954169126, in epoch 96, in step 199, in global step 48200, learning rate is 0.00015, taks 9.218400001525879 seconds
2020-03-23 16:20:56,254 - RBF - ERROR - loss 1.2964483944240277, in epoch 96, in step 399, in global step 48400, learning rate is 0.00015, taks 6.079999923706055 seconds
2020-03-23 16:20:59,330 - RBF - INFO - train epoch 97 of total 5000 epoches
2020-03-23 16:21:05,453 - RBF - ERROR - loss 1.2964275759763166, in epoch 97, in step 199, in global step 48700, learning rate is 0.00015, taks 9.199000120162964 seconds
2020-03-23 16:21:11,547 - RBF - ERROR - loss 1.2964201118748377, in epoch 97, in step 399, in global step 48900, learning rate is 0.00015, taks 6.094399929046631 seconds
2020-03-23 16:21:14,610 - RBF - INFO - train epoch 98 of total 5000 epoches
2020-03-23 16:21:20,742 - RBF - ERROR - loss 1.296421001994574, in epoch 98, in step 199, in global step 49200, learning rate is 0.00015, taks 9.193399906158447 seconds
2020-03-23 16:21:26,858 - RBF - ERROR - loss 1.2964038665322788, in epoch 98, in step 399, in global step 49400, learning rate is 0.00015, taks 6.115999937057495 seconds
2020-03-23 16:21:29,932 - RBF - INFO - train epoch 99 of total 5000 epoches
2020-03-23 16:21:36,012 - RBF - ERROR - loss 1.2964019683145145, in epoch 99, in step 199, in global step 49700, learning rate is 0.00015, taks 9.1528000831604 seconds
2020-03-23 16:21:42,141 - RBF - ERROR - loss 1.2963866323911657, in epoch 99, in step 399, in global step 49900, learning rate is 0.00015, taks 6.12820029258728 seconds
2020-03-23 16:21:47,508 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 99. learning_rate is 0.00015, loss is 1.2964039630301611
2020-03-23 16:21:47,508 - RBF - INFO - train epoch 100 of total 5000 epoches
2020-03-23 16:21:54,289 - RBF - ERROR - loss 1.296377776681208, in epoch 100, in step 199, in global step 50200, learning rate is 0.00015, taks 12.148399829864502 seconds
2020-03-23 16:22:00,415 - RBF - ERROR - loss 1.296381304257949, in epoch 100, in step 399, in global step 50400, learning rate is 0.00015, taks 6.125200033187866 seconds
2020-03-23 16:22:03,503 - RBF - INFO - train epoch 101 of total 5000 epoches
2020-03-23 16:22:09,655 - RBF - ERROR - loss 1.296361136868741, in epoch 101, in step 199, in global step 50700, learning rate is 0.00015, taks 9.239800214767456 seconds
2020-03-23 16:22:15,766 - RBF - ERROR - loss 1.296360639482338, in epoch 101, in step 399, in global step 50900, learning rate is 0.00015, taks 6.111199855804443 seconds
2020-03-23 16:22:18,840 - RBF - INFO - train epoch 102 of total 5000 epoches
2020-03-23 16:22:24,962 - RBF - ERROR - loss 1.2963451942326436, in epoch 102, in step 199, in global step 51200, learning rate is 0.00015, taks 9.195799827575684 seconds
2020-03-23 16:22:31,071 - RBF - ERROR - loss 1.2963461327608636, in epoch 102, in step 399, in global step 51400, learning rate is 0.00015, taks 6.107800006866455 seconds
2020-03-23 16:22:34,121 - RBF - INFO - train epoch 103 of total 5000 epoches
2020-03-23 16:22:40,221 - RBF - ERROR - loss 1.296339307929097, in epoch 103, in step 199, in global step 51700, learning rate is 0.00015, taks 9.148599624633789 seconds
2020-03-23 16:22:46,379 - RBF - ERROR - loss 1.2963209363929693, in epoch 103, in step 399, in global step 51900, learning rate is 0.00015, taks 6.157399892807007 seconds
2020-03-23 16:22:49,426 - RBF - INFO - train epoch 104 of total 5000 epoches
2020-03-23 16:22:55,526 - RBF - ERROR - loss 1.2963115593352408, in epoch 104, in step 199, in global step 52200, learning rate is 0.00015, taks 9.147000074386597 seconds
2020-03-23 16:23:01,681 - RBF - ERROR - loss 1.2963054655089226, in epoch 104, in step 399, in global step 52400, learning rate is 0.00015, taks 6.155400037765503 seconds
2020-03-23 16:23:04,712 - RBF - INFO - train epoch 105 of total 5000 epoches
2020-03-23 16:23:10,847 - RBF - ERROR - loss 1.2962969523299277, in epoch 105, in step 199, in global step 52700, learning rate is 0.00015, taks 9.165199995040894 seconds
2020-03-23 16:23:16,962 - RBF - ERROR - loss 1.2962892669052601, in epoch 105, in step 399, in global step 52900, learning rate is 0.00015, taks 6.115000009536743 seconds
2020-03-23 16:23:20,030 - RBF - INFO - train epoch 106 of total 5000 epoches
2020-03-23 16:23:26,155 - RBF - ERROR - loss 1.2962786733218454, in epoch 106, in step 199, in global step 53200, learning rate is 0.00015, taks 9.192199945449829 seconds
2020-03-23 16:23:32,282 - RBF - ERROR - loss 1.2962763527020076, in epoch 106, in step 399, in global step 53400, learning rate is 0.00015, taks 6.126000165939331 seconds
2020-03-23 16:23:35,353 - RBF - INFO - train epoch 107 of total 5000 epoches
2020-03-23 16:23:41,445 - RBF - ERROR - loss 1.2962669114154037, in epoch 107, in step 199, in global step 53700, learning rate is 0.00015, taks 9.163599967956543 seconds
2020-03-23 16:23:47,600 - RBF - ERROR - loss 1.2962586155074611, in epoch 107, in step 399, in global step 53900, learning rate is 0.00015, taks 6.15339994430542 seconds
2020-03-23 16:23:50,653 - RBF - INFO - train epoch 108 of total 5000 epoches
2020-03-23 16:23:56,774 - RBF - ERROR - loss 1.296269459434837, in epoch 108, in step 199, in global step 54200, learning rate is 0.00015, taks 9.174200534820557 seconds
2020-03-23 16:24:02,912 - RBF - ERROR - loss 1.2962460324627492, in epoch 108, in step 399, in global step 54400, learning rate is 0.00015, taks 6.1377997398376465 seconds
2020-03-23 16:24:05,964 - RBF - INFO - train epoch 109 of total 5000 epoches
2020-03-23 16:24:12,093 - RBF - ERROR - loss 1.2962502731713934, in epoch 109, in step 199, in global step 54700, learning rate is 0.00015, taks 9.1806001663208 seconds
2020-03-23 16:24:18,211 - RBF - ERROR - loss 1.2962258566867269, in epoch 109, in step 399, in global step 54900, learning rate is 0.00015, taks 6.117199897766113 seconds
2020-03-23 16:24:21,268 - RBF - INFO - train epoch 110 of total 5000 epoches
2020-03-23 16:24:27,378 - RBF - ERROR - loss 1.2962298183286534, in epoch 110, in step 199, in global step 55200, learning rate is 0.00015, taks 9.167799949645996 seconds
2020-03-23 16:24:33,487 - RBF - ERROR - loss 1.2962101592036148, in epoch 110, in step 399, in global step 55400, learning rate is 0.00015, taks 6.108400106430054 seconds
2020-03-23 16:24:36,537 - RBF - INFO - train epoch 111 of total 5000 epoches
2020-03-23 16:24:42,661 - RBF - ERROR - loss 1.2961992026536762, in epoch 111, in step 199, in global step 55700, learning rate is 0.00015, taks 9.174400091171265 seconds
2020-03-23 16:24:48,781 - RBF - ERROR - loss 1.2961930761411493, in epoch 111, in step 399, in global step 55900, learning rate is 0.00015, taks 6.119799852371216 seconds
2020-03-23 16:24:51,873 - RBF - INFO - train epoch 112 of total 5000 epoches
2020-03-23 16:24:57,989 - RBF - ERROR - loss 1.2961845683117967, in epoch 112, in step 199, in global step 56200, learning rate is 0.00015, taks 9.207200050354004 seconds
2020-03-23 16:25:04,119 - RBF - ERROR - loss 1.2961939511955807, in epoch 112, in step 399, in global step 56400, learning rate is 0.00015, taks 6.128799915313721 seconds
2020-03-23 16:25:07,153 - RBF - INFO - train epoch 113 of total 5000 epoches
2020-03-23 16:25:13,299 - RBF - ERROR - loss 1.2961710949847918, in epoch 113, in step 199, in global step 56700, learning rate is 0.00015, taks 9.18019986152649 seconds
2020-03-23 16:25:19,405 - RBF - ERROR - loss 1.2961663081107937, in epoch 113, in step 399, in global step 56900, learning rate is 0.00015, taks 6.104399919509888 seconds
2020-03-23 16:25:22,435 - RBF - INFO - train epoch 114 of total 5000 epoches
2020-03-23 16:25:28,582 - RBF - ERROR - loss 1.2961672346233102, in epoch 114, in step 199, in global step 57200, learning rate is 0.00015, taks 9.177000045776367 seconds
2020-03-23 16:25:34,717 - RBF - ERROR - loss 1.2961453626109993, in epoch 114, in step 399, in global step 57400, learning rate is 0.00015, taks 6.135800123214722 seconds
2020-03-23 16:25:37,777 - RBF - INFO - train epoch 115 of total 5000 epoches
2020-03-23 16:25:43,874 - RBF - ERROR - loss 1.2961361086347334, in epoch 115, in step 199, in global step 57700, learning rate is 0.00015, taks 9.15560007095337 seconds
2020-03-23 16:25:49,740 - RBF - ERROR - loss 1.2961371190565798, in epoch 115, in step 399, in global step 57900, learning rate is 0.00015, taks 5.865999937057495 seconds
2020-03-23 16:25:52,518 - RBF - INFO - train epoch 116 of total 5000 epoches
2020-03-23 16:25:58,123 - RBF - ERROR - loss 1.2961203482661385, in epoch 116, in step 199, in global step 58200, learning rate is 0.00015, taks 8.382599830627441 seconds
2020-03-23 16:26:03,727 - RBF - ERROR - loss 1.2961145291634644, in epoch 116, in step 399, in global step 58400, learning rate is 0.00015, taks 5.60479998588562 seconds
2020-03-23 16:26:06,527 - RBF - INFO - train epoch 117 of total 5000 epoches
2020-03-23 16:26:12,117 - RBF - ERROR - loss 1.2961091104018658, in epoch 117, in step 199, in global step 58700, learning rate is 0.00015, taks 8.389800310134888 seconds
2020-03-23 16:26:17,740 - RBF - ERROR - loss 1.2961126466774102, in epoch 117, in step 399, in global step 58900, learning rate is 0.00015, taks 5.622799873352051 seconds
2020-03-23 16:26:20,514 - RBF - INFO - train epoch 118 of total 5000 epoches
2020-03-23 16:26:26,105 - RBF - ERROR - loss 1.296098551583394, in epoch 118, in step 199, in global step 59200, learning rate is 0.00015, taks 8.362600088119507 seconds
2020-03-23 16:26:31,697 - RBF - ERROR - loss 1.2960949582743029, in epoch 118, in step 399, in global step 59400, learning rate is 0.00015, taks 5.592800140380859 seconds
2020-03-23 16:26:34,494 - RBF - INFO - train epoch 119 of total 5000 epoches
2020-03-23 16:26:40,087 - RBF - ERROR - loss 1.2960881763495546, in epoch 119, in step 199, in global step 59700, learning rate is 0.00015, taks 8.388400077819824 seconds
2020-03-23 16:26:45,664 - RBF - ERROR - loss 1.2960690563085537, in epoch 119, in step 399, in global step 59900, learning rate is 0.00015, taks 5.576399803161621 seconds
2020-03-23 16:26:50,980 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 119. learning_rate is 0.00015, loss is 1.296072989332353
2020-03-23 16:26:50,981 - RBF - INFO - train epoch 120 of total 5000 epoches
2020-03-23 16:26:57,386 - RBF - ERROR - loss 1.2960587166553894, in epoch 120, in step 199, in global step 60200, learning rate is 0.00015, taks 11.722000122070312 seconds
2020-03-23 16:27:03,509 - RBF - ERROR - loss 1.296051446784794, in epoch 120, in step 399, in global step 60400, learning rate is 0.00015, taks 6.123000144958496 seconds
2020-03-23 16:27:06,561 - RBF - INFO - train epoch 121 of total 5000 epoches
2020-03-23 16:27:12,644 - RBF - ERROR - loss 1.2960419573409458, in epoch 121, in step 199, in global step 60700, learning rate is 0.00015, taks 9.134599924087524 seconds
2020-03-23 16:27:18,752 - RBF - ERROR - loss 1.2960360457448108, in epoch 121, in step 399, in global step 60900, learning rate is 0.00015, taks 6.106800079345703 seconds
2020-03-23 16:27:21,820 - RBF - INFO - train epoch 122 of total 5000 epoches
2020-03-23 16:27:27,918 - RBF - ERROR - loss 1.296027561859884, in epoch 122, in step 199, in global step 61200, learning rate is 0.00015, taks 9.164999961853027 seconds
2020-03-23 16:27:34,031 - RBF - ERROR - loss 1.296021430152334, in epoch 122, in step 399, in global step 61400, learning rate is 0.00015, taks 6.1132001876831055 seconds
2020-03-23 16:27:37,084 - RBF - INFO - train epoch 123 of total 5000 epoches
2020-03-23 16:27:43,181 - RBF - ERROR - loss 1.296017601921003, in epoch 123, in step 199, in global step 61700, learning rate is 0.00015, taks 9.15019965171814 seconds
2020-03-23 16:27:49,345 - RBF - ERROR - loss 1.2960050943783143, in epoch 123, in step 399, in global step 61900, learning rate is 0.00015, taks 6.1631999015808105 seconds
2020-03-23 16:27:52,391 - RBF - INFO - train epoch 124 of total 5000 epoches
2020-03-23 16:27:58,527 - RBF - ERROR - loss 1.295996442211328, in epoch 124, in step 199, in global step 62200, learning rate is 0.00015, taks 9.180999994277954 seconds
2020-03-23 16:28:04,650 - RBF - ERROR - loss 1.2959899302458318, in epoch 124, in step 399, in global step 62400, learning rate is 0.00015, taks 6.121800184249878 seconds
2020-03-23 16:28:07,719 - RBF - INFO - train epoch 125 of total 5000 epoches
2020-03-23 16:28:13,830 - RBF - ERROR - loss 1.2959809180905835, in epoch 125, in step 199, in global step 62700, learning rate is 0.00015, taks 9.180000066757202 seconds
2020-03-23 16:28:19,922 - RBF - ERROR - loss 1.295977063338999, in epoch 125, in step 399, in global step 62900, learning rate is 0.00015, taks 6.090199947357178 seconds
2020-03-23 16:28:22,976 - RBF - INFO - train epoch 126 of total 5000 epoches
2020-03-23 16:28:29,108 - RBF - ERROR - loss 1.2959679167051597, in epoch 126, in step 199, in global step 63200, learning rate is 0.00015, taks 9.186000108718872 seconds
2020-03-23 16:28:35,207 - RBF - ERROR - loss 1.2959604881799804, in epoch 126, in step 399, in global step 63400, learning rate is 0.00015, taks 6.097599983215332 seconds
2020-03-23 16:28:38,275 - RBF - INFO - train epoch 127 of total 5000 epoches
2020-03-23 16:28:44,363 - RBF - ERROR - loss 1.2959503930740401, in epoch 127, in step 199, in global step 63700, learning rate is 0.00015, taks 9.155400037765503 seconds
2020-03-23 16:28:50,543 - RBF - ERROR - loss 1.2959459583069532, in epoch 127, in step 399, in global step 63900, learning rate is 0.00015, taks 6.180000066757202 seconds
2020-03-23 16:28:53,598 - RBF - INFO - train epoch 128 of total 5000 epoches
2020-03-23 16:28:59,724 - RBF - ERROR - loss 1.2959350524138524, in epoch 128, in step 199, in global step 64200, learning rate is 0.00015, taks 9.180599927902222 seconds
2020-03-23 16:29:05,861 - RBF - ERROR - loss 1.295928248663957, in epoch 128, in step 399, in global step 64400, learning rate is 0.00015, taks 6.136000156402588 seconds
2020-03-23 16:29:08,900 - RBF - INFO - train epoch 129 of total 5000 epoches
2020-03-23 16:29:15,021 - RBF - ERROR - loss 1.2959189195853913, in epoch 129, in step 199, in global step 64700, learning rate is 0.00015, taks 9.15999984741211 seconds
2020-03-23 16:29:21,134 - RBF - ERROR - loss 1.2959123214809312, in epoch 129, in step 399, in global step 64900, learning rate is 0.00015, taks 6.111799955368042 seconds
2020-03-23 16:29:24,195 - RBF - INFO - train epoch 130 of total 5000 epoches
2020-03-23 16:29:30,287 - RBF - ERROR - loss 1.2959032419246808, in epoch 130, in step 199, in global step 65200, learning rate is 0.00015, taks 9.15339994430542 seconds
2020-03-23 16:29:36,389 - RBF - ERROR - loss 1.2958988953885784, in epoch 130, in step 399, in global step 65400, learning rate is 0.00015, taks 6.102400064468384 seconds
2020-03-23 16:29:39,448 - RBF - INFO - train epoch 131 of total 5000 epoches
2020-03-23 16:29:45,587 - RBF - ERROR - loss 1.295891236532918, in epoch 131, in step 199, in global step 65700, learning rate is 0.00015, taks 9.198000192642212 seconds
2020-03-23 16:29:51,737 - RBF - ERROR - loss 1.2958974108685692, in epoch 131, in step 399, in global step 65900, learning rate is 0.00015, taks 6.148799896240234 seconds
2020-03-23 16:29:54,809 - RBF - INFO - train epoch 132 of total 5000 epoches
2020-03-23 16:30:00,887 - RBF - ERROR - loss 1.2958950523910675, in epoch 132, in step 199, in global step 66200, learning rate is 0.00015, taks 9.1496000289917 seconds
2020-03-23 16:30:07,014 - RBF - ERROR - loss 1.2958671303186842, in epoch 132, in step 399, in global step 66400, learning rate is 0.00015, taks 6.127200126647949 seconds
2020-03-23 16:30:10,061 - RBF - INFO - train epoch 133 of total 5000 epoches
2020-03-23 16:30:16,159 - RBF - ERROR - loss 1.2958571200530111, in epoch 133, in step 199, in global step 66700, learning rate is 0.00015, taks 9.145400047302246 seconds
2020-03-23 16:30:22,258 - RBF - ERROR - loss 1.295851155037767, in epoch 133, in step 399, in global step 66900, learning rate is 0.00015, taks 6.097799777984619 seconds
2020-03-23 16:30:25,317 - RBF - INFO - train epoch 134 of total 5000 epoches
2020-03-23 16:30:31,439 - RBF - ERROR - loss 1.2958421210934308, in epoch 134, in step 199, in global step 67200, learning rate is 0.00015, taks 9.180999994277954 seconds
2020-03-23 16:30:37,533 - RBF - ERROR - loss 1.2958414310429816, in epoch 134, in step 399, in global step 67400, learning rate is 0.00015, taks 6.0940001010894775 seconds
2020-03-23 16:30:40,600 - RBF - INFO - train epoch 135 of total 5000 epoches
2020-03-23 16:30:46,751 - RBF - ERROR - loss 1.2958263204376606, in epoch 135, in step 199, in global step 67700, learning rate is 0.00015, taks 9.217999935150146 seconds
2020-03-23 16:30:52,870 - RBF - ERROR - loss 1.2958195901299685, in epoch 135, in step 399, in global step 67900, learning rate is 0.00015, taks 6.118800163269043 seconds
2020-03-23 16:30:55,920 - RBF - INFO - train epoch 136 of total 5000 epoches
2020-03-23 16:31:02,071 - RBF - ERROR - loss 1.2958097950277776, in epoch 136, in step 199, in global step 68200, learning rate is 0.00015, taks 9.200799942016602 seconds
2020-03-23 16:31:08,191 - RBF - ERROR - loss 1.2958052394903925, in epoch 136, in step 399, in global step 68400, learning rate is 0.00015, taks 6.118799924850464 seconds
2020-03-23 16:31:11,229 - RBF - INFO - train epoch 137 of total 5000 epoches
2020-03-23 16:31:17,359 - RBF - ERROR - loss 1.2957953249561107, in epoch 137, in step 199, in global step 68700, learning rate is 0.00015, taks 9.168200016021729 seconds
2020-03-23 16:31:23,476 - RBF - ERROR - loss 1.295788538466265, in epoch 137, in step 399, in global step 68900, learning rate is 0.00015, taks 6.115999937057495 seconds
2020-03-23 16:31:26,534 - RBF - INFO - train epoch 138 of total 5000 epoches
2020-03-23 16:31:32,636 - RBF - ERROR - loss 1.2957784341272263, in epoch 138, in step 199, in global step 69200, learning rate is 0.00015, taks 9.15939998626709 seconds
2020-03-23 16:31:38,752 - RBF - ERROR - loss 1.2957721023400475, in epoch 138, in step 399, in global step 69400, learning rate is 0.00015, taks 6.115999937057495 seconds
2020-03-23 16:31:41,802 - RBF - INFO - train epoch 139 of total 5000 epoches
2020-03-23 16:31:47,950 - RBF - ERROR - loss 1.295789059790312, in epoch 139, in step 199, in global step 69700, learning rate is 0.00015, taks 9.197399854660034 seconds
2020-03-23 16:31:54,095 - RBF - ERROR - loss 1.2957614327713551, in epoch 139, in step 399, in global step 69900, learning rate is 0.00015, taks 6.145400047302246 seconds
2020-03-23 16:31:59,352 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 139. learning_rate is 0.00015, loss is 1.2957552371413836
2020-03-23 16:31:59,352 - RBF - INFO - train epoch 140 of total 5000 epoches
2020-03-23 16:32:05,728 - RBF - ERROR - loss 1.2957478111004415, in epoch 140, in step 199, in global step 70200, learning rate is 0.00015, taks 11.632400035858154 seconds
2020-03-23 16:32:11,829 - RBF - ERROR - loss 1.2957408766021994, in epoch 140, in step 399, in global step 70400, learning rate is 0.00015, taks 6.100800037384033 seconds
2020-03-23 16:32:14,896 - RBF - INFO - train epoch 141 of total 5000 epoches
2020-03-23 16:32:21,008 - RBF - ERROR - loss 1.2957339228098983, in epoch 141, in step 199, in global step 70700, learning rate is 0.00015, taks 9.179199934005737 seconds
2020-03-23 16:32:27,106 - RBF - ERROR - loss 1.2957354862249104, in epoch 141, in step 399, in global step 70900, learning rate is 0.00015, taks 6.0971999168396 seconds
2020-03-23 16:32:30,166 - RBF - INFO - train epoch 142 of total 5000 epoches
2020-03-23 16:32:36,282 - RBF - ERROR - loss 1.2957147607520765, in epoch 142, in step 199, in global step 71200, learning rate is 0.00015, taks 9.17519998550415 seconds
2020-03-23 16:32:42,398 - RBF - ERROR - loss 1.295712668202363, in epoch 142, in step 399, in global step 71400, learning rate is 0.00015, taks 6.1164000034332275 seconds
2020-03-23 16:32:45,438 - RBF - INFO - train epoch 143 of total 5000 epoches
2020-03-23 16:32:51,573 - RBF - ERROR - loss 1.295716445647364, in epoch 143, in step 199, in global step 71700, learning rate is 0.00015, taks 9.174200057983398 seconds
2020-03-23 16:32:57,709 - RBF - ERROR - loss 1.2956950658661048, in epoch 143, in step 399, in global step 71900, learning rate is 0.00015, taks 6.135800123214722 seconds
2020-03-23 16:33:00,732 - RBF - INFO - train epoch 144 of total 5000 epoches
2020-03-23 16:33:06,855 - RBF - ERROR - loss 1.295682968334336, in epoch 144, in step 199, in global step 72200, learning rate is 0.00015, taks 9.14520001411438 seconds
2020-03-23 16:33:12,942 - RBF - ERROR - loss 1.2957210478143877, in epoch 144, in step 399, in global step 72400, learning rate is 0.00015, taks 6.086199760437012 seconds
2020-03-23 16:33:16,014 - RBF - INFO - train epoch 145 of total 5000 epoches
2020-03-23 16:33:22,104 - RBF - ERROR - loss 1.2956671440221943, in epoch 145, in step 199, in global step 72700, learning rate is 0.00015, taks 9.16260027885437 seconds
2020-03-23 16:33:28,202 - RBF - ERROR - loss 1.2956650964769245, in epoch 145, in step 399, in global step 72900, learning rate is 0.00015, taks 6.097399711608887 seconds
2020-03-23 16:33:31,248 - RBF - INFO - train epoch 146 of total 5000 epoches
2020-03-23 16:33:37,354 - RBF - ERROR - loss 1.2956508121532573, in epoch 146, in step 199, in global step 73200, learning rate is 0.00015, taks 9.15220022201538 seconds
2020-03-23 16:33:43,458 - RBF - ERROR - loss 1.295652370113816, in epoch 146, in step 399, in global step 73400, learning rate is 0.00015, taks 6.103400230407715 seconds
2020-03-23 16:33:46,496 - RBF - INFO - train epoch 147 of total 5000 epoches
2020-03-23 16:33:52,638 - RBF - ERROR - loss 1.2956362210075305, in epoch 147, in step 199, in global step 73700, learning rate is 0.00015, taks 9.179799795150757 seconds
2020-03-23 16:33:58,741 - RBF - ERROR - loss 1.2956279654540734, in epoch 147, in step 399, in global step 73900, learning rate is 0.00015, taks 6.103000164031982 seconds
2020-03-23 16:34:01,830 - RBF - INFO - train epoch 148 of total 5000 epoches
2020-03-23 16:34:07,941 - RBF - ERROR - loss 1.2956186070926767, in epoch 148, in step 199, in global step 74200, learning rate is 0.00015, taks 9.200199842453003 seconds
2020-03-23 16:34:14,048 - RBF - ERROR - loss 1.295612234389594, in epoch 148, in step 399, in global step 74400, learning rate is 0.00015, taks 6.1072001457214355 seconds
2020-03-23 16:34:17,085 - RBF - INFO - train epoch 149 of total 5000 epoches
2020-03-23 16:34:23,205 - RBF - ERROR - loss 1.2956026737532413, in epoch 149, in step 199, in global step 74700, learning rate is 0.00015, taks 9.15559983253479 seconds
2020-03-23 16:34:29,281 - RBF - ERROR - loss 1.2956025936386364, in epoch 149, in step 399, in global step 74900, learning rate is 0.00015, taks 6.076200008392334 seconds
2020-03-23 16:34:32,333 - RBF - INFO - train epoch 150 of total 5000 epoches
2020-03-23 16:34:38,455 - RBF - ERROR - loss 1.2956090336566477, in epoch 150, in step 199, in global step 75200, learning rate is 0.00015, taks 9.172799825668335 seconds
2020-03-23 16:34:44,554 - RBF - ERROR - loss 1.2955828659555444, in epoch 150, in step 399, in global step 75400, learning rate is 0.00015, taks 6.09879994392395 seconds
2020-03-23 16:34:47,647 - RBF - INFO - train epoch 151 of total 5000 epoches
2020-03-23 16:34:53,790 - RBF - ERROR - loss 1.295575333463922, in epoch 151, in step 199, in global step 75700, learning rate is 0.00015, taks 9.235400199890137 seconds
2020-03-23 16:34:59,907 - RBF - ERROR - loss 1.2955671188424065, in epoch 151, in step 399, in global step 75900, learning rate is 0.00015, taks 6.117199897766113 seconds
2020-03-23 16:35:02,955 - RBF - INFO - train epoch 152 of total 5000 epoches
2020-03-23 16:35:09,052 - RBF - ERROR - loss 1.2955555767744078, in epoch 152, in step 199, in global step 76200, learning rate is 0.00015, taks 9.144199848175049 seconds
2020-03-23 16:35:15,162 - RBF - ERROR - loss 1.2955505894975834, in epoch 152, in step 399, in global step 76400, learning rate is 0.00015, taks 6.110400199890137 seconds
2020-03-23 16:35:18,198 - RBF - INFO - train epoch 153 of total 5000 epoches
2020-03-23 16:35:24,316 - RBF - ERROR - loss 1.2955650582262654, in epoch 153, in step 199, in global step 76700, learning rate is 0.00015, taks 9.152999877929688 seconds
2020-03-23 16:35:30,422 - RBF - ERROR - loss 1.2955347036943516, in epoch 153, in step 399, in global step 76900, learning rate is 0.00015, taks 6.106400012969971 seconds
2020-03-23 16:35:33,461 - RBF - INFO - train epoch 154 of total 5000 epoches
2020-03-23 16:35:39,557 - RBF - ERROR - loss 1.2955266378318788, in epoch 154, in step 199, in global step 77200, learning rate is 0.00015, taks 9.134200096130371 seconds
2020-03-23 16:35:45,661 - RBF - ERROR - loss 1.2955163342940959, in epoch 154, in step 399, in global step 77400, learning rate is 0.00015, taks 6.10479998588562 seconds
2020-03-23 16:35:48,750 - RBF - INFO - train epoch 155 of total 5000 epoches
2020-03-23 16:35:54,849 - RBF - ERROR - loss 1.295526665921695, in epoch 155, in step 199, in global step 77700, learning rate is 0.00015, taks 9.187599897384644 seconds
2020-03-23 16:36:00,952 - RBF - ERROR - loss 1.2955112336811494, in epoch 155, in step 399, in global step 77900, learning rate is 0.00015, taks 6.102800130844116 seconds
2020-03-23 16:36:04,025 - RBF - INFO - train epoch 156 of total 5000 epoches
2020-03-23 16:36:10,145 - RBF - ERROR - loss 1.2954939459595736, in epoch 156, in step 199, in global step 78200, learning rate is 0.00015, taks 9.192799806594849 seconds
2020-03-23 16:36:16,228 - RBF - ERROR - loss 1.2954874698164398, in epoch 156, in step 399, in global step 78400, learning rate is 0.00015, taks 6.083200216293335 seconds
2020-03-23 16:36:19,312 - RBF - INFO - train epoch 157 of total 5000 epoches
2020-03-23 16:36:25,399 - RBF - ERROR - loss 1.2954781211020858, in epoch 157, in step 199, in global step 78700, learning rate is 0.00015, taks 9.171199798583984 seconds
2020-03-23 16:36:31,503 - RBF - ERROR - loss 1.29547579147092, in epoch 157, in step 399, in global step 78900, learning rate is 0.00015, taks 6.103000164031982 seconds
2020-03-23 16:36:34,567 - RBF - INFO - train epoch 158 of total 5000 epoches
2020-03-23 16:36:40,685 - RBF - ERROR - loss 1.2954642193644483, in epoch 158, in step 199, in global step 79200, learning rate is 0.00015, taks 9.182399988174438 seconds
2020-03-23 16:36:46,841 - RBF - ERROR - loss 1.2954537999815814, in epoch 158, in step 399, in global step 79400, learning rate is 0.00015, taks 6.155799865722656 seconds
2020-03-23 16:36:49,955 - RBF - INFO - train epoch 159 of total 5000 epoches
2020-03-23 16:36:56,057 - RBF - ERROR - loss 1.2954558060532146, in epoch 159, in step 199, in global step 79700, learning rate is 0.00015, taks 9.216200113296509 seconds
2020-03-23 16:37:02,184 - RBF - ERROR - loss 1.295437411416287, in epoch 159, in step 399, in global step 79900, learning rate is 0.00015, taks 6.125999927520752 seconds
2020-03-23 16:37:07,541 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 159. learning_rate is 0.00015, loss is 1.2954389432403648
2020-03-23 16:37:07,542 - RBF - INFO - train epoch 160 of total 5000 epoches
2020-03-23 16:37:14,280 - RBF - ERROR - loss 1.2954380626265458, in epoch 160, in step 199, in global step 80200, learning rate is 0.00015, taks 12.095999956130981 seconds
2020-03-23 16:37:20,398 - RBF - ERROR - loss 1.295422349248701, in epoch 160, in step 399, in global step 80400, learning rate is 0.00015, taks 6.118000268936157 seconds
2020-03-23 16:37:23,446 - RBF - INFO - train epoch 161 of total 5000 epoches
2020-03-23 16:37:29,568 - RBF - ERROR - loss 1.2954136579068254, in epoch 161, in step 199, in global step 80700, learning rate is 0.00015, taks 9.168800115585327 seconds
2020-03-23 16:37:35,679 - RBF - ERROR - loss 1.2954126832921382, in epoch 161, in step 399, in global step 80900, learning rate is 0.00015, taks 6.110599994659424 seconds
2020-03-23 16:37:38,732 - RBF - INFO - train epoch 162 of total 5000 epoches
2020-03-23 16:37:44,824 - RBF - ERROR - loss 1.295398659324968, in epoch 162, in step 199, in global step 81200, learning rate is 0.00015, taks 9.1451997756958 seconds
2020-03-23 16:37:50,969 - RBF - ERROR - loss 1.2954218322447915, in epoch 162, in step 399, in global step 81400, learning rate is 0.00015, taks 6.144800186157227 seconds
2020-03-23 16:37:54,011 - RBF - INFO - train epoch 163 of total 5000 epoches
2020-03-23 16:38:00,122 - RBF - ERROR - loss 1.295386512449545, in epoch 163, in step 199, in global step 81700, learning rate is 0.00015, taks 9.151999950408936 seconds
2020-03-23 16:38:06,248 - RBF - ERROR - loss 1.295378680990799, in epoch 163, in step 399, in global step 81900, learning rate is 0.00015, taks 6.126399993896484 seconds
2020-03-23 16:38:09,298 - RBF - INFO - train epoch 164 of total 5000 epoches
2020-03-23 16:38:15,384 - RBF - ERROR - loss 1.2953748476276532, in epoch 164, in step 199, in global step 82200, learning rate is 0.00015, taks 9.135599851608276 seconds
2020-03-23 16:38:21,524 - RBF - ERROR - loss 1.2953667823174444, in epoch 164, in step 399, in global step 82400, learning rate is 0.00015, taks 6.140199899673462 seconds
2020-03-23 16:38:24,556 - RBF - INFO - train epoch 165 of total 5000 epoches
2020-03-23 16:38:30,699 - RBF - ERROR - loss 1.295363915452772, in epoch 165, in step 199, in global step 82700, learning rate is 0.00015, taks 9.175000190734863 seconds
2020-03-23 16:38:36,788 - RBF - ERROR - loss 1.2953494939129964, in epoch 165, in step 399, in global step 82900, learning rate is 0.00015, taks 6.088199853897095 seconds
2020-03-23 16:38:39,855 - RBF - INFO - train epoch 166 of total 5000 epoches
2020-03-23 16:38:45,974 - RBF - ERROR - loss 1.295341633259507, in epoch 166, in step 199, in global step 83200, learning rate is 0.00015, taks 9.185400009155273 seconds
2020-03-23 16:38:52,124 - RBF - ERROR - loss 1.2953367878410207, in epoch 166, in step 399, in global step 83400, learning rate is 0.00015, taks 6.148999929428101 seconds
2020-03-23 16:38:55,183 - RBF - INFO - train epoch 167 of total 5000 epoches
2020-03-23 16:39:01,279 - RBF - ERROR - loss 1.2953262230226756, in epoch 167, in step 199, in global step 83700, learning rate is 0.00015, taks 9.154200077056885 seconds
2020-03-23 16:39:07,395 - RBF - ERROR - loss 1.2953210774366206, in epoch 167, in step 399, in global step 83900, learning rate is 0.00015, taks 6.115799903869629 seconds
2020-03-23 16:39:10,441 - RBF - INFO - train epoch 168 of total 5000 epoches
2020-03-23 16:39:16,555 - RBF - ERROR - loss 1.2953193107138392, in epoch 168, in step 199, in global step 84200, learning rate is 0.00015, taks 9.159599781036377 seconds
2020-03-23 16:39:22,675 - RBF - ERROR - loss 1.2953085815733578, in epoch 168, in step 399, in global step 84400, learning rate is 0.00015, taks 6.1192004680633545 seconds
2020-03-23 16:39:25,736 - RBF - INFO - train epoch 169 of total 5000 epoches
2020-03-23 16:39:31,851 - RBF - ERROR - loss 1.2952988487878823, in epoch 169, in step 199, in global step 84700, learning rate is 0.00015, taks 9.174399852752686 seconds
2020-03-23 16:39:37,970 - RBF - ERROR - loss 1.2953080723039847, in epoch 169, in step 399, in global step 84900, learning rate is 0.00015, taks 6.119000196456909 seconds
2020-03-23 16:39:41,005 - RBF - INFO - train epoch 170 of total 5000 epoches
2020-03-23 16:39:47,133 - RBF - ERROR - loss 1.2952842441992087, in epoch 170, in step 199, in global step 85200, learning rate is 0.00015, taks 9.162999629974365 seconds
2020-03-23 16:39:53,254 - RBF - ERROR - loss 1.295279404952997, in epoch 170, in step 399, in global step 85400, learning rate is 0.00015, taks 6.1202003955841064 seconds
2020-03-23 16:39:56,324 - RBF - INFO - train epoch 171 of total 5000 epoches
2020-03-23 16:40:02,442 - RBF - ERROR - loss 1.2952697376851172, in epoch 171, in step 199, in global step 85700, learning rate is 0.00015, taks 9.186999797821045 seconds
2020-03-23 16:40:08,549 - RBF - ERROR - loss 1.2952645493050325, in epoch 171, in step 399, in global step 85900, learning rate is 0.00015, taks 6.1071999073028564 seconds
2020-03-23 16:40:11,610 - RBF - INFO - train epoch 172 of total 5000 epoches
2020-03-23 16:40:17,745 - RBF - ERROR - loss 1.2952598364224213, in epoch 172, in step 199, in global step 86200, learning rate is 0.00015, taks 9.196199893951416 seconds
2020-03-23 16:40:23,850 - RBF - ERROR - loss 1.295251179166899, in epoch 172, in step 399, in global step 86400, learning rate is 0.00015, taks 6.105000019073486 seconds
2020-03-23 16:40:26,888 - RBF - INFO - train epoch 173 of total 5000 epoches
2020-03-23 16:40:32,996 - RBF - ERROR - loss 1.295243267216, in epoch 173, in step 199, in global step 86700, learning rate is 0.00015, taks 9.1457998752594 seconds
2020-03-23 16:40:39,123 - RBF - ERROR - loss 1.2952464099756107, in epoch 173, in step 399, in global step 86900, learning rate is 0.00015, taks 6.125799894332886 seconds
2020-03-23 16:40:42,185 - RBF - INFO - train epoch 174 of total 5000 epoches
2020-03-23 16:40:48,285 - RBF - ERROR - loss 1.2952404177740653, in epoch 174, in step 199, in global step 87200, learning rate is 0.00015, taks 9.162000179290771 seconds
2020-03-23 16:40:54,434 - RBF - ERROR - loss 1.295229286771153, in epoch 174, in step 399, in global step 87400, learning rate is 0.00015, taks 6.148399829864502 seconds
2020-03-23 16:40:57,469 - RBF - INFO - train epoch 175 of total 5000 epoches
2020-03-23 16:41:03,581 - RBF - ERROR - loss 1.2952177322369551, in epoch 175, in step 199, in global step 87700, learning rate is 0.00015, taks 9.145200252532959 seconds
2020-03-23 16:41:09,713 - RBF - ERROR - loss 1.2952116537484457, in epoch 175, in step 399, in global step 87900, learning rate is 0.00015, taks 6.131999969482422 seconds
2020-03-23 16:41:12,773 - RBF - INFO - train epoch 176 of total 5000 epoches
2020-03-23 16:41:18,885 - RBF - ERROR - loss 1.2952126320226098, in epoch 176, in step 199, in global step 88200, learning rate is 0.00015, taks 9.171200037002563 seconds
2020-03-23 16:41:24,958 - RBF - ERROR - loss 1.2952263999688336, in epoch 176, in step 399, in global step 88400, learning rate is 0.00015, taks 6.073400020599365 seconds
2020-03-23 16:41:28,023 - RBF - INFO - train epoch 177 of total 5000 epoches
2020-03-23 16:41:34,135 - RBF - ERROR - loss 1.2951927225368434, in epoch 177, in step 199, in global step 88700, learning rate is 0.00015, taks 9.176000118255615 seconds
2020-03-23 16:41:40,236 - RBF - ERROR - loss 1.295189168345867, in epoch 177, in step 399, in global step 88900, learning rate is 0.00015, taks 6.099800109863281 seconds
2020-03-23 16:41:43,287 - RBF - INFO - train epoch 178 of total 5000 epoches
2020-03-23 16:41:49,442 - RBF - ERROR - loss 1.2951813649030033, in epoch 178, in step 199, in global step 89200, learning rate is 0.00015, taks 9.20579981803894 seconds
2020-03-23 16:41:55,541 - RBF - ERROR - loss 1.2951832449837055, in epoch 178, in step 399, in global step 89400, learning rate is 0.00015, taks 6.0980000495910645 seconds
2020-03-23 16:41:58,608 - RBF - INFO - train epoch 179 of total 5000 epoches
2020-03-23 16:42:04,737 - RBF - ERROR - loss 1.2951649863809658, in epoch 179, in step 199, in global step 89700, learning rate is 0.00015, taks 9.194999933242798 seconds
2020-03-23 16:42:10,847 - RBF - ERROR - loss 1.295162695039285, in epoch 179, in step 399, in global step 89900, learning rate is 0.00015, taks 6.109999895095825 seconds
2020-03-23 16:42:16,366 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 179. learning_rate is 0.00015, loss is 1.2951767381435786
2020-03-23 16:42:16,367 - RBF - INFO - train epoch 180 of total 5000 epoches
2020-03-23 16:42:22,737 - RBF - ERROR - loss 1.2951716372615167, in epoch 180, in step 199, in global step 90200, learning rate is 0.00015, taks 11.890399932861328 seconds
2020-03-23 16:42:28,820 - RBF - ERROR - loss 1.295147920986597, in epoch 180, in step 399, in global step 90400, learning rate is 0.00015, taks 6.0817999839782715 seconds
2020-03-23 16:42:31,867 - RBF - INFO - train epoch 181 of total 5000 epoches
2020-03-23 16:42:37,960 - RBF - ERROR - loss 1.2951483041465341, in epoch 181, in step 199, in global step 90700, learning rate is 0.00015, taks 9.140399932861328 seconds
2020-03-23 16:42:44,077 - RBF - ERROR - loss 1.2951402997200006, in epoch 181, in step 399, in global step 90900, learning rate is 0.00015, taks 6.116199970245361 seconds
2020-03-23 16:42:47,117 - RBF - INFO - train epoch 182 of total 5000 epoches
2020-03-23 16:42:53,238 - RBF - ERROR - loss 1.2951289071717489, in epoch 182, in step 199, in global step 91200, learning rate is 0.00015, taks 9.161200046539307 seconds
2020-03-23 16:42:59,391 - RBF - ERROR - loss 1.2951295263679214, in epoch 182, in step 399, in global step 91400, learning rate is 0.00015, taks 6.153199911117554 seconds
2020-03-23 16:43:02,470 - RBF - INFO - train epoch 183 of total 5000 epoches
2020-03-23 16:43:08,586 - RBF - ERROR - loss 1.2951190649499484, in epoch 183, in step 199, in global step 91700, learning rate is 0.00015, taks 9.195199966430664 seconds
2020-03-23 16:43:14,681 - RBF - ERROR - loss 1.2951339512085194, in epoch 183, in step 399, in global step 91900, learning rate is 0.00015, taks 6.0950000286102295 seconds
2020-03-23 16:43:17,774 - RBF - INFO - train epoch 184 of total 5000 epoches
2020-03-23 16:43:23,883 - RBF - ERROR - loss 1.295103045979677, in epoch 184, in step 199, in global step 92200, learning rate is 0.00015, taks 9.20080018043518 seconds
2020-03-23 16:43:29,999 - RBF - ERROR - loss 1.2950984978494056, in epoch 184, in step 399, in global step 92400, learning rate is 0.00015, taks 6.114799976348877 seconds
2020-03-23 16:43:33,045 - RBF - INFO - train epoch 185 of total 5000 epoches
2020-03-23 16:43:39,166 - RBF - ERROR - loss 1.2950929401162155, in epoch 185, in step 199, in global step 92700, learning rate is 0.00015, taks 9.166399955749512 seconds
2020-03-23 16:43:45,239 - RBF - ERROR - loss 1.295090781993429, in epoch 185, in step 399, in global step 92900, learning rate is 0.00015, taks 6.073000192642212 seconds
2020-03-23 16:43:48,318 - RBF - INFO - train epoch 186 of total 5000 epoches
2020-03-23 16:43:54,457 - RBF - ERROR - loss 1.295076939259013, in epoch 186, in step 199, in global step 93200, learning rate is 0.00015, taks 9.217999935150146 seconds
2020-03-23 16:44:00,541 - RBF - ERROR - loss 1.2950716081246083, in epoch 186, in step 399, in global step 93400, learning rate is 0.00015, taks 6.083600044250488 seconds
2020-03-23 16:44:03,603 - RBF - INFO - train epoch 187 of total 5000 epoches
2020-03-23 16:44:09,684 - RBF - ERROR - loss 1.2950663880767825, in epoch 187, in step 199, in global step 93700, learning rate is 0.00015, taks 9.141999959945679 seconds
2020-03-23 16:44:15,276 - RBF - ERROR - loss 1.2950938207302851, in epoch 187, in step 399, in global step 93900, learning rate is 0.00015, taks 5.5920000076293945 seconds
2020-03-23 16:44:18,066 - RBF - INFO - train epoch 188 of total 5000 epoches
2020-03-23 16:44:23,632 - RBF - ERROR - loss 1.2950515425846514, in epoch 188, in step 199, in global step 94200, learning rate is 0.00015, taks 8.355999946594238 seconds
2020-03-23 16:44:29,192 - RBF - ERROR - loss 1.295062659155438, in epoch 188, in step 399, in global step 94400, learning rate is 0.00015, taks 5.56000018119812 seconds
2020-03-23 16:44:31,990 - RBF - INFO - train epoch 189 of total 5000 epoches
2020-03-23 16:44:37,567 - RBF - ERROR - loss 1.2950397720333833, in epoch 189, in step 199, in global step 94700, learning rate is 0.00015, taks 8.374399900436401 seconds
2020-03-23 16:44:43,140 - RBF - ERROR - loss 1.2950373417483414, in epoch 189, in step 399, in global step 94900, learning rate is 0.00015, taks 5.572799921035767 seconds
2020-03-23 16:44:45,949 - RBF - INFO - train epoch 190 of total 5000 epoches
2020-03-23 16:44:51,565 - RBF - ERROR - loss 1.295027227725516, in epoch 190, in step 199, in global step 95200, learning rate is 0.00015, taks 8.424800157546997 seconds
2020-03-23 16:44:57,144 - RBF - ERROR - loss 1.2950233068679895, in epoch 190, in step 399, in global step 95400, learning rate is 0.00015, taks 5.5787999629974365 seconds
2020-03-23 16:44:59,944 - RBF - INFO - train epoch 191 of total 5000 epoches
2020-03-23 16:45:05,555 - RBF - ERROR - loss 1.2950136129765744, in epoch 191, in step 199, in global step 95700, learning rate is 0.00015, taks 8.410399913787842 seconds
2020-03-23 16:45:11,133 - RBF - ERROR - loss 1.295010573519188, in epoch 191, in step 399, in global step 95900, learning rate is 0.00015, taks 5.578200101852417 seconds
2020-03-23 16:45:13,920 - RBF - INFO - train epoch 192 of total 5000 epoches
2020-03-23 16:45:19,484 - RBF - ERROR - loss 1.2950227693291236, in epoch 192, in step 199, in global step 96200, learning rate is 0.00015, taks 8.350599765777588 seconds
2020-03-23 16:45:25,054 - RBF - ERROR - loss 1.2949963173019832, in epoch 192, in step 399, in global step 96400, learning rate is 0.00015, taks 5.57039999961853 seconds
2020-03-23 16:45:27,838 - RBF - INFO - train epoch 193 of total 5000 epoches
2020-03-23 16:45:33,468 - RBF - ERROR - loss 1.2950014266984586, in epoch 193, in step 199, in global step 96700, learning rate is 0.00015, taks 8.412400245666504 seconds
2020-03-23 16:45:39,040 - RBF - ERROR - loss 1.2949837822671695, in epoch 193, in step 399, in global step 96900, learning rate is 0.00015, taks 5.572199821472168 seconds
2020-03-23 16:45:41,818 - RBF - INFO - train epoch 194 of total 5000 epoches
2020-03-23 16:45:47,418 - RBF - ERROR - loss 1.2949804669600398, in epoch 194, in step 199, in global step 97200, learning rate is 0.00015, taks 8.378000020980835 seconds
2020-03-23 16:45:53,066 - RBF - ERROR - loss 1.2949769786541705, in epoch 194, in step 399, in global step 97400, learning rate is 0.00015, taks 5.647799968719482 seconds
2020-03-23 16:45:55,840 - RBF - INFO - train epoch 195 of total 5000 epoches
2020-03-23 16:46:01,448 - RBF - ERROR - loss 1.2949685188468978, in epoch 195, in step 199, in global step 97700, learning rate is 0.00015, taks 8.382400035858154 seconds
2020-03-23 16:46:07,073 - RBF - ERROR - loss 1.2949610280342272, in epoch 195, in step 399, in global step 97900, learning rate is 0.00015, taks 5.623800039291382 seconds
2020-03-23 16:46:09,882 - RBF - INFO - train epoch 196 of total 5000 epoches
2020-03-23 16:46:15,495 - RBF - ERROR - loss 1.2949542586507854, in epoch 196, in step 199, in global step 98200, learning rate is 0.00015, taks 8.422600030899048 seconds
2020-03-23 16:46:21,081 - RBF - ERROR - loss 1.2949491550948156, in epoch 196, in step 399, in global step 98400, learning rate is 0.00015, taks 5.584199905395508 seconds
2020-03-23 16:46:23,865 - RBF - INFO - train epoch 197 of total 5000 epoches
2020-03-23 16:46:29,479 - RBF - ERROR - loss 1.2949400128684483, in epoch 197, in step 199, in global step 98700, learning rate is 0.00015, taks 8.398799896240234 seconds
2020-03-23 16:46:35,063 - RBF - ERROR - loss 1.294934126582948, in epoch 197, in step 399, in global step 98900, learning rate is 0.00015, taks 5.5838000774383545 seconds
2020-03-23 16:46:37,844 - RBF - INFO - train epoch 198 of total 5000 epoches
2020-03-23 16:46:43,410 - RBF - ERROR - loss 1.294926693335884, in epoch 198, in step 199, in global step 99200, learning rate is 0.00015, taks 8.346400022506714 seconds
2020-03-23 16:46:48,439 - RBF - ERROR - loss 1.2949213232954624, in epoch 198, in step 399, in global step 99400, learning rate is 0.00015, taks 5.0289998054504395 seconds
2020-03-23 16:46:50,840 - RBF - INFO - train epoch 199 of total 5000 epoches
2020-03-23 16:46:55,636 - RBF - ERROR - loss 1.294928555637561, in epoch 199, in step 199, in global step 99700, learning rate is 0.00015, taks 7.197400093078613 seconds
2020-03-23 16:47:00,447 - RBF - ERROR - loss 1.2949135187487348, in epoch 199, in step 399, in global step 99900, learning rate is 0.00015, taks 4.810200214385986 seconds
2020-03-23 16:47:05,170 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 199. learning_rate is 0.00015, loss is 1.2949051786292476
2020-03-23 16:47:05,170 - RBF - INFO - train epoch 200 of total 5000 epoches
2020-03-23 16:47:11,979 - RBF - ERROR - loss 1.29490405465482, in epoch 200, in step 199, in global step 100200, learning rate is 0.00015, taks 11.531599998474121 seconds
2020-03-23 16:47:18,116 - RBF - ERROR - loss 1.2948974051201816, in epoch 200, in step 399, in global step 100400, learning rate is 0.00015, taks 6.137399911880493 seconds
2020-03-23 16:47:21,151 - RBF - INFO - train epoch 201 of total 5000 epoches
2020-03-23 16:47:27,270 - RBF - ERROR - loss 1.2948934648836545, in epoch 201, in step 199, in global step 100700, learning rate is 0.00015, taks 9.15339994430542 seconds
2020-03-23 16:47:33,386 - RBF - ERROR - loss 1.2948843225386528, in epoch 201, in step 399, in global step 100900, learning rate is 0.00015, taks 6.115600109100342 seconds
2020-03-23 16:47:36,424 - RBF - INFO - train epoch 202 of total 5000 epoches
2020-03-23 16:47:42,542 - RBF - ERROR - loss 1.2948796519632384, in epoch 202, in step 199, in global step 101200, learning rate is 0.00015, taks 9.155400037765503 seconds
2020-03-23 16:47:48,693 - RBF - ERROR - loss 1.294871229753683, in epoch 202, in step 399, in global step 101400, learning rate is 0.00015, taks 6.151600122451782 seconds
2020-03-23 16:47:51,770 - RBF - INFO - train epoch 203 of total 5000 epoches
2020-03-23 16:47:57,883 - RBF - ERROR - loss 1.29488367079537, in epoch 203, in step 199, in global step 101700, learning rate is 0.00015, taks 9.189399719238281 seconds
2020-03-23 16:48:03,996 - RBF - ERROR - loss 1.2948582635807782, in epoch 203, in step 399, in global step 101900, learning rate is 0.00015, taks 6.1132001876831055 seconds
2020-03-23 16:48:07,059 - RBF - INFO - train epoch 204 of total 5000 epoches
2020-03-23 16:48:13,169 - RBF - ERROR - loss 1.2948745103305823, in epoch 204, in step 199, in global step 102200, learning rate is 0.00015, taks 9.17199993133545 seconds
2020-03-23 16:48:19,274 - RBF - ERROR - loss 1.2948595303301627, in epoch 204, in step 399, in global step 102400, learning rate is 0.00015, taks 6.105200290679932 seconds
2020-03-23 16:48:22,349 - RBF - INFO - train epoch 205 of total 5000 epoches
2020-03-23 16:48:28,443 - RBF - ERROR - loss 1.2948373018466444, in epoch 205, in step 199, in global step 102700, learning rate is 0.00015, taks 9.169399976730347 seconds
2020-03-23 16:48:34,857 - RBF - ERROR - loss 1.2948457547824712, in epoch 205, in step 399, in global step 102900, learning rate is 0.00015, taks 6.412199974060059 seconds
2020-03-23 16:48:37,907 - RBF - INFO - train epoch 206 of total 5000 epoches
2020-03-23 16:48:42,991 - RBF - ERROR - loss 1.2948262565452258, in epoch 206, in step 199, in global step 103200, learning rate is 0.00015, taks 8.134399890899658 seconds
2020-03-23 16:48:47,326 - RBF - ERROR - loss 1.2948250781244868, in epoch 206, in step 399, in global step 103400, learning rate is 0.00015, taks 4.335200071334839 seconds
2020-03-23 16:48:49,093 - RBF - INFO - train epoch 207 of total 5000 epoches
2020-03-23 16:48:52,307 - RBF - ERROR - loss 1.2948140835887803, in epoch 207, in step 199, in global step 103700, learning rate is 0.00015, taks 4.980999946594238 seconds
2020-03-23 16:48:55,715 - RBF - ERROR - loss 1.2948127143466972, in epoch 207, in step 399, in global step 103900, learning rate is 0.00015, taks 3.408200263977051 seconds
2020-03-23 16:48:57,261 - RBF - INFO - train epoch 208 of total 5000 epoches
2020-03-23 16:48:59,963 - RBF - ERROR - loss 1.2948045494621363, in epoch 208, in step 199, in global step 104200, learning rate is 0.00015, taks 4.247200012207031 seconds
2020-03-23 16:49:02,650 - RBF - ERROR - loss 1.2948039052694078, in epoch 208, in step 399, in global step 104400, learning rate is 0.00015, taks 2.687199831008911 seconds
2020-03-23 16:49:03,938 - RBF - INFO - train epoch 209 of total 5000 epoches
2020-03-23 16:49:06,611 - RBF - ERROR - loss 1.2947863544534037, in epoch 209, in step 199, in global step 104700, learning rate is 0.00015, taks 3.961399793624878 seconds
2020-03-23 16:49:09,359 - RBF - ERROR - loss 1.29478378454658, in epoch 209, in step 399, in global step 104900, learning rate is 0.00015, taks 2.7476003170013428 seconds
2020-03-23 16:49:10,688 - RBF - INFO - train epoch 210 of total 5000 epoches
2020-03-23 16:49:13,356 - RBF - ERROR - loss 1.294782212774499, in epoch 210, in step 199, in global step 105200, learning rate is 0.00015, taks 3.9961998462677 seconds
2020-03-23 16:49:16,029 - RBF - ERROR - loss 1.2947688589211224, in epoch 210, in step 399, in global step 105400, learning rate is 0.00015, taks 2.6734001636505127 seconds
2020-03-23 16:49:17,261 - RBF - INFO - train epoch 211 of total 5000 epoches
2020-03-23 16:49:20,020 - RBF - ERROR - loss 1.2947641731262303, in epoch 211, in step 199, in global step 105700, learning rate is 0.00015, taks 3.9902000427246094 seconds
2020-03-23 16:49:22,789 - RBF - ERROR - loss 1.2947559011549548, in epoch 211, in step 399, in global step 105900, learning rate is 0.00015, taks 2.769400119781494 seconds
2020-03-23 16:49:24,182 - RBF - INFO - train epoch 212 of total 5000 epoches
2020-03-23 16:49:26,899 - RBF - ERROR - loss 1.2948058332377679, in epoch 212, in step 199, in global step 106200, learning rate is 0.00015, taks 4.108599901199341 seconds
2020-03-23 16:49:29,618 - RBF - ERROR - loss 1.2947826705383458, in epoch 212, in step 399, in global step 106400, learning rate is 0.00015, taks 2.719399929046631 seconds
2020-03-23 16:49:30,872 - RBF - INFO - train epoch 213 of total 5000 epoches
2020-03-23 16:49:33,499 - RBF - ERROR - loss 1.2947366733754033, in epoch 213, in step 199, in global step 106700, learning rate is 0.00015, taks 3.8804001808166504 seconds
2020-03-23 16:49:36,079 - RBF - ERROR - loss 1.2947300382171416, in epoch 213, in step 399, in global step 106900, learning rate is 0.00015, taks 2.5795998573303223 seconds
2020-03-23 16:49:37,322 - RBF - INFO - train epoch 214 of total 5000 epoches
2020-03-23 16:49:39,973 - RBF - ERROR - loss 1.2947261986149101, in epoch 214, in step 199, in global step 107200, learning rate is 0.00015, taks 3.894200086593628 seconds
2020-03-23 16:49:42,510 - RBF - ERROR - loss 1.2947348844763233, in epoch 214, in step 399, in global step 107400, learning rate is 0.00015, taks 2.536600112915039 seconds
2020-03-23 16:49:43,796 - RBF - INFO - train epoch 215 of total 5000 epoches
2020-03-23 16:49:46,360 - RBF - ERROR - loss 1.2947174006514646, in epoch 215, in step 199, in global step 107700, learning rate is 0.00015, taks 3.850399971008301 seconds
2020-03-23 16:49:48,924 - RBF - ERROR - loss 1.2947377144532035, in epoch 215, in step 399, in global step 107900, learning rate is 0.00015, taks 2.5634000301361084 seconds
2020-03-23 16:49:50,203 - RBF - INFO - train epoch 216 of total 5000 epoches
2020-03-23 16:49:52,698 - RBF - ERROR - loss 1.294701838219098, in epoch 216, in step 199, in global step 108200, learning rate is 0.00015, taks 3.774199962615967 seconds
2020-03-23 16:49:55,387 - RBF - ERROR - loss 1.2946998007620474, in epoch 216, in step 399, in global step 108400, learning rate is 0.00015, taks 2.688999891281128 seconds
2020-03-23 16:49:56,739 - RBF - INFO - train epoch 217 of total 5000 epoches
2020-03-23 16:49:59,308 - RBF - ERROR - loss 1.29473289131161, in epoch 217, in step 199, in global step 108700, learning rate is 0.00015, taks 3.9212000370025635 seconds
2020-03-23 16:50:01,920 - RBF - ERROR - loss 1.2946795796164938, in epoch 217, in step 399, in global step 108900, learning rate is 0.00015, taks 2.6124000549316406 seconds
2020-03-23 16:50:03,187 - RBF - INFO - train epoch 218 of total 5000 epoches
2020-03-23 16:50:05,816 - RBF - ERROR - loss 1.2946739301316874, in epoch 218, in step 199, in global step 109200, learning rate is 0.00015, taks 3.89520001411438 seconds
2020-03-23 16:50:08,484 - RBF - ERROR - loss 1.294672141673337, in epoch 218, in step 399, in global step 109400, learning rate is 0.00015, taks 2.668600082397461 seconds
2020-03-23 16:50:09,792 - RBF - INFO - train epoch 219 of total 5000 epoches
2020-03-23 16:50:12,571 - RBF - ERROR - loss 1.2946641472606688, in epoch 219, in step 199, in global step 109700, learning rate is 0.00015, taks 4.087199926376343 seconds
2020-03-23 16:50:15,197 - RBF - ERROR - loss 1.2946686324928116, in epoch 219, in step 399, in global step 109900, learning rate is 0.00015, taks 2.6256000995635986 seconds
2020-03-23 16:50:19,115 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 219. learning_rate is 0.00015, loss is 1.2946496934154363
2020-03-23 16:50:19,117 - RBF - INFO - train epoch 220 of total 5000 epoches
2020-03-23 16:50:25,649 - RBF - ERROR - loss 1.2946490286446402, in epoch 220, in step 199, in global step 110200, learning rate is 0.00015, taks 10.45199990272522 seconds
2020-03-23 16:50:31,972 - RBF - ERROR - loss 1.2946490175131202, in epoch 220, in step 399, in global step 110400, learning rate is 0.00015, taks 6.322799921035767 seconds
2020-03-23 16:50:35,183 - RBF - INFO - train epoch 221 of total 5000 epoches
2020-03-23 16:50:41,537 - RBF - ERROR - loss 1.2946313591140244, in epoch 221, in step 199, in global step 110700, learning rate is 0.00015, taks 9.56499981880188 seconds
2020-03-23 16:50:47,956 - RBF - ERROR - loss 1.2946268657295092, in epoch 221, in step 399, in global step 110900, learning rate is 0.00015, taks 6.419000148773193 seconds
2020-03-23 16:50:51,141 - RBF - INFO - train epoch 222 of total 5000 epoches
2020-03-23 16:50:57,534 - RBF - ERROR - loss 1.2946205526956904, in epoch 222, in step 199, in global step 111200, learning rate is 0.00015, taks 9.57859992980957 seconds
2020-03-23 16:51:03,891 - RBF - ERROR - loss 1.2946157909682419, in epoch 222, in step 399, in global step 111400, learning rate is 0.00015, taks 6.356200218200684 seconds
2020-03-23 16:51:07,099 - RBF - INFO - train epoch 223 of total 5000 epoches
2020-03-23 16:51:13,484 - RBF - ERROR - loss 1.29460708166498, in epoch 223, in step 199, in global step 111700, learning rate is 0.00015, taks 9.592999935150146 seconds
2020-03-23 16:51:19,844 - RBF - ERROR - loss 1.2946019977346348, in epoch 223, in step 399, in global step 111900, learning rate is 0.00015, taks 6.360599994659424 seconds
2020-03-23 16:51:23,049 - RBF - INFO - train epoch 224 of total 5000 epoches
2020-03-23 16:51:29,411 - RBF - ERROR - loss 1.2945938011556446, in epoch 224, in step 199, in global step 112200, learning rate is 0.00015, taks 9.567199945449829 seconds
2020-03-23 16:51:35,788 - RBF - ERROR - loss 1.2946222597276582, in epoch 224, in step 399, in global step 112400, learning rate is 0.00015, taks 6.375800132751465 seconds
2020-03-23 16:51:38,973 - RBF - INFO - train epoch 225 of total 5000 epoches
2020-03-23 16:51:45,337 - RBF - ERROR - loss 1.2945824270170423, in epoch 225, in step 199, in global step 112700, learning rate is 0.00015, taks 9.54919981956482 seconds
2020-03-23 16:51:51,723 - RBF - ERROR - loss 1.2946002390022153, in epoch 225, in step 399, in global step 112900, learning rate is 0.00015, taks 6.384200096130371 seconds
2020-03-23 16:51:54,916 - RBF - INFO - train epoch 226 of total 5000 epoches
2020-03-23 16:52:01,274 - RBF - ERROR - loss 1.2945815960782163, in epoch 226, in step 199, in global step 113200, learning rate is 0.00015, taks 9.551599740982056 seconds
2020-03-23 16:52:07,625 - RBF - ERROR - loss 1.294563901157435, in epoch 226, in step 399, in global step 113400, learning rate is 0.00015, taks 6.350600004196167 seconds
2020-03-23 16:52:10,815 - RBF - INFO - train epoch 227 of total 5000 epoches
2020-03-23 16:52:17,177 - RBF - ERROR - loss 1.2945726081683215, in epoch 227, in step 199, in global step 113700, learning rate is 0.00015, taks 9.551599979400635 seconds
2020-03-23 16:52:23,528 - RBF - ERROR - loss 1.2945503360555337, in epoch 227, in step 399, in global step 113900, learning rate is 0.00015, taks 6.350800037384033 seconds
2020-03-23 16:52:26,775 - RBF - INFO - train epoch 228 of total 5000 epoches
2020-03-23 16:52:33,278 - RBF - ERROR - loss 1.294557197401187, in epoch 228, in step 199, in global step 114200, learning rate is 0.00015, taks 9.734600067138672 seconds
2020-03-23 16:52:39,183 - RBF - ERROR - loss 1.2945491725297553, in epoch 228, in step 399, in global step 114400, learning rate is 0.00015, taks 5.904399871826172 seconds
2020-03-23 16:52:42,068 - RBF - INFO - train epoch 229 of total 5000 epoches
2020-03-23 16:52:47,878 - RBF - ERROR - loss 1.2945304838877199, in epoch 229, in step 199, in global step 114700, learning rate is 0.00015, taks 8.695000171661377 seconds
2020-03-23 16:52:53,735 - RBF - ERROR - loss 1.294527229063102, in epoch 229, in step 399, in global step 114900, learning rate is 0.00015, taks 5.85699987411499 seconds
2020-03-23 16:52:56,461 - RBF - INFO - train epoch 230 of total 5000 epoches
2020-03-23 16:53:01,451 - RBF - ERROR - loss 1.2945178529703236, in epoch 230, in step 199, in global step 115200, learning rate is 0.00015, taks 7.716600179672241 seconds
2020-03-23 16:53:06,427 - RBF - ERROR - loss 1.2945279529135418, in epoch 230, in step 399, in global step 115400, learning rate is 0.00015, taks 4.975399732589722 seconds
2020-03-23 16:53:08,914 - RBF - INFO - train epoch 231 of total 5000 epoches
2020-03-23 16:53:13,906 - RBF - ERROR - loss 1.294522315011452, in epoch 231, in step 199, in global step 115700, learning rate is 0.00015, taks 7.479600191116333 seconds
2020-03-23 16:53:18,871 - RBF - ERROR - loss 1.294497137094831, in epoch 231, in step 399, in global step 115900, learning rate is 0.00015, taks 4.9649999141693115 seconds
2020-03-23 16:53:21,376 - RBF - INFO - train epoch 232 of total 5000 epoches
2020-03-23 16:53:26,316 - RBF - ERROR - loss 1.2945138050373797, in epoch 232, in step 199, in global step 116200, learning rate is 0.00015, taks 7.4446001052856445 seconds
2020-03-23 16:53:31,285 - RBF - ERROR - loss 1.2944872236508045, in epoch 232, in step 399, in global step 116400, learning rate is 0.00015, taks 4.96940016746521 seconds
2020-03-23 16:53:33,773 - RBF - INFO - train epoch 233 of total 5000 epoches
2020-03-23 16:53:38,772 - RBF - ERROR - loss 1.294475995587063, in epoch 233, in step 199, in global step 116700, learning rate is 0.00015, taks 7.486799716949463 seconds
2020-03-23 16:53:43,758 - RBF - ERROR - loss 1.2944914020876588, in epoch 233, in step 399, in global step 116900, learning rate is 0.00015, taks 4.984400272369385 seconds
2020-03-23 16:53:46,248 - RBF - INFO - train epoch 234 of total 5000 epoches
2020-03-23 16:53:51,229 - RBF - ERROR - loss 1.2944678779920111, in epoch 234, in step 199, in global step 117200, learning rate is 0.00015, taks 7.4709999561309814 seconds
2020-03-23 16:53:56,208 - RBF - ERROR - loss 1.294459800546247, in epoch 234, in step 399, in global step 117400, learning rate is 0.00015, taks 4.979399919509888 seconds
2020-03-23 16:53:58,705 - RBF - INFO - train epoch 235 of total 5000 epoches
2020-03-23 16:54:03,673 - RBF - ERROR - loss 1.2944798327890894, in epoch 235, in step 199, in global step 117700, learning rate is 0.00015, taks 7.464600086212158 seconds
2020-03-23 16:54:08,652 - RBF - ERROR - loss 1.2944509520748084, in epoch 235, in step 399, in global step 117900, learning rate is 0.00015, taks 4.978200197219849 seconds
2020-03-23 16:54:11,130 - RBF - INFO - train epoch 236 of total 5000 epoches
2020-03-23 16:54:16,092 - RBF - ERROR - loss 1.2944409449347598, in epoch 236, in step 199, in global step 118200, learning rate is 0.00015, taks 7.440599679946899 seconds
2020-03-23 16:54:21,056 - RBF - ERROR - loss 1.294453352331742, in epoch 236, in step 399, in global step 118400, learning rate is 0.00015, taks 4.963200092315674 seconds
2020-03-23 16:54:23,533 - RBF - INFO - train epoch 237 of total 5000 epoches
2020-03-23 16:54:28,531 - RBF - ERROR - loss 1.2944277480848607, in epoch 237, in step 199, in global step 118700, learning rate is 0.00015, taks 7.475800037384033 seconds
2020-03-23 16:54:33,502 - RBF - ERROR - loss 1.2944284074624655, in epoch 237, in step 399, in global step 118900, learning rate is 0.00015, taks 4.970399856567383 seconds
2020-03-23 16:54:35,989 - RBF - INFO - train epoch 238 of total 5000 epoches
2020-03-23 16:54:40,964 - RBF - ERROR - loss 1.2944150095859959, in epoch 238, in step 199, in global step 119200, learning rate is 0.00015, taks 7.462200164794922 seconds
2020-03-23 16:54:45,960 - RBF - ERROR - loss 1.2944133868254752, in epoch 238, in step 399, in global step 119400, learning rate is 0.00015, taks 4.996000051498413 seconds
2020-03-23 16:54:48,479 - RBF - INFO - train epoch 239 of total 5000 epoches
2020-03-23 16:54:53,474 - RBF - ERROR - loss 1.2944006318637191, in epoch 239, in step 199, in global step 119700, learning rate is 0.00015, taks 7.512799978256226 seconds
2020-03-23 16:54:58,425 - RBF - ERROR - loss 1.294398706452714, in epoch 239, in step 399, in global step 119900, learning rate is 0.00015, taks 4.951200008392334 seconds
2020-03-23 16:55:03,394 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 239. learning_rate is 0.00015, loss is 1.2943929123612907
2020-03-23 16:55:03,395 - RBF - INFO - train epoch 240 of total 5000 epoches
2020-03-23 16:55:09,919 - RBF - ERROR - loss 1.2944072826609918, in epoch 240, in step 199, in global step 120200, learning rate is 0.00015, taks 11.493799924850464 seconds
2020-03-23 16:55:16,300 - RBF - ERROR - loss 1.2943870023213404, in epoch 240, in step 399, in global step 120400, learning rate is 0.00015, taks 6.381400108337402 seconds
2020-03-23 16:55:19,483 - RBF - INFO - train epoch 241 of total 5000 epoches
2020-03-23 16:55:25,896 - RBF - ERROR - loss 1.29437586392066, in epoch 241, in step 199, in global step 120700, learning rate is 0.00015, taks 9.595399856567383 seconds
2020-03-23 16:55:32,239 - RBF - ERROR - loss 1.2943766204331058, in epoch 241, in step 399, in global step 120900, learning rate is 0.00015, taks 6.343000173568726 seconds
2020-03-23 16:55:35,146 - RBF - INFO - train epoch 242 of total 5000 epoches
2020-03-23 16:55:40,961 - RBF - ERROR - loss 1.2943688785088006, in epoch 242, in step 199, in global step 121200, learning rate is 0.00015, taks 8.722399950027466 seconds
2020-03-23 16:55:46,769 - RBF - ERROR - loss 1.294358730113466, in epoch 242, in step 399, in global step 121400, learning rate is 0.00015, taks 5.806800127029419 seconds
2020-03-23 16:55:49,497 - RBF - INFO - train epoch 243 of total 5000 epoches
2020-03-23 16:55:54,479 - RBF - ERROR - loss 1.2943552039105484, in epoch 243, in step 199, in global step 121700, learning rate is 0.00015, taks 7.710599899291992 seconds
2020-03-23 16:55:59,445 - RBF - ERROR - loss 1.2943492497652367, in epoch 243, in step 399, in global step 121900, learning rate is 0.00015, taks 4.966000080108643 seconds
2020-03-23 16:56:01,936 - RBF - INFO - train epoch 244 of total 5000 epoches
2020-03-23 16:56:06,921 - RBF - ERROR - loss 1.2943485309247773, in epoch 244, in step 199, in global step 122200, learning rate is 0.00015, taks 7.474800109863281 seconds
2020-03-23 16:56:11,885 - RBF - ERROR - loss 1.2943351037387367, in epoch 244, in step 399, in global step 122400, learning rate is 0.00015, taks 4.96399998664856 seconds
2020-03-23 16:56:14,366 - RBF - INFO - train epoch 245 of total 5000 epoches
2020-03-23 16:56:19,361 - RBF - ERROR - loss 1.294326791620812, in epoch 245, in step 199, in global step 122700, learning rate is 0.00015, taks 7.475600004196167 seconds
2020-03-23 16:56:24,342 - RBF - ERROR - loss 1.2943532015528276, in epoch 245, in step 399, in global step 122900, learning rate is 0.00015, taks 4.981400012969971 seconds
2020-03-23 16:56:26,852 - RBF - INFO - train epoch 246 of total 5000 epoches
2020-03-23 16:56:31,798 - RBF - ERROR - loss 1.2943497406277247, in epoch 246, in step 199, in global step 123200, learning rate is 0.00015, taks 7.454599857330322 seconds
2020-03-23 16:56:36,765 - RBF - ERROR - loss 1.294310393819994, in epoch 246, in step 399, in global step 123400, learning rate is 0.00015, taks 4.9659998416900635 seconds
2020-03-23 16:56:39,268 - RBF - INFO - train epoch 247 of total 5000 epoches
2020-03-23 16:56:44,231 - RBF - ERROR - loss 1.2943552820926703, in epoch 247, in step 199, in global step 123700, learning rate is 0.00015, taks 7.466399908065796 seconds
2020-03-23 16:56:49,199 - RBF - ERROR - loss 1.2943015499529213, in epoch 247, in step 399, in global step 123900, learning rate is 0.00015, taks 4.9679999351501465 seconds
2020-03-23 16:56:51,529 - RBF - INFO - train epoch 248 of total 5000 epoches
2020-03-23 16:56:56,175 - RBF - ERROR - loss 1.2943170965739226, in epoch 248, in step 199, in global step 124200, learning rate is 0.00015, taks 6.976000070571899 seconds
2020-03-23 16:57:00,859 - RBF - ERROR - loss 1.2942905497463866, in epoch 248, in step 399, in global step 124400, learning rate is 0.00015, taks 4.684000015258789 seconds
2020-03-23 16:57:03,193 - RBF - INFO - train epoch 249 of total 5000 epoches
2020-03-23 16:57:07,829 - RBF - ERROR - loss 1.2942888061577067, in epoch 249, in step 199, in global step 124700, learning rate is 0.00015, taks 6.968800067901611 seconds
2020-03-23 16:57:12,464 - RBF - ERROR - loss 1.2942798953346926, in epoch 249, in step 399, in global step 124900, learning rate is 0.00015, taks 4.635200023651123 seconds
2020-03-23 16:57:14,807 - RBF - INFO - train epoch 250 of total 5000 epoches
2020-03-23 16:57:19,445 - RBF - ERROR - loss 1.2942689140236154, in epoch 250, in step 199, in global step 125200, learning rate is 0.00015, taks 6.980599880218506 seconds
2020-03-23 16:57:24,078 - RBF - ERROR - loss 1.2942618867754763, in epoch 250, in step 399, in global step 125400, learning rate is 0.00015, taks 4.632000207901001 seconds
2020-03-23 16:57:26,404 - RBF - INFO - train epoch 251 of total 5000 epoches
2020-03-23 16:57:31,041 - RBF - ERROR - loss 1.2942933642520458, in epoch 251, in step 199, in global step 125700, learning rate is 0.00015, taks 6.963599920272827 seconds
2020-03-23 16:57:35,689 - RBF - ERROR - loss 1.2942501780050173, in epoch 251, in step 399, in global step 125900, learning rate is 0.00015, taks 4.646200180053711 seconds
2020-03-23 16:57:38,006 - RBF - INFO - train epoch 252 of total 5000 epoches
2020-03-23 16:57:42,674 - RBF - ERROR - loss 1.2942472198055215, in epoch 252, in step 199, in global step 126200, learning rate is 0.00015, taks 6.985599994659424 seconds
2020-03-23 16:57:47,300 - RBF - ERROR - loss 1.2942372401202051, in epoch 252, in step 399, in global step 126400, learning rate is 0.00015, taks 4.626199960708618 seconds
2020-03-23 16:57:49,649 - RBF - INFO - train epoch 253 of total 5000 epoches
2020-03-23 16:57:54,319 - RBF - ERROR - loss 1.2942663083373416, in epoch 253, in step 199, in global step 126700, learning rate is 0.00015, taks 7.018999814987183 seconds
2020-03-23 16:57:58,970 - RBF - ERROR - loss 1.2942544140981829, in epoch 253, in step 399, in global step 126900, learning rate is 0.00015, taks 4.651000261306763 seconds
2020-03-23 16:58:01,308 - RBF - INFO - train epoch 254 of total 5000 epoches
2020-03-23 16:58:05,971 - RBF - ERROR - loss 1.2942280958191328, in epoch 254, in step 199, in global step 127200, learning rate is 0.00015, taks 7.000999927520752 seconds
2020-03-23 16:58:10,600 - RBF - ERROR - loss 1.294223416503983, in epoch 254, in step 399, in global step 127400, learning rate is 0.00015, taks 4.629000186920166 seconds
2020-03-23 16:58:12,911 - RBF - INFO - train epoch 255 of total 5000 epoches
2020-03-23 16:58:17,575 - RBF - ERROR - loss 1.294212421796255, in epoch 255, in step 199, in global step 127700, learning rate is 0.00015, taks 6.973999738693237 seconds
2020-03-23 16:58:22,208 - RBF - ERROR - loss 1.2942314694874548, in epoch 255, in step 399, in global step 127900, learning rate is 0.00015, taks 4.632800102233887 seconds
2020-03-23 16:58:24,533 - RBF - INFO - train epoch 256 of total 5000 epoches
2020-03-23 16:58:29,188 - RBF - ERROR - loss 1.2941998640991441, in epoch 256, in step 199, in global step 128200, learning rate is 0.00015, taks 6.980000019073486 seconds
2020-03-23 16:58:33,842 - RBF - ERROR - loss 1.2942026574951968, in epoch 256, in step 399, in global step 128400, learning rate is 0.00015, taks 4.6540000438690186 seconds
2020-03-23 16:58:36,143 - RBF - INFO - train epoch 257 of total 5000 epoches
2020-03-23 16:58:40,792 - RBF - ERROR - loss 1.2941893749462705, in epoch 257, in step 199, in global step 128700, learning rate is 0.00015, taks 6.948999881744385 seconds
2020-03-23 16:58:45,481 - RBF - ERROR - loss 1.2941975111809036, in epoch 257, in step 399, in global step 128900, learning rate is 0.00015, taks 4.689200162887573 seconds
2020-03-23 16:58:47,785 - RBF - INFO - train epoch 258 of total 5000 epoches
2020-03-23 16:58:52,453 - RBF - ERROR - loss 1.2941930827644577, in epoch 258, in step 199, in global step 129200, learning rate is 0.00015, taks 6.970200061798096 seconds
2020-03-23 16:58:57,111 - RBF - ERROR - loss 1.2941770773668517, in epoch 258, in step 399, in global step 129400, learning rate is 0.00015, taks 4.658600091934204 seconds
2020-03-23 16:58:59,434 - RBF - INFO - train epoch 259 of total 5000 epoches
2020-03-23 16:59:04,202 - RBF - ERROR - loss 1.2941752336153673, in epoch 259, in step 199, in global step 129700, learning rate is 0.00015, taks 7.0909998416900635 seconds
2020-03-23 16:59:08,233 - RBF - ERROR - loss 1.294161329715051, in epoch 259, in step 399, in global step 129900, learning rate is 0.00015, taks 4.030400037765503 seconds
2020-03-23 16:59:12,557 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 259. learning_rate is 0.00015, loss is 1.294167525202652
2020-03-23 16:59:12,558 - RBF - INFO - train epoch 260 of total 5000 epoches
2020-03-23 16:59:19,023 - RBF - ERROR - loss 1.2941681494871384, in epoch 260, in step 199, in global step 130200, learning rate is 0.00015, taks 10.789400100708008 seconds
2020-03-23 16:59:25,005 - RBF - ERROR - loss 1.2941581089107146, in epoch 260, in step 399, in global step 130400, learning rate is 0.00015, taks 5.982399940490723 seconds
2020-03-23 16:59:27,911 - RBF - INFO - train epoch 261 of total 5000 epoches
2020-03-23 16:59:33,748 - RBF - ERROR - loss 1.2941549186763976, in epoch 261, in step 199, in global step 130700, learning rate is 0.00015, taks 8.741400241851807 seconds
2020-03-23 16:59:39,548 - RBF - ERROR - loss 1.2941458665962098, in epoch 261, in step 399, in global step 130900, learning rate is 0.00015, taks 5.8003997802734375 seconds
2020-03-23 16:59:42,459 - RBF - INFO - train epoch 262 of total 5000 epoches
2020-03-23 16:59:48,343 - RBF - ERROR - loss 1.2941492035497606, in epoch 262, in step 199, in global step 131200, learning rate is 0.00015, taks 8.794600248336792 seconds
2020-03-23 16:59:54,076 - RBF - ERROR - loss 1.2941255531205251, in epoch 262, in step 399, in global step 131400, learning rate is 0.00015, taks 5.731800079345703 seconds
2020-03-23 16:59:56,550 - RBF - INFO - train epoch 263 of total 5000 epoches
2020-03-23 17:00:01,584 - RBF - ERROR - loss 1.2941296106148086, in epoch 263, in step 199, in global step 131700, learning rate is 0.00015, taks 7.507200002670288 seconds
2020-03-23 17:00:06,569 - RBF - ERROR - loss 1.2941619593425977, in epoch 263, in step 399, in global step 131900, learning rate is 0.00015, taks 4.985399961471558 seconds
2020-03-23 17:00:09,033 - RBF - INFO - train epoch 264 of total 5000 epoches
2020-03-23 17:00:13,982 - RBF - ERROR - loss 1.2941100775612975, in epoch 264, in step 199, in global step 132200, learning rate is 0.00015, taks 7.412800073623657 seconds
2020-03-23 17:00:18,945 - RBF - ERROR - loss 1.2941119809124177, in epoch 264, in step 399, in global step 132400, learning rate is 0.00015, taks 4.961999893188477 seconds
2020-03-23 17:00:21,422 - RBF - INFO - train epoch 265 of total 5000 epoches
2020-03-23 17:00:26,384 - RBF - ERROR - loss 1.2941025763966647, in epoch 265, in step 199, in global step 132700, learning rate is 0.00015, taks 7.438600301742554 seconds
2020-03-23 17:00:31,342 - RBF - ERROR - loss 1.2941164953129007, in epoch 265, in step 399, in global step 132900, learning rate is 0.00015, taks 4.957399606704712 seconds
2020-03-23 17:00:33,841 - RBF - INFO - train epoch 266 of total 5000 epoches
2020-03-23 17:00:38,803 - RBF - ERROR - loss 1.29409106651074, in epoch 266, in step 199, in global step 133200, learning rate is 0.00015, taks 7.461400032043457 seconds
2020-03-23 17:00:43,769 - RBF - ERROR - loss 1.2941156205829694, in epoch 266, in step 399, in global step 133400, learning rate is 0.00015, taks 4.964399814605713 seconds
2020-03-23 17:00:46,256 - RBF - INFO - train epoch 267 of total 5000 epoches
2020-03-23 17:00:51,305 - RBF - ERROR - loss 1.2940769353583141, in epoch 267, in step 199, in global step 133700, learning rate is 0.00015, taks 7.535000324249268 seconds
2020-03-23 17:00:56,301 - RBF - ERROR - loss 1.2940773221030561, in epoch 267, in step 399, in global step 133900, learning rate is 0.00015, taks 4.995599746704102 seconds
2020-03-23 17:00:58,794 - RBF - INFO - train epoch 268 of total 5000 epoches
2020-03-23 17:01:03,764 - RBF - ERROR - loss 1.2940832053533744, in epoch 268, in step 199, in global step 134200, learning rate is 0.00015, taks 7.462400197982788 seconds
2020-03-23 17:01:08,728 - RBF - ERROR - loss 1.2941035300327726, in epoch 268, in step 399, in global step 134400, learning rate is 0.00015, taks 4.964400053024292 seconds
2020-03-23 17:01:11,226 - RBF - INFO - train epoch 269 of total 5000 epoches
2020-03-23 17:01:16,255 - RBF - ERROR - loss 1.2940746006728152, in epoch 269, in step 199, in global step 134700, learning rate is 0.00015, taks 7.526799917221069 seconds
2020-03-23 17:01:21,240 - RBF - ERROR - loss 1.2940544995736027, in epoch 269, in step 399, in global step 134900, learning rate is 0.00015, taks 4.984799861907959 seconds
2020-03-23 17:01:23,716 - RBF - INFO - train epoch 270 of total 5000 epoches
2020-03-23 17:01:28,697 - RBF - ERROR - loss 1.2940523149043042, in epoch 270, in step 199, in global step 135200, learning rate is 0.00015, taks 7.456399917602539 seconds
2020-03-23 17:01:33,668 - RBF - ERROR - loss 1.294042077063096, in epoch 270, in step 399, in global step 135400, learning rate is 0.00015, taks 4.9710001945495605 seconds
2020-03-23 17:01:36,134 - RBF - INFO - train epoch 271 of total 5000 epoches
2020-03-23 17:01:41,101 - RBF - ERROR - loss 1.2940430998699857, in epoch 271, in step 199, in global step 135700, learning rate is 0.00015, taks 7.430599927902222 seconds
2020-03-23 17:01:46,086 - RBF - ERROR - loss 1.2940360428779603, in epoch 271, in step 399, in global step 135900, learning rate is 0.00015, taks 4.9853997230529785 seconds
2020-03-23 17:01:48,635 - RBF - INFO - train epoch 272 of total 5000 epoches
2020-03-23 17:01:53,605 - RBF - ERROR - loss 1.294028395123789, in epoch 272, in step 199, in global step 136200, learning rate is 0.00015, taks 7.519200086593628 seconds
2020-03-23 17:01:58,558 - RBF - ERROR - loss 1.2940333355331899, in epoch 272, in step 399, in global step 136400, learning rate is 0.00015, taks 4.952200174331665 seconds
2020-03-23 17:02:01,040 - RBF - INFO - train epoch 273 of total 5000 epoches
2020-03-23 17:02:06,031 - RBF - ERROR - loss 1.2940327120683839, in epoch 273, in step 199, in global step 136700, learning rate is 0.00015, taks 7.47379994392395 seconds
2020-03-23 17:02:10,988 - RBF - ERROR - loss 1.294016296654766, in epoch 273, in step 399, in global step 136900, learning rate is 0.00015, taks 4.956199884414673 seconds
2020-03-23 17:02:13,499 - RBF - INFO - train epoch 274 of total 5000 epoches
2020-03-23 17:02:18,453 - RBF - ERROR - loss 1.294025609710977, in epoch 274, in step 199, in global step 137200, learning rate is 0.00015, taks 7.46560001373291 seconds
2020-03-23 17:02:23,406 - RBF - ERROR - loss 1.2940385731904032, in epoch 274, in step 399, in global step 137400, learning rate is 0.00015, taks 4.952200174331665 seconds
2020-03-23 17:02:25,897 - RBF - INFO - train epoch 275 of total 5000 epoches
2020-03-23 17:02:30,878 - RBF - ERROR - loss 1.2939996282244943, in epoch 275, in step 199, in global step 137700, learning rate is 0.00015, taks 7.471400022506714 seconds
2020-03-23 17:02:35,871 - RBF - ERROR - loss 1.2939969858921878, in epoch 275, in step 399, in global step 137900, learning rate is 0.00015, taks 4.993199825286865 seconds
2020-03-23 17:02:38,350 - RBF - INFO - train epoch 276 of total 5000 epoches
2020-03-23 17:02:43,313 - RBF - ERROR - loss 1.2940560479687477, in epoch 276, in step 199, in global step 138200, learning rate is 0.00015, taks 7.442000150680542 seconds
2020-03-23 17:02:48,292 - RBF - ERROR - loss 1.2939873636351942, in epoch 276, in step 399, in global step 138400, learning rate is 0.00015, taks 4.978799819946289 seconds
2020-03-23 17:02:50,818 - RBF - INFO - train epoch 277 of total 5000 epoches
2020-03-23 17:02:55,779 - RBF - ERROR - loss 1.293999682533784, in epoch 277, in step 199, in global step 138700, learning rate is 0.00015, taks 7.486800193786621 seconds
2020-03-23 17:03:00,745 - RBF - ERROR - loss 1.293994279340785, in epoch 277, in step 399, in global step 138900, learning rate is 0.00015, taks 4.9659998416900635 seconds
2020-03-23 17:03:03,237 - RBF - INFO - train epoch 278 of total 5000 epoches
2020-03-23 17:03:08,204 - RBF - ERROR - loss 1.2939698695638868, in epoch 278, in step 199, in global step 139200, learning rate is 0.00015, taks 7.459600210189819 seconds
2020-03-23 17:03:13,172 - RBF - ERROR - loss 1.2939733372712605, in epoch 278, in step 399, in global step 139400, learning rate is 0.00015, taks 4.968199729919434 seconds
2020-03-23 17:03:15,650 - RBF - INFO - train epoch 279 of total 5000 epoches
2020-03-23 17:03:20,635 - RBF - ERROR - loss 1.2940063190178803, in epoch 279, in step 199, in global step 139700, learning rate is 0.00015, taks 7.4628002643585205 seconds
2020-03-23 17:03:25,585 - RBF - ERROR - loss 1.2939783252592592, in epoch 279, in step 399, in global step 139900, learning rate is 0.00015, taks 4.94980001449585 seconds
2020-03-23 17:03:30,406 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 279. learning_rate is 0.00015, loss is 1.2939588326289628
2020-03-23 17:03:30,407 - RBF - INFO - train epoch 280 of total 5000 epoches
2020-03-23 17:03:36,978 - RBF - ERROR - loss 1.2939502907789475, in epoch 280, in step 199, in global step 140200, learning rate is 0.00015, taks 11.39299988746643 seconds
2020-03-23 17:03:42,799 - RBF - ERROR - loss 1.294062874736749, in epoch 280, in step 399, in global step 140400, learning rate is 0.00015, taks 5.820200204849243 seconds
2020-03-23 17:03:45,693 - RBF - INFO - train epoch 281 of total 5000 epoches
2020-03-23 17:03:51,118 - RBF - ERROR - loss 1.2939366169725075, in epoch 281, in step 199, in global step 140700, learning rate is 0.00015, taks 8.318599939346313 seconds
2020-03-23 17:03:56,070 - RBF - ERROR - loss 1.293971563863188, in epoch 281, in step 399, in global step 140900, learning rate is 0.00015, taks 4.95199990272522 seconds
2020-03-23 17:03:58,558 - RBF - INFO - train epoch 282 of total 5000 epoches
2020-03-23 17:04:03,655 - RBF - ERROR - loss 1.2939716603970213, in epoch 282, in step 199, in global step 141200, learning rate is 0.00015, taks 7.584600210189819 seconds
2020-03-23 17:04:07,755 - RBF - ERROR - loss 1.293998925218305, in epoch 282, in step 399, in global step 141400, learning rate is 0.00015, taks 4.09939980506897 seconds
2020-03-23 17:04:09,142 - RBF - INFO - train epoch 283 of total 5000 epoches
2020-03-23 17:04:11,894 - RBF - ERROR - loss 1.2939432808048814, in epoch 283, in step 199, in global step 141700, learning rate is 0.00015, taks 4.13919997215271 seconds
2020-03-23 17:04:14,690 - RBF - ERROR - loss 1.2939303182588553, in epoch 283, in step 399, in global step 141900, learning rate is 0.00015, taks 2.796400308609009 seconds
2020-03-23 17:04:16,065 - RBF - INFO - train epoch 284 of total 5000 epoches
2020-03-23 17:04:18,835 - RBF - ERROR - loss 1.293907501018976, in epoch 284, in step 199, in global step 142200, learning rate is 0.00015, taks 4.143399715423584 seconds
2020-03-23 17:04:21,451 - RBF - ERROR - loss 1.2939498104476332, in epoch 284, in step 399, in global step 142400, learning rate is 0.00015, taks 2.616600275039673 seconds
2020-03-23 17:04:22,701 - RBF - INFO - train epoch 285 of total 5000 epoches
2020-03-23 17:04:25,206 - RBF - ERROR - loss 1.29393698274987, in epoch 285, in step 199, in global step 142700, learning rate is 0.00015, taks 3.754199981689453 seconds
2020-03-23 17:04:27,721 - RBF - ERROR - loss 1.2939523213044328, in epoch 285, in step 399, in global step 142900, learning rate is 0.00015, taks 2.514400005340576 seconds
2020-03-23 17:04:28,968 - RBF - INFO - train epoch 286 of total 5000 epoches
2020-03-23 17:04:31,470 - RBF - ERROR - loss 1.2939403745851623, in epoch 286, in step 199, in global step 143200, learning rate is 0.00015, taks 3.7494001388549805 seconds
2020-03-23 17:04:33,987 - RBF - ERROR - loss 1.2938906456199377, in epoch 286, in step 399, in global step 143400, learning rate is 0.00015, taks 2.51639986038208 seconds
2020-03-23 17:04:35,242 - RBF - INFO - train epoch 287 of total 5000 epoches
2020-03-23 17:04:37,745 - RBF - ERROR - loss 1.2938915673132563, in epoch 287, in step 199, in global step 143700, learning rate is 0.00015, taks 3.757200002670288 seconds
2020-03-23 17:04:40,247 - RBF - ERROR - loss 1.2938857359374014, in epoch 287, in step 399, in global step 143900, learning rate is 0.00015, taks 2.5016000270843506 seconds
2020-03-23 17:04:41,498 - RBF - INFO - train epoch 288 of total 5000 epoches
2020-03-23 17:04:43,999 - RBF - ERROR - loss 1.2938823299759301, in epoch 288, in step 199, in global step 144200, learning rate is 0.00015, taks 3.75219988822937 seconds
2020-03-23 17:04:46,500 - RBF - ERROR - loss 1.293872778242856, in epoch 288, in step 399, in global step 144400, learning rate is 0.00015, taks 2.5016000270843506 seconds
2020-03-23 17:04:47,750 - RBF - INFO - train epoch 289 of total 5000 epoches
2020-03-23 17:04:50,282 - RBF - ERROR - loss 1.2938689452967458, in epoch 289, in step 199, in global step 144700, learning rate is 0.00015, taks 3.780600070953369 seconds
2020-03-23 17:04:52,777 - RBF - ERROR - loss 1.2939229924700535, in epoch 289, in step 399, in global step 144900, learning rate is 0.00015, taks 2.4953999519348145 seconds
2020-03-23 17:04:54,031 - RBF - INFO - train epoch 290 of total 5000 epoches
2020-03-23 17:04:56,538 - RBF - ERROR - loss 1.2938538950625746, in epoch 290, in step 199, in global step 145200, learning rate is 0.00015, taks 3.7604000568389893 seconds
2020-03-23 17:04:59,045 - RBF - ERROR - loss 1.2938504161614575, in epoch 290, in step 399, in global step 145400, learning rate is 0.00015, taks 2.5064001083374023 seconds
2020-03-23 17:05:00,298 - RBF - INFO - train epoch 291 of total 5000 epoches
2020-03-23 17:05:02,817 - RBF - ERROR - loss 1.2938467682944783, in epoch 291, in step 199, in global step 145700, learning rate is 0.00015, taks 3.772199869155884 seconds
2020-03-23 17:05:05,340 - RBF - ERROR - loss 1.2938426620768095, in epoch 291, in step 399, in global step 145900, learning rate is 0.00015, taks 2.5226001739501953 seconds
2020-03-23 17:05:06,583 - RBF - INFO - train epoch 292 of total 5000 epoches
2020-03-23 17:05:09,100 - RBF - ERROR - loss 1.293837069660104, in epoch 292, in step 199, in global step 146200, learning rate is 0.00015, taks 3.760200023651123 seconds
2020-03-23 17:05:11,599 - RBF - ERROR - loss 1.2938406834246008, in epoch 292, in step 399, in global step 146400, learning rate is 0.00015, taks 2.497799873352051 seconds
2020-03-23 17:05:12,855 - RBF - INFO - train epoch 293 of total 5000 epoches
2020-03-23 17:05:15,371 - RBF - ERROR - loss 1.2938833963392045, in epoch 293, in step 199, in global step 146700, learning rate is 0.00015, taks 3.7720000743865967 seconds
2020-03-23 17:05:17,906 - RBF - ERROR - loss 1.29393452321597, in epoch 293, in step 399, in global step 146900, learning rate is 0.00015, taks 2.535400152206421 seconds
2020-03-23 17:05:19,160 - RBF - INFO - train epoch 294 of total 5000 epoches
2020-03-23 17:05:21,662 - RBF - ERROR - loss 1.2938174456211415, in epoch 294, in step 199, in global step 147200, learning rate is 0.00015, taks 3.755200147628784 seconds
2020-03-23 17:05:24,164 - RBF - ERROR - loss 1.293886578946892, in epoch 294, in step 399, in global step 147400, learning rate is 0.00015, taks 2.5025997161865234 seconds
2020-03-23 17:05:25,432 - RBF - INFO - train epoch 295 of total 5000 epoches
2020-03-23 17:05:27,942 - RBF - ERROR - loss 1.2938088903454052, in epoch 295, in step 199, in global step 147700, learning rate is 0.00015, taks 3.778200149536133 seconds
2020-03-23 17:05:30,450 - RBF - ERROR - loss 1.2938034821449536, in epoch 295, in step 399, in global step 147900, learning rate is 0.00015, taks 2.5075998306274414 seconds
2020-03-23 17:05:31,704 - RBF - INFO - train epoch 296 of total 5000 epoches
2020-03-23 17:05:34,208 - RBF - ERROR - loss 1.2938255169809056, in epoch 296, in step 199, in global step 148200, learning rate is 0.00015, taks 3.758200168609619 seconds
2020-03-23 17:05:36,715 - RBF - ERROR - loss 1.2938344421811898, in epoch 296, in step 399, in global step 148400, learning rate is 0.00015, taks 2.5053999423980713 seconds
2020-03-23 17:05:37,978 - RBF - INFO - train epoch 297 of total 5000 epoches
2020-03-23 17:05:40,481 - RBF - ERROR - loss 1.2938012558473677, in epoch 297, in step 199, in global step 148700, learning rate is 0.00015, taks 3.766400098800659 seconds
2020-03-23 17:05:42,991 - RBF - ERROR - loss 1.2938472615359864, in epoch 297, in step 399, in global step 148900, learning rate is 0.00015, taks 2.5104000568389893 seconds
2020-03-23 17:05:44,241 - RBF - INFO - train epoch 298 of total 5000 epoches
2020-03-23 17:05:46,745 - RBF - ERROR - loss 1.2937863881203464, in epoch 298, in step 199, in global step 149200, learning rate is 0.00015, taks 3.753200054168701 seconds
2020-03-23 17:05:49,273 - RBF - ERROR - loss 1.2937822257916878, in epoch 298, in step 399, in global step 149400, learning rate is 0.00015, taks 2.528599739074707 seconds
2020-03-23 17:05:50,530 - RBF - INFO - train epoch 299 of total 5000 epoches
2020-03-23 17:05:53,023 - RBF - ERROR - loss 1.2938086103561108, in epoch 299, in step 199, in global step 149700, learning rate is 0.00015, taks 3.750200033187866 seconds
2020-03-23 17:05:55,527 - RBF - ERROR - loss 1.2937869685682715, in epoch 299, in step 399, in global step 149900, learning rate is 0.00015, taks 2.5036003589630127 seconds
2020-03-23 17:05:59,122 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 299. learning_rate is 0.00015, loss is 1.2938276030823956
2020-03-23 17:05:59,123 - RBF - INFO - train epoch 300 of total 5000 epoches
2020-03-23 17:06:05,094 - RBF - ERROR - loss 1.2937687527501172, in epoch 300, in step 199, in global step 150200, learning rate is 0.00015, taks 9.56659984588623 seconds
2020-03-23 17:06:10,910 - RBF - ERROR - loss 1.2937608894462083, in epoch 300, in step 399, in global step 150400, learning rate is 0.00015, taks 5.81660008430481 seconds
2020-03-23 17:06:13,831 - RBF - INFO - train epoch 301 of total 5000 epoches
2020-03-23 17:06:19,634 - RBF - ERROR - loss 1.2937685188165378, in epoch 301, in step 199, in global step 150700, learning rate is 0.00015, taks 8.723999977111816 seconds
2020-03-23 17:06:24,744 - RBF - ERROR - loss 1.2937514383181579, in epoch 301, in step 399, in global step 150900, learning rate is 0.00015, taks 5.108999967575073 seconds
2020-03-23 17:06:27,095 - RBF - INFO - train epoch 302 of total 5000 epoches
2020-03-23 17:06:31,727 - RBF - ERROR - loss 1.293762518962221, in epoch 302, in step 199, in global step 151200, learning rate is 0.00015, taks 6.982399940490723 seconds
2020-03-23 17:06:36,416 - RBF - ERROR - loss 1.2937724797334997, in epoch 302, in step 399, in global step 151400, learning rate is 0.00015, taks 4.689200162887573 seconds
2020-03-23 17:06:38,738 - RBF - INFO - train epoch 303 of total 5000 epoches
2020-03-23 17:06:43,430 - RBF - ERROR - loss 1.2938523458364855, in epoch 303, in step 199, in global step 151700, learning rate is 0.00015, taks 7.012599945068359 seconds
2020-03-23 17:06:48,074 - RBF - ERROR - loss 1.293733929386496, in epoch 303, in step 399, in global step 151900, learning rate is 0.00015, taks 4.643200159072876 seconds
2020-03-23 17:06:50,260 - RBF - INFO - train epoch 304 of total 5000 epoches
2020-03-23 17:06:54,399 - RBF - ERROR - loss 1.2937985597263841, in epoch 304, in step 199, in global step 152200, learning rate is 0.00015, taks 6.325799942016602 seconds
2020-03-23 17:06:58,538 - RBF - ERROR - loss 1.293740472413592, in epoch 304, in step 399, in global step 152400, learning rate is 0.00015, taks 4.138200044631958 seconds
2020-03-23 17:07:00,588 - RBF - INFO - train epoch 305 of total 5000 epoches
2020-03-23 17:07:04,744 - RBF - ERROR - loss 1.2937223733832013, in epoch 305, in step 199, in global step 152700, learning rate is 0.00015, taks 6.206599950790405 seconds
2020-03-23 17:07:08,892 - RBF - ERROR - loss 1.2937635864298371, in epoch 305, in step 399, in global step 152900, learning rate is 0.00015, taks 4.148199796676636 seconds
2020-03-23 17:07:10,957 - RBF - INFO - train epoch 306 of total 5000 epoches
2020-03-23 17:07:15,092 - RBF - ERROR - loss 1.2937176308472613, in epoch 306, in step 199, in global step 153200, learning rate is 0.00015, taks 6.199800252914429 seconds
2020-03-23 17:07:19,264 - RBF - ERROR - loss 1.2937127714173695, in epoch 306, in step 399, in global step 153400, learning rate is 0.00015, taks 4.172199726104736 seconds
2020-03-23 17:07:21,336 - RBF - INFO - train epoch 307 of total 5000 epoches
2020-03-23 17:07:25,475 - RBF - ERROR - loss 1.2937352188254025, in epoch 307, in step 199, in global step 153700, learning rate is 0.00015, taks 6.2108001708984375 seconds
2020-03-23 17:07:29,607 - RBF - ERROR - loss 1.2937153444022795, in epoch 307, in step 399, in global step 153900, learning rate is 0.00015, taks 4.131400108337402 seconds
2020-03-23 17:07:31,681 - RBF - INFO - train epoch 308 of total 5000 epoches
2020-03-23 17:07:35,822 - RBF - ERROR - loss 1.2937022561909925, in epoch 308, in step 199, in global step 154200, learning rate is 0.00015, taks 6.215399742126465 seconds
2020-03-23 17:07:39,984 - RBF - ERROR - loss 1.2937258808784526, in epoch 308, in step 399, in global step 154400, learning rate is 0.00015, taks 4.162200212478638 seconds
2020-03-23 17:07:42,054 - RBF - INFO - train epoch 309 of total 5000 epoches
2020-03-23 17:07:46,185 - RBF - ERROR - loss 1.2936899687073744, in epoch 309, in step 199, in global step 154700, learning rate is 0.00015, taks 6.200999975204468 seconds
2020-03-23 17:07:50,365 - RBF - ERROR - loss 1.2936889823798172, in epoch 309, in step 399, in global step 154900, learning rate is 0.00015, taks 4.179199934005737 seconds
2020-03-23 17:07:52,425 - RBF - INFO - train epoch 310 of total 5000 epoches
2020-03-23 17:07:56,566 - RBF - ERROR - loss 1.2937388265448841, in epoch 310, in step 199, in global step 155200, learning rate is 0.00015, taks 6.200199842453003 seconds
2020-03-23 17:08:00,727 - RBF - ERROR - loss 1.2936959248711244, in epoch 310, in step 399, in global step 155400, learning rate is 0.00015, taks 4.1600000858306885 seconds
2020-03-23 17:08:02,791 - RBF - INFO - train epoch 311 of total 5000 epoches
2020-03-23 17:08:06,936 - RBF - ERROR - loss 1.293674862167161, in epoch 311, in step 199, in global step 155700, learning rate is 0.00015, taks 6.209400177001953 seconds
2020-03-23 17:08:11,086 - RBF - ERROR - loss 1.2936687735333419, in epoch 311, in step 399, in global step 155900, learning rate is 0.00015, taks 4.150199890136719 seconds
2020-03-23 17:08:13,157 - RBF - INFO - train epoch 312 of total 5000 epoches
2020-03-23 17:08:17,287 - RBF - ERROR - loss 1.2936671967357571, in epoch 312, in step 199, in global step 156200, learning rate is 0.00015, taks 6.1987998485565186 seconds
2020-03-23 17:08:21,501 - RBF - ERROR - loss 1.2936677891375632, in epoch 312, in step 399, in global step 156400, learning rate is 0.00015, taks 4.2139997482299805 seconds
2020-03-23 17:08:23,581 - RBF - INFO - train epoch 313 of total 5000 epoches
2020-03-23 17:08:27,721 - RBF - ERROR - loss 1.2936674849004992, in epoch 313, in step 199, in global step 156700, learning rate is 0.00015, taks 6.218600273132324 seconds
2020-03-23 17:08:31,854 - RBF - ERROR - loss 1.2936815875272198, in epoch 313, in step 399, in global step 156900, learning rate is 0.00015, taks 4.13319993019104 seconds
2020-03-23 17:08:33,948 - RBF - INFO - train epoch 314 of total 5000 epoches
2020-03-23 17:08:38,095 - RBF - ERROR - loss 1.2936534547957912, in epoch 314, in step 199, in global step 157200, learning rate is 0.00015, taks 6.241199970245361 seconds
2020-03-23 17:08:42,220 - RBF - ERROR - loss 1.29371493320991, in epoch 314, in step 399, in global step 157400, learning rate is 0.00015, taks 4.124199867248535 seconds
2020-03-23 17:08:44,302 - RBF - INFO - train epoch 315 of total 5000 epoches
2020-03-23 17:08:48,426 - RBF - ERROR - loss 1.2937408758036713, in epoch 315, in step 199, in global step 157700, learning rate is 0.00015, taks 6.205400228500366 seconds
2020-03-23 17:08:52,579 - RBF - ERROR - loss 1.293656667948012, in epoch 315, in step 399, in global step 157900, learning rate is 0.00015, taks 4.153799772262573 seconds
2020-03-23 17:08:54,669 - RBF - INFO - train epoch 316 of total 5000 epoches
2020-03-23 17:08:58,809 - RBF - ERROR - loss 1.2936679737156573, in epoch 316, in step 199, in global step 158200, learning rate is 0.00015, taks 6.230000257492065 seconds
2020-03-23 17:09:02,991 - RBF - ERROR - loss 1.2936318656265973, in epoch 316, in step 399, in global step 158400, learning rate is 0.00015, taks 4.180200099945068 seconds
2020-03-23 17:09:05,067 - RBF - INFO - train epoch 317 of total 5000 epoches
2020-03-23 17:09:09,217 - RBF - ERROR - loss 1.2936739302477416, in epoch 317, in step 199, in global step 158700, learning rate is 0.00015, taks 6.225600004196167 seconds
2020-03-23 17:09:13,355 - RBF - ERROR - loss 1.293637891438685, in epoch 317, in step 399, in global step 158900, learning rate is 0.00015, taks 4.136199951171875 seconds
2020-03-23 17:09:15,429 - RBF - INFO - train epoch 318 of total 5000 epoches
2020-03-23 17:09:19,572 - RBF - ERROR - loss 1.2936809570616987, in epoch 318, in step 199, in global step 159200, learning rate is 0.00015, taks 6.216200113296509 seconds
2020-03-23 17:09:23,703 - RBF - ERROR - loss 1.2936272460347604, in epoch 318, in step 399, in global step 159400, learning rate is 0.00015, taks 4.13100004196167 seconds
2020-03-23 17:09:25,776 - RBF - INFO - train epoch 319 of total 5000 epoches
2020-03-23 17:09:29,920 - RBF - ERROR - loss 1.2936868893452358, in epoch 319, in step 199, in global step 159700, learning rate is 0.00015, taks 6.2170000076293945 seconds
2020-03-23 17:09:34,055 - RBF - ERROR - loss 1.2936637094579795, in epoch 319, in step 399, in global step 159900, learning rate is 0.00015, taks 4.135599851608276 seconds
2020-03-23 17:09:37,796 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 319. learning_rate is 0.00015, loss is 1.2936176432172117
2020-03-23 17:09:37,797 - RBF - INFO - train epoch 320 of total 5000 epoches
2020-03-23 17:09:41,505 - RBF - ERROR - loss 1.2936837831905104, in epoch 320, in step 199, in global step 160200, learning rate is 0.00015, taks 7.44980001449585 seconds
2020-03-23 17:09:45,045 - RBF - ERROR - loss 1.2936490477717595, in epoch 320, in step 399, in global step 160400, learning rate is 0.00015, taks 3.539799928665161 seconds
2020-03-23 17:09:46,744 - RBF - INFO - train epoch 321 of total 5000 epoches
2020-03-23 17:09:50,105 - RBF - ERROR - loss 1.2935978086415227, in epoch 321, in step 199, in global step 160700, learning rate is 0.00015, taks 5.05899977684021 seconds
2020-03-23 17:09:53,380 - RBF - ERROR - loss 1.2936112553195478, in epoch 321, in step 399, in global step 160900, learning rate is 0.00015, taks 3.2750000953674316 seconds
2020-03-23 17:09:55,045 - RBF - INFO - train epoch 322 of total 5000 epoches
2020-03-23 17:09:58,333 - RBF - ERROR - loss 1.2935907130191364, in epoch 322, in step 199, in global step 161200, learning rate is 0.00015, taks 4.952800035476685 seconds
2020-03-23 17:10:01,641 - RBF - ERROR - loss 1.2935938018733528, in epoch 322, in step 399, in global step 161400, learning rate is 0.00015, taks 3.308199882507324 seconds
2020-03-23 17:10:03,287 - RBF - INFO - train epoch 323 of total 5000 epoches
2020-03-23 17:10:06,583 - RBF - ERROR - loss 1.2936198087453132, in epoch 323, in step 199, in global step 161700, learning rate is 0.00015, taks 4.942200183868408 seconds
2020-03-23 17:10:09,884 - RBF - ERROR - loss 1.2936238819481702, in epoch 323, in step 399, in global step 161900, learning rate is 0.00015, taks 3.3011999130249023 seconds
2020-03-23 17:10:11,534 - RBF - INFO - train epoch 324 of total 5000 epoches
2020-03-23 17:10:14,828 - RBF - ERROR - loss 1.2935731804482213, in epoch 324, in step 199, in global step 162200, learning rate is 0.00015, taks 4.944000005722046 seconds
2020-03-23 17:10:18,126 - RBF - ERROR - loss 1.2935621909254484, in epoch 324, in step 399, in global step 162400, learning rate is 0.00015, taks 3.2973999977111816 seconds
2020-03-23 17:10:19,802 - RBF - INFO - train epoch 325 of total 5000 epoches
2020-03-23 17:10:23,096 - RBF - ERROR - loss 1.29360620424229, in epoch 325, in step 199, in global step 162700, learning rate is 0.00015, taks 4.9700000286102295 seconds
2020-03-23 17:10:26,394 - RBF - ERROR - loss 1.2935622003444742, in epoch 325, in step 399, in global step 162900, learning rate is 0.00015, taks 3.2983999252319336 seconds
2020-03-23 17:10:28,047 - RBF - INFO - train epoch 326 of total 5000 epoches
2020-03-23 17:10:31,326 - RBF - ERROR - loss 1.2937071431143503, in epoch 326, in step 199, in global step 163200, learning rate is 0.00015, taks 4.932000160217285 seconds
2020-03-23 17:10:34,616 - RBF - ERROR - loss 1.2936030591138918, in epoch 326, in step 399, in global step 163400, learning rate is 0.00015, taks 3.289599895477295 seconds
2020-03-23 17:10:36,267 - RBF - INFO - train epoch 327 of total 5000 epoches
2020-03-23 17:10:39,573 - RBF - ERROR - loss 1.293636002160651, in epoch 327, in step 199, in global step 163700, learning rate is 0.00015, taks 4.957799911499023 seconds
2020-03-23 17:10:42,867 - RBF - ERROR - loss 1.2936050301667588, in epoch 327, in step 399, in global step 163900, learning rate is 0.00015, taks 3.2922000885009766 seconds
2020-03-23 17:10:44,505 - RBF - INFO - train epoch 328 of total 5000 epoches
2020-03-23 17:10:47,812 - RBF - ERROR - loss 1.293571028267015, in epoch 328, in step 199, in global step 164200, learning rate is 0.00015, taks 4.944999933242798 seconds
2020-03-23 17:10:51,122 - RBF - ERROR - loss 1.2935411236409213, in epoch 328, in step 399, in global step 164400, learning rate is 0.00015, taks 3.3104000091552734 seconds
2020-03-23 17:10:52,759 - RBF - INFO - train epoch 329 of total 5000 epoches
2020-03-23 17:10:56,043 - RBF - ERROR - loss 1.2935633258061299, in epoch 329, in step 199, in global step 164700, learning rate is 0.00015, taks 4.92140007019043 seconds
2020-03-23 17:10:59,350 - RBF - ERROR - loss 1.2935676137077396, in epoch 329, in step 399, in global step 164900, learning rate is 0.00015, taks 3.3065998554229736 seconds
2020-03-23 17:11:00,990 - RBF - INFO - train epoch 330 of total 5000 epoches
2020-03-23 17:11:04,292 - RBF - ERROR - loss 1.2936064883017546, in epoch 330, in step 199, in global step 165200, learning rate is 0.00015, taks 4.941999912261963 seconds
2020-03-23 17:11:07,586 - RBF - ERROR - loss 1.2935292546034303, in epoch 330, in step 399, in global step 165400, learning rate is 0.00015, taks 3.2943999767303467 seconds
2020-03-23 17:11:09,232 - RBF - INFO - train epoch 331 of total 5000 epoches
2020-03-23 17:11:12,518 - RBF - ERROR - loss 1.293563754720195, in epoch 331, in step 199, in global step 165700, learning rate is 0.00015, taks 4.931999921798706 seconds
2020-03-23 17:11:15,803 - RBF - ERROR - loss 1.2935156335939377, in epoch 331, in step 399, in global step 165900, learning rate is 0.00015, taks 3.2842001914978027 seconds
2020-03-23 17:11:17,441 - RBF - INFO - train epoch 332 of total 5000 epoches
2020-03-23 17:11:20,746 - RBF - ERROR - loss 1.2935284517656784, in epoch 332, in step 199, in global step 166200, learning rate is 0.00015, taks 4.941999912261963 seconds
2020-03-23 17:11:24,039 - RBF - ERROR - loss 1.2935109840691532, in epoch 332, in step 399, in global step 166400, learning rate is 0.00015, taks 3.2923998832702637 seconds
2020-03-23 17:11:25,699 - RBF - INFO - train epoch 333 of total 5000 epoches
2020-03-23 17:11:28,982 - RBF - ERROR - loss 1.2935071896049755, in epoch 333, in step 199, in global step 166700, learning rate is 0.00015, taks 4.943399906158447 seconds
2020-03-23 17:11:32,279 - RBF - ERROR - loss 1.2935306985282846, in epoch 333, in step 399, in global step 166900, learning rate is 0.00015, taks 3.296400308609009 seconds
2020-03-23 17:11:33,937 - RBF - INFO - train epoch 334 of total 5000 epoches
2020-03-23 17:11:37,233 - RBF - ERROR - loss 1.2934972943844345, in epoch 334, in step 199, in global step 167200, learning rate is 0.00015, taks 4.953999757766724 seconds
2020-03-23 17:11:40,518 - RBF - ERROR - loss 1.2934933610819594, in epoch 334, in step 399, in global step 167400, learning rate is 0.00015, taks 3.285400152206421 seconds
2020-03-23 17:11:42,180 - RBF - INFO - train epoch 335 of total 5000 epoches
2020-03-23 17:11:45,468 - RBF - ERROR - loss 1.2935482174679669, in epoch 335, in step 199, in global step 167700, learning rate is 0.00015, taks 4.948999881744385 seconds
2020-03-23 17:11:48,757 - RBF - ERROR - loss 1.293488031493567, in epoch 335, in step 399, in global step 167900, learning rate is 0.00015, taks 3.2891998291015625 seconds
2020-03-23 17:11:50,466 - RBF - INFO - train epoch 336 of total 5000 epoches
2020-03-23 17:11:53,751 - RBF - ERROR - loss 1.293516303126022, in epoch 336, in step 199, in global step 168200, learning rate is 0.00015, taks 4.994000196456909 seconds
2020-03-23 17:11:57,027 - RBF - ERROR - loss 1.2935318195493537, in epoch 336, in step 399, in global step 168400, learning rate is 0.00015, taks 3.275399923324585 seconds
2020-03-23 17:11:58,676 - RBF - INFO - train epoch 337 of total 5000 epoches
2020-03-23 17:12:01,977 - RBF - ERROR - loss 1.293506128315042, in epoch 337, in step 199, in global step 168700, learning rate is 0.00015, taks 4.948999881744385 seconds
2020-03-23 17:12:05,270 - RBF - ERROR - loss 1.2935669901224294, in epoch 337, in step 399, in global step 168900, learning rate is 0.00015, taks 3.2934000492095947 seconds
2020-03-23 17:12:06,913 - RBF - INFO - train epoch 338 of total 5000 epoches
2020-03-23 17:12:10,211 - RBF - ERROR - loss 1.2934705729056089, in epoch 338, in step 199, in global step 169200, learning rate is 0.00015, taks 4.940000057220459 seconds
2020-03-23 17:12:13,505 - RBF - ERROR - loss 1.293525920714598, in epoch 338, in step 399, in global step 169400, learning rate is 0.00015, taks 3.2934000492095947 seconds
2020-03-23 17:12:15,153 - RBF - INFO - train epoch 339 of total 5000 epoches
2020-03-23 17:12:18,445 - RBF - ERROR - loss 1.2935050032739217, in epoch 339, in step 199, in global step 169700, learning rate is 0.00015, taks 4.938000202178955 seconds
2020-03-23 17:12:21,792 - RBF - ERROR - loss 1.2935340516780802, in epoch 339, in step 399, in global step 169900, learning rate is 0.00015, taks 3.347599983215332 seconds
2020-03-23 17:12:25,822 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 339. learning_rate is 0.00015, loss is 1.2935283274007954
2020-03-23 17:12:25,823 - RBF - INFO - train epoch 340 of total 5000 epoches
2020-03-23 17:12:33,185 - RBF - ERROR - loss 1.2934947513438058, in epoch 340, in step 199, in global step 170200, learning rate is 0.00015, taks 11.392400026321411 seconds
2020-03-23 17:12:39,593 - RBF - ERROR - loss 1.2934722243091397, in epoch 340, in step 399, in global step 170400, learning rate is 0.00015, taks 6.408799886703491 seconds
2020-03-23 17:12:42,812 - RBF - INFO - train epoch 341 of total 5000 epoches
2020-03-23 17:12:49,232 - RBF - ERROR - loss 1.2935293998867743, in epoch 341, in step 199, in global step 170700, learning rate is 0.00015, taks 9.63860011100769 seconds
2020-03-23 17:12:55,054 - RBF - ERROR - loss 1.2934399193039565, in epoch 341, in step 399, in global step 170900, learning rate is 0.00015, taks 5.822000026702881 seconds
2020-03-23 17:12:57,973 - RBF - INFO - train epoch 342 of total 5000 epoches
2020-03-23 17:13:03,784 - RBF - ERROR - loss 1.2935107051008532, in epoch 342, in step 199, in global step 171200, learning rate is 0.00015, taks 8.72979998588562 seconds
2020-03-23 17:13:09,626 - RBF - ERROR - loss 1.2936620256030293, in epoch 342, in step 399, in global step 171400, learning rate is 0.00015, taks 5.842200040817261 seconds
2020-03-23 17:13:12,501 - RBF - INFO - train epoch 343 of total 5000 epoches
2020-03-23 17:13:18,377 - RBF - ERROR - loss 1.2934459572469736, in epoch 343, in step 199, in global step 171700, learning rate is 0.00015, taks 8.750400066375732 seconds
2020-03-23 17:13:24,182 - RBF - ERROR - loss 1.293430225055061, in epoch 343, in step 399, in global step 171900, learning rate is 0.00015, taks 5.804799795150757 seconds
2020-03-23 17:13:27,102 - RBF - INFO - train epoch 344 of total 5000 epoches
2020-03-23 17:13:32,932 - RBF - ERROR - loss 1.2934395912198617, in epoch 344, in step 199, in global step 172200, learning rate is 0.00015, taks 8.749799966812134 seconds
2020-03-23 17:13:38,767 - RBF - ERROR - loss 1.2934483603505416, in epoch 344, in step 399, in global step 172400, learning rate is 0.00015, taks 5.835200071334839 seconds
2020-03-23 17:13:41,680 - RBF - INFO - train epoch 345 of total 5000 epoches
2020-03-23 17:13:47,480 - RBF - ERROR - loss 1.2934321491355678, in epoch 345, in step 199, in global step 172700, learning rate is 0.00015, taks 8.712000370025635 seconds
2020-03-23 17:13:53,321 - RBF - ERROR - loss 1.2934766081463311, in epoch 345, in step 399, in global step 172900, learning rate is 0.00015, taks 5.840199947357178 seconds
2020-03-23 17:13:56,239 - RBF - INFO - train epoch 346 of total 5000 epoches
2020-03-23 17:14:02,051 - RBF - ERROR - loss 1.293417168289792, in epoch 346, in step 199, in global step 173200, learning rate is 0.00015, taks 8.729799747467041 seconds
2020-03-23 17:14:07,874 - RBF - ERROR - loss 1.293436161770887, in epoch 346, in step 399, in global step 173400, learning rate is 0.00015, taks 5.822400093078613 seconds
2020-03-23 17:14:10,799 - RBF - INFO - train epoch 347 of total 5000 epoches
2020-03-23 17:14:16,627 - RBF - ERROR - loss 1.2934522788992617, in epoch 347, in step 199, in global step 173700, learning rate is 0.00015, taks 8.75379991531372 seconds
2020-03-23 17:14:22,424 - RBF - ERROR - loss 1.2934192354028577, in epoch 347, in step 399, in global step 173900, learning rate is 0.00015, taks 5.7962000370025635 seconds
2020-03-23 17:14:25,340 - RBF - INFO - train epoch 348 of total 5000 epoches
2020-03-23 17:14:31,148 - RBF - ERROR - loss 1.2934388158093282, in epoch 348, in step 199, in global step 174200, learning rate is 0.00015, taks 8.724400043487549 seconds
2020-03-23 17:14:36,944 - RBF - ERROR - loss 1.293481493071075, in epoch 348, in step 399, in global step 174400, learning rate is 0.00015, taks 5.794600009918213 seconds
2020-03-23 17:14:39,864 - RBF - INFO - train epoch 349 of total 5000 epoches
2020-03-23 17:14:45,675 - RBF - ERROR - loss 1.293437856098912, in epoch 349, in step 199, in global step 174700, learning rate is 0.00015, taks 8.729999780654907 seconds
2020-03-23 17:14:51,553 - RBF - ERROR - loss 1.2934132904101265, in epoch 349, in step 399, in global step 174900, learning rate is 0.00015, taks 5.8788001537323 seconds
2020-03-23 17:14:54,494 - RBF - INFO - train epoch 350 of total 5000 epoches
2020-03-23 17:15:00,319 - RBF - ERROR - loss 1.2933918081656288, in epoch 350, in step 199, in global step 175200, learning rate is 0.00015, taks 8.76579999923706 seconds
2020-03-23 17:15:06,187 - RBF - ERROR - loss 1.293408536251848, in epoch 350, in step 399, in global step 175400, learning rate is 0.00015, taks 5.867799997329712 seconds
2020-03-23 17:15:09,113 - RBF - INFO - train epoch 351 of total 5000 epoches
2020-03-23 17:15:14,944 - RBF - ERROR - loss 1.2933847914373686, in epoch 351, in step 199, in global step 175700, learning rate is 0.00015, taks 8.756399869918823 seconds
2020-03-23 17:15:20,777 - RBF - ERROR - loss 1.2934438767931244, in epoch 351, in step 399, in global step 175900, learning rate is 0.00015, taks 5.832600116729736 seconds
2020-03-23 17:15:23,675 - RBF - INFO - train epoch 352 of total 5000 epoches
2020-03-23 17:15:29,522 - RBF - ERROR - loss 1.2933776280136133, in epoch 352, in step 199, in global step 176200, learning rate is 0.00015, taks 8.743800163269043 seconds
2020-03-23 17:15:35,337 - RBF - ERROR - loss 1.2933956598754628, in epoch 352, in step 399, in global step 176400, learning rate is 0.00015, taks 5.813800096511841 seconds
2020-03-23 17:15:38,269 - RBF - INFO - train epoch 353 of total 5000 epoches
2020-03-23 17:15:44,078 - RBF - ERROR - loss 1.293410606200596, in epoch 353, in step 199, in global step 176700, learning rate is 0.00015, taks 8.74180006980896 seconds
2020-03-23 17:15:49,861 - RBF - ERROR - loss 1.2935639938756807, in epoch 353, in step 399, in global step 176900, learning rate is 0.00015, taks 5.782599925994873 seconds
2020-03-23 17:15:52,341 - RBF - INFO - train epoch 354 of total 5000 epoches
2020-03-23 17:15:57,302 - RBF - ERROR - loss 1.2933641667020046, in epoch 354, in step 199, in global step 177200, learning rate is 0.00015, taks 7.440799951553345 seconds
2020-03-23 17:16:02,294 - RBF - ERROR - loss 1.293499299595058, in epoch 354, in step 399, in global step 177400, learning rate is 0.00015, taks 4.991999864578247 seconds
2020-03-23 17:16:04,796 - RBF - INFO - train epoch 355 of total 5000 epoches
2020-03-23 17:16:09,781 - RBF - ERROR - loss 1.2933569661837747, in epoch 355, in step 199, in global step 177700, learning rate is 0.00015, taks 7.486400127410889 seconds
2020-03-23 17:16:14,764 - RBF - ERROR - loss 1.2933713690968125, in epoch 355, in step 399, in global step 177900, learning rate is 0.00015, taks 4.983000040054321 seconds
2020-03-23 17:16:17,253 - RBF - INFO - train epoch 356 of total 5000 epoches
2020-03-23 17:16:22,251 - RBF - ERROR - loss 1.2933900599433872, in epoch 356, in step 199, in global step 178200, learning rate is 0.00015, taks 7.485599994659424 seconds
2020-03-23 17:16:27,245 - RBF - ERROR - loss 1.2933715315988839, in epoch 356, in step 399, in global step 178400, learning rate is 0.00015, taks 4.994199991226196 seconds
2020-03-23 17:16:29,736 - RBF - INFO - train epoch 357 of total 5000 epoches
2020-03-23 17:16:34,715 - RBF - ERROR - loss 1.2933611788060433, in epoch 357, in step 199, in global step 178700, learning rate is 0.00015, taks 7.46940016746521 seconds
2020-03-23 17:16:39,697 - RBF - ERROR - loss 1.2933723957253946, in epoch 357, in step 399, in global step 178900, learning rate is 0.00015, taks 4.981799840927124 seconds
2020-03-23 17:16:42,205 - RBF - INFO - train epoch 358 of total 5000 epoches
2020-03-23 17:16:47,182 - RBF - ERROR - loss 1.2933984516188348, in epoch 358, in step 199, in global step 179200, learning rate is 0.00015, taks 7.484000205993652 seconds
2020-03-23 17:16:52,213 - RBF - ERROR - loss 1.293324923105686, in epoch 358, in step 399, in global step 179400, learning rate is 0.00015, taks 5.029399871826172 seconds
2020-03-23 17:16:54,716 - RBF - INFO - train epoch 359 of total 5000 epoches
2020-03-23 17:16:59,730 - RBF - ERROR - loss 1.293334979864405, in epoch 359, in step 199, in global step 179700, learning rate is 0.00015, taks 7.5178000926971436 seconds
2020-03-23 17:17:04,721 - RBF - ERROR - loss 1.2933298018977906, in epoch 359, in step 399, in global step 179900, learning rate is 0.00015, taks 4.990000009536743 seconds
2020-03-23 17:17:09,667 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 359. learning_rate is 0.00015, loss is 1.29333918766549
2020-03-23 17:17:09,667 - RBF - INFO - train epoch 360 of total 5000 epoches
2020-03-23 17:17:16,164 - RBF - ERROR - loss 1.2933695892029888, in epoch 360, in step 199, in global step 180200, learning rate is 0.00015, taks 11.442399978637695 seconds
2020-03-23 17:17:22,445 - RBF - ERROR - loss 1.2933584685388952, in epoch 360, in step 399, in global step 180400, learning rate is 0.00015, taks 6.279800176620483 seconds
2020-03-23 17:17:25,589 - RBF - INFO - train epoch 361 of total 5000 epoches
2020-03-23 17:17:31,849 - RBF - ERROR - loss 1.2933204509956968, in epoch 361, in step 199, in global step 180700, learning rate is 0.00015, taks 9.404000043869019 seconds
2020-03-23 17:17:38,127 - RBF - ERROR - loss 1.2933388303431874, in epoch 361, in step 399, in global step 180900, learning rate is 0.00015, taks 6.278799772262573 seconds
2020-03-23 17:17:41,271 - RBF - INFO - train epoch 362 of total 5000 epoches
2020-03-23 17:17:47,525 - RBF - ERROR - loss 1.2933993079664914, in epoch 362, in step 199, in global step 181200, learning rate is 0.00015, taks 9.397400140762329 seconds
2020-03-23 17:17:53,452 - RBF - ERROR - loss 1.2933215508265428, in epoch 362, in step 399, in global step 181400, learning rate is 0.00015, taks 5.927200078964233 seconds
2020-03-23 17:17:56,311 - RBF - INFO - train epoch 363 of total 5000 epoches
2020-03-23 17:18:02,049 - RBF - ERROR - loss 1.2932957762938473, in epoch 363, in step 199, in global step 181700, learning rate is 0.00015, taks 8.59660005569458 seconds
2020-03-23 17:18:07,788 - RBF - ERROR - loss 1.2933531228832558, in epoch 363, in step 399, in global step 181900, learning rate is 0.00015, taks 5.7393999099731445 seconds
2020-03-23 17:18:10,625 - RBF - INFO - train epoch 364 of total 5000 epoches
2020-03-23 17:18:16,325 - RBF - ERROR - loss 1.2933076900553484, in epoch 364, in step 199, in global step 182200, learning rate is 0.00015, taks 8.537400007247925 seconds
2020-03-23 17:18:22,042 - RBF - ERROR - loss 1.2933678046931292, in epoch 364, in step 399, in global step 182400, learning rate is 0.00015, taks 5.716799974441528 seconds
2020-03-23 17:18:24,895 - RBF - INFO - train epoch 365 of total 5000 epoches
2020-03-23 17:18:30,625 - RBF - ERROR - loss 1.293564360890056, in epoch 365, in step 199, in global step 182700, learning rate is 0.00015, taks 8.582000017166138 seconds
2020-03-23 17:18:36,326 - RBF - ERROR - loss 1.293304333986446, in epoch 365, in step 399, in global step 182900, learning rate is 0.00015, taks 5.700800180435181 seconds
2020-03-23 17:18:39,196 - RBF - INFO - train epoch 366 of total 5000 epoches
2020-03-23 17:18:44,895 - RBF - ERROR - loss 1.2933815007144822, in epoch 366, in step 199, in global step 183200, learning rate is 0.00015, taks 8.568399906158447 seconds
2020-03-23 17:18:50,674 - RBF - ERROR - loss 1.2933506449574548, in epoch 366, in step 399, in global step 183400, learning rate is 0.00015, taks 5.778600215911865 seconds
2020-03-23 17:18:53,519 - RBF - INFO - train epoch 367 of total 5000 epoches
2020-03-23 17:18:59,214 - RBF - ERROR - loss 1.2932969815340791, in epoch 367, in step 199, in global step 183700, learning rate is 0.00015, taks 8.54039978981018 seconds
2020-03-23 17:19:04,959 - RBF - ERROR - loss 1.2932943639941938, in epoch 367, in step 399, in global step 183900, learning rate is 0.00015, taks 5.7444000244140625 seconds
2020-03-23 17:19:07,843 - RBF - INFO - train epoch 368 of total 5000 epoches
2020-03-23 17:19:13,569 - RBF - ERROR - loss 1.2936456250944708, in epoch 368, in step 199, in global step 184200, learning rate is 0.00015, taks 8.610599994659424 seconds
2020-03-23 17:19:19,019 - RBF - ERROR - loss 1.293315043557451, in epoch 368, in step 399, in global step 184400, learning rate is 0.00015, taks 5.448199987411499 seconds
2020-03-23 17:19:21,487 - RBF - INFO - train epoch 369 of total 5000 epoches
2020-03-23 17:19:26,397 - RBF - ERROR - loss 1.2932574081345463, in epoch 369, in step 199, in global step 184700, learning rate is 0.00015, taks 7.378000020980835 seconds
2020-03-23 17:19:31,324 - RBF - ERROR - loss 1.2934478689987514, in epoch 369, in step 399, in global step 184900, learning rate is 0.00015, taks 4.927000045776367 seconds
2020-03-23 17:19:33,777 - RBF - INFO - train epoch 370 of total 5000 epoches
2020-03-23 17:19:38,680 - RBF - ERROR - loss 1.2933151706043986, in epoch 370, in step 199, in global step 185200, learning rate is 0.00015, taks 7.356599807739258 seconds
2020-03-23 17:19:43,579 - RBF - ERROR - loss 1.2933200068310113, in epoch 370, in step 399, in global step 185400, learning rate is 0.00015, taks 4.899200201034546 seconds
2020-03-23 17:19:46,037 - RBF - INFO - train epoch 371 of total 5000 epoches
2020-03-23 17:19:50,998 - RBF - ERROR - loss 1.2932855041016302, in epoch 371, in step 199, in global step 185700, learning rate is 0.00015, taks 7.41759991645813 seconds
2020-03-23 17:19:55,897 - RBF - ERROR - loss 1.2932604868835866, in epoch 371, in step 399, in global step 185900, learning rate is 0.00015, taks 4.899399995803833 seconds
2020-03-23 17:19:58,343 - RBF - INFO - train epoch 372 of total 5000 epoches
2020-03-23 17:20:03,281 - RBF - ERROR - loss 1.2932530686999852, in epoch 372, in step 199, in global step 186200, learning rate is 0.00015, taks 7.383599758148193 seconds
2020-03-23 17:20:08,184 - RBF - ERROR - loss 1.2933503955537575, in epoch 372, in step 399, in global step 186400, learning rate is 0.00015, taks 4.903000116348267 seconds
2020-03-23 17:20:10,636 - RBF - INFO - train epoch 373 of total 5000 epoches
2020-03-23 17:20:15,593 - RBF - ERROR - loss 1.2932428816740478, in epoch 373, in step 199, in global step 186700, learning rate is 0.00015, taks 7.4066002368927 seconds
2020-03-23 17:20:20,475 - RBF - ERROR - loss 1.2932524634449227, in epoch 373, in step 399, in global step 186900, learning rate is 0.00015, taks 4.881999969482422 seconds
2020-03-23 17:20:22,934 - RBF - INFO - train epoch 374 of total 5000 epoches
2020-03-23 17:20:27,836 - RBF - ERROR - loss 1.29327497224582, in epoch 374, in step 199, in global step 187200, learning rate is 0.00015, taks 7.359999895095825 seconds
2020-03-23 17:20:32,745 - RBF - ERROR - loss 1.2933341063776145, in epoch 374, in step 399, in global step 187400, learning rate is 0.00015, taks 4.909800052642822 seconds
2020-03-23 17:20:35,198 - RBF - INFO - train epoch 375 of total 5000 epoches
2020-03-23 17:20:40,082 - RBF - ERROR - loss 1.2932848538224189, in epoch 375, in step 199, in global step 187700, learning rate is 0.00015, taks 7.336600065231323 seconds
2020-03-23 17:20:44,981 - RBF - ERROR - loss 1.2933105330453754, in epoch 375, in step 399, in global step 187900, learning rate is 0.00015, taks 4.8979997634887695 seconds
2020-03-23 17:20:47,431 - RBF - INFO - train epoch 376 of total 5000 epoches
2020-03-23 17:20:52,354 - RBF - ERROR - loss 1.2932241934239173, in epoch 376, in step 199, in global step 188200, learning rate is 0.00015, taks 7.372600078582764 seconds
2020-03-23 17:20:57,266 - RBF - ERROR - loss 1.293357533685635, in epoch 376, in step 399, in global step 188400, learning rate is 0.00015, taks 4.911999940872192 seconds
2020-03-23 17:20:59,723 - RBF - INFO - train epoch 377 of total 5000 epoches
2020-03-23 17:21:04,619 - RBF - ERROR - loss 1.2932614426035636, in epoch 377, in step 199, in global step 188700, learning rate is 0.00015, taks 7.353400230407715 seconds
2020-03-23 17:21:09,545 - RBF - ERROR - loss 1.2932211238897242, in epoch 377, in step 399, in global step 188900, learning rate is 0.00015, taks 4.925999879837036 seconds
2020-03-23 17:21:11,993 - RBF - INFO - train epoch 378 of total 5000 epoches
2020-03-23 17:21:16,894 - RBF - ERROR - loss 1.2932817581875402, in epoch 378, in step 199, in global step 189200, learning rate is 0.00015, taks 7.347999811172485 seconds
2020-03-23 17:21:21,854 - RBF - ERROR - loss 1.293239859923538, in epoch 378, in step 399, in global step 189400, learning rate is 0.00015, taks 4.960000038146973 seconds
2020-03-23 17:21:24,293 - RBF - INFO - train epoch 379 of total 5000 epoches
2020-03-23 17:21:29,231 - RBF - ERROR - loss 1.2932347603459504, in epoch 379, in step 199, in global step 189700, learning rate is 0.00015, taks 7.3764002323150635 seconds
2020-03-23 17:21:34,122 - RBF - ERROR - loss 1.2932290401782325, in epoch 379, in step 399, in global step 189900, learning rate is 0.00015, taks 4.891000032424927 seconds
2020-03-23 17:21:38,994 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 379. learning_rate is 0.00015, loss is 1.2933029547900265
2020-03-23 17:21:38,995 - RBF - INFO - train epoch 380 of total 5000 epoches
2020-03-23 17:21:46,254 - RBF - ERROR - loss 1.293358298675961, in epoch 380, in step 199, in global step 190200, learning rate is 0.00015, taks 12.131200075149536 seconds
2020-03-23 17:21:52,555 - RBF - ERROR - loss 1.2933164067767897, in epoch 380, in step 399, in global step 190400, learning rate is 0.00015, taks 6.30079984664917 seconds
2020-03-23 17:21:55,709 - RBF - INFO - train epoch 381 of total 5000 epoches
2020-03-23 17:22:02,012 - RBF - ERROR - loss 1.2932946236368301, in epoch 381, in step 199, in global step 190700, learning rate is 0.00015, taks 9.456200122833252 seconds
2020-03-23 17:22:08,254 - RBF - ERROR - loss 1.2931917600769753, in epoch 381, in step 399, in global step 190900, learning rate is 0.00015, taks 6.2414000034332275 seconds
2020-03-23 17:22:11,405 - RBF - INFO - train epoch 382 of total 5000 epoches
2020-03-23 17:22:17,680 - RBF - ERROR - loss 1.2935084275678834, in epoch 382, in step 199, in global step 191200, learning rate is 0.00015, taks 9.426000118255615 seconds
2020-03-23 17:22:23,965 - RBF - ERROR - loss 1.2931861036761276, in epoch 382, in step 399, in global step 191400, learning rate is 0.00015, taks 6.284999847412109 seconds
2020-03-23 17:22:27,107 - RBF - INFO - train epoch 383 of total 5000 epoches
2020-03-23 17:22:33,370 - RBF - ERROR - loss 1.2932683482484408, in epoch 383, in step 199, in global step 191700, learning rate is 0.00015, taks 9.404000043869019 seconds
2020-03-23 17:22:39,621 - RBF - ERROR - loss 1.2932450006415226, in epoch 383, in step 399, in global step 191900, learning rate is 0.00015, taks 6.250800132751465 seconds
2020-03-23 17:22:42,775 - RBF - INFO - train epoch 384 of total 5000 epoches
2020-03-23 17:22:49,018 - RBF - ERROR - loss 1.2932078078732197, in epoch 384, in step 199, in global step 192200, learning rate is 0.00015, taks 9.395800113677979 seconds
2020-03-23 17:22:54,825 - RBF - ERROR - loss 1.2932310111555638, in epoch 384, in step 399, in global step 192400, learning rate is 0.00015, taks 5.807799816131592 seconds
2020-03-23 17:22:57,684 - RBF - INFO - train epoch 385 of total 5000 epoches
2020-03-23 17:23:03,385 - RBF - ERROR - loss 1.2931974217408815, in epoch 385, in step 199, in global step 192700, learning rate is 0.00015, taks 8.559800148010254 seconds
2020-03-23 17:23:09,113 - RBF - ERROR - loss 1.2935430009869422, in epoch 385, in step 399, in global step 192900, learning rate is 0.00015, taks 5.72819972038269 seconds
2020-03-23 17:23:11,959 - RBF - INFO - train epoch 386 of total 5000 epoches
2020-03-23 17:23:17,705 - RBF - ERROR - loss 1.2931648738039911, in epoch 386, in step 199, in global step 193200, learning rate is 0.00015, taks 8.591400384902954 seconds
2020-03-23 17:23:23,393 - RBF - ERROR - loss 1.2932023007080362, in epoch 386, in step 399, in global step 193400, learning rate is 0.00015, taks 5.688199758529663 seconds
2020-03-23 17:23:26,230 - RBF - INFO - train epoch 387 of total 5000 epoches
2020-03-23 17:23:31,951 - RBF - ERROR - loss 1.29321347295725, in epoch 387, in step 199, in global step 193700, learning rate is 0.00015, taks 8.55840015411377 seconds
2020-03-23 17:23:36,868 - RBF - ERROR - loss 1.2931898996169913, in epoch 387, in step 399, in global step 193900, learning rate is 0.00015, taks 4.915999889373779 seconds
2020-03-23 17:23:39,332 - RBF - INFO - train epoch 388 of total 5000 epoches
2020-03-23 17:23:44,219 - RBF - ERROR - loss 1.2931594702812852, in epoch 388, in step 199, in global step 194200, learning rate is 0.00015, taks 7.350600004196167 seconds
2020-03-23 17:23:49,119 - RBF - ERROR - loss 1.2934070461431781, in epoch 388, in step 399, in global step 194400, learning rate is 0.00015, taks 4.900400161743164 seconds
2020-03-23 17:23:51,592 - RBF - INFO - train epoch 389 of total 5000 epoches
2020-03-23 17:23:56,494 - RBF - ERROR - loss 1.2933161237397675, in epoch 389, in step 199, in global step 194700, learning rate is 0.00015, taks 7.374599933624268 seconds
2020-03-23 17:24:01,402 - RBF - ERROR - loss 1.2931773151894426, in epoch 389, in step 399, in global step 194900, learning rate is 0.00015, taks 4.9079999923706055 seconds
2020-03-23 17:24:03,855 - RBF - INFO - train epoch 390 of total 5000 epoches
2020-03-23 17:24:08,757 - RBF - ERROR - loss 1.293162055429151, in epoch 390, in step 199, in global step 195200, learning rate is 0.00015, taks 7.35539984703064 seconds
2020-03-23 17:24:13,661 - RBF - ERROR - loss 1.2931745021557777, in epoch 390, in step 399, in global step 195400, learning rate is 0.00015, taks 4.903400182723999 seconds
2020-03-23 17:24:16,110 - RBF - INFO - train epoch 391 of total 5000 epoches
2020-03-23 17:24:21,021 - RBF - ERROR - loss 1.293159042927448, in epoch 391, in step 199, in global step 195700, learning rate is 0.00015, taks 7.359799861907959 seconds
2020-03-23 17:24:25,909 - RBF - ERROR - loss 1.2931937702494576, in epoch 391, in step 399, in global step 195900, learning rate is 0.00015, taks 4.88860011100769 seconds
2020-03-23 17:24:28,359 - RBF - INFO - train epoch 392 of total 5000 epoches
2020-03-23 17:24:33,303 - RBF - ERROR - loss 1.2931516547640867, in epoch 392, in step 199, in global step 196200, learning rate is 0.00015, taks 7.392400026321411 seconds
2020-03-23 17:24:38,239 - RBF - ERROR - loss 1.293147724661472, in epoch 392, in step 399, in global step 196400, learning rate is 0.00015, taks 4.936000108718872 seconds
2020-03-23 17:24:40,686 - RBF - INFO - train epoch 393 of total 5000 epoches
2020-03-23 17:24:45,605 - RBF - ERROR - loss 1.2932882857267234, in epoch 393, in step 199, in global step 196700, learning rate is 0.00015, taks 7.366599798202515 seconds
2020-03-23 17:24:50,544 - RBF - ERROR - loss 1.2932041957337723, in epoch 393, in step 399, in global step 196900, learning rate is 0.00015, taks 4.9374001026153564 seconds
2020-03-23 17:24:53,000 - RBF - INFO - train epoch 394 of total 5000 epoches
2020-03-23 17:24:57,896 - RBF - ERROR - loss 1.2932147407680148, in epoch 394, in step 199, in global step 197200, learning rate is 0.00015, taks 7.352400302886963 seconds
2020-03-23 17:25:02,864 - RBF - ERROR - loss 1.293127866406325, in epoch 394, in step 399, in global step 197400, learning rate is 0.00015, taks 4.967399835586548 seconds
2020-03-23 17:25:05,323 - RBF - INFO - train epoch 395 of total 5000 epoches
2020-03-23 17:25:10,259 - RBF - ERROR - loss 1.29313518720331, in epoch 395, in step 199, in global step 197700, learning rate is 0.00015, taks 7.39460015296936 seconds
2020-03-23 17:25:15,173 - RBF - ERROR - loss 1.29313491221344, in epoch 395, in step 399, in global step 197900, learning rate is 0.00015, taks 4.9141998291015625 seconds
2020-03-23 17:25:17,633 - RBF - INFO - train epoch 396 of total 5000 epoches
2020-03-23 17:25:22,558 - RBF - ERROR - loss 1.2933490734511714, in epoch 396, in step 199, in global step 198200, learning rate is 0.00015, taks 7.382999897003174 seconds
2020-03-23 17:25:27,461 - RBF - ERROR - loss 1.2931067937507208, in epoch 396, in step 399, in global step 198400, learning rate is 0.00015, taks 4.9029998779296875 seconds
2020-03-23 17:25:29,907 - RBF - INFO - train epoch 397 of total 5000 epoches
2020-03-23 17:25:34,808 - RBF - ERROR - loss 1.2932581361003954, in epoch 397, in step 199, in global step 198700, learning rate is 0.00015, taks 7.346800088882446 seconds
2020-03-23 17:25:39,703 - RBF - ERROR - loss 1.2931154512811407, in epoch 397, in step 399, in global step 198900, learning rate is 0.00015, taks 4.894399881362915 seconds
2020-03-23 17:25:42,184 - RBF - INFO - train epoch 398 of total 5000 epoches
2020-03-23 17:25:47,078 - RBF - ERROR - loss 1.2931157123450248, in epoch 398, in step 199, in global step 199200, learning rate is 0.00015, taks 7.374800205230713 seconds
2020-03-23 17:25:52,044 - RBF - ERROR - loss 1.2930956545943344, in epoch 398, in step 399, in global step 199400, learning rate is 0.00015, taks 4.964399814605713 seconds
2020-03-23 17:25:54,524 - RBF - INFO - train epoch 399 of total 5000 epoches
2020-03-23 17:25:59,424 - RBF - ERROR - loss 1.2932912464157091, in epoch 399, in step 199, in global step 199700, learning rate is 0.00015, taks 7.379199981689453 seconds
2020-03-23 17:26:04,323 - RBF - ERROR - loss 1.2930865118890342, in epoch 399, in step 399, in global step 199900, learning rate is 0.00015, taks 4.899399995803833 seconds
2020-03-23 17:26:08,908 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 399. learning_rate is 0.00015, loss is 1.2931082573452224
2020-03-23 17:26:08,908 - RBF - INFO - train epoch 400 of total 5000 epoches
2020-03-23 17:26:13,631 - RBF - ERROR - loss 1.293107389739086, in epoch 400, in step 199, in global step 200200, learning rate is 0.00015, taks 9.306600093841553 seconds
2020-03-23 17:26:18,211 - RBF - ERROR - loss 1.293077550957667, in epoch 400, in step 399, in global step 200400, learning rate is 0.00015, taks 4.580399990081787 seconds
2020-03-23 17:26:20,515 - RBF - INFO - train epoch 401 of total 5000 epoches
2020-03-23 17:26:25,088 - RBF - ERROR - loss 1.2930841189774311, in epoch 401, in step 199, in global step 200700, learning rate is 0.00015, taks 6.876600027084351 seconds
2020-03-23 17:26:29,684 - RBF - ERROR - loss 1.2931127392924382, in epoch 401, in step 399, in global step 200900, learning rate is 0.00015, taks 4.595400094985962 seconds
2020-03-23 17:26:31,972 - RBF - INFO - train epoch 402 of total 5000 epoches
2020-03-23 17:26:36,552 - RBF - ERROR - loss 1.2930932252703615, in epoch 402, in step 199, in global step 201200, learning rate is 0.00015, taks 6.8673999309539795 seconds
2020-03-23 17:26:41,169 - RBF - ERROR - loss 1.2930809101523606, in epoch 402, in step 399, in global step 201400, learning rate is 0.00015, taks 4.617000102996826 seconds
2020-03-23 17:26:43,473 - RBF - INFO - train epoch 403 of total 5000 epoches
2020-03-23 17:26:48,111 - RBF - ERROR - loss 1.2930976747159537, in epoch 403, in step 199, in global step 201700, learning rate is 0.00015, taks 6.941799879074097 seconds
2020-03-23 17:26:52,724 - RBF - ERROR - loss 1.2931047009277015, in epoch 403, in step 399, in global step 201900, learning rate is 0.00015, taks 4.611999988555908 seconds
2020-03-23 17:26:55,019 - RBF - INFO - train epoch 404 of total 5000 epoches
2020-03-23 17:26:59,593 - RBF - ERROR - loss 1.293083499257266, in epoch 404, in step 199, in global step 202200, learning rate is 0.00015, taks 6.867799758911133 seconds
2020-03-23 17:27:04,208 - RBF - ERROR - loss 1.2932329960255475, in epoch 404, in step 399, in global step 202400, learning rate is 0.00015, taks 4.615000009536743 seconds
2020-03-23 17:27:06,501 - RBF - INFO - train epoch 405 of total 5000 epoches
2020-03-23 17:27:11,080 - RBF - ERROR - loss 1.2930871179723968, in epoch 405, in step 199, in global step 202700, learning rate is 0.00015, taks 6.871600151062012 seconds
2020-03-23 17:27:15,719 - RBF - ERROR - loss 1.293165760172841, in epoch 405, in step 399, in global step 202900, learning rate is 0.00015, taks 4.637999773025513 seconds
2020-03-23 17:27:18,014 - RBF - INFO - train epoch 406 of total 5000 epoches
2020-03-23 17:27:22,590 - RBF - ERROR - loss 1.2932310336197, in epoch 406, in step 199, in global step 203200, learning rate is 0.00015, taks 6.871200084686279 seconds
2020-03-23 17:27:27,178 - RBF - ERROR - loss 1.2930467508361296, in epoch 406, in step 399, in global step 203400, learning rate is 0.00015, taks 4.588000059127808 seconds
2020-03-23 17:27:29,510 - RBF - INFO - train epoch 407 of total 5000 epoches
2020-03-23 17:27:34,093 - RBF - ERROR - loss 1.293105251231381, in epoch 407, in step 199, in global step 203700, learning rate is 0.00015, taks 6.914999961853027 seconds
2020-03-23 17:27:38,699 - RBF - ERROR - loss 1.2930375209345717, in epoch 407, in step 399, in global step 203900, learning rate is 0.00015, taks 4.606000185012817 seconds
2020-03-23 17:27:40,970 - RBF - INFO - train epoch 408 of total 5000 epoches
2020-03-23 17:27:45,556 - RBF - ERROR - loss 1.293087882116677, in epoch 408, in step 199, in global step 204200, learning rate is 0.00015, taks 6.856599807739258 seconds
2020-03-23 17:27:50,156 - RBF - ERROR - loss 1.293051766930121, in epoch 408, in step 399, in global step 204400, learning rate is 0.00015, taks 4.600800037384033 seconds
2020-03-23 17:27:52,442 - RBF - INFO - train epoch 409 of total 5000 epoches
2020-03-23 17:27:57,041 - RBF - ERROR - loss 1.293137361738838, in epoch 409, in step 199, in global step 204700, learning rate is 0.00015, taks 6.884200096130371 seconds
2020-03-23 17:28:01,643 - RBF - ERROR - loss 1.2932240020655654, in epoch 409, in step 399, in global step 204900, learning rate is 0.00015, taks 4.6021997928619385 seconds
2020-03-23 17:28:03,928 - RBF - INFO - train epoch 410 of total 5000 epoches
2020-03-23 17:28:08,516 - RBF - ERROR - loss 1.2930490581326548, in epoch 410, in step 199, in global step 205200, learning rate is 0.00015, taks 6.873000144958496 seconds
2020-03-23 17:28:13,101 - RBF - ERROR - loss 1.2934501616931493, in epoch 410, in step 399, in global step 205400, learning rate is 0.00015, taks 4.585000038146973 seconds
2020-03-23 17:28:15,396 - RBF - INFO - train epoch 411 of total 5000 epoches
2020-03-23 17:28:19,976 - RBF - ERROR - loss 1.2931601300199396, in epoch 411, in step 199, in global step 205700, learning rate is 0.00015, taks 6.8755998611450195 seconds
2020-03-23 17:28:24,550 - RBF - ERROR - loss 1.2931558156587426, in epoch 411, in step 399, in global step 205900, learning rate is 0.00015, taks 4.573200225830078 seconds
2020-03-23 17:28:26,859 - RBF - INFO - train epoch 412 of total 5000 epoches
2020-03-23 17:28:31,453 - RBF - ERROR - loss 1.2931100992014268, in epoch 412, in step 199, in global step 206200, learning rate is 0.00015, taks 6.9019997119903564 seconds
2020-03-23 17:28:36,032 - RBF - ERROR - loss 1.293039873190485, in epoch 412, in step 399, in global step 206400, learning rate is 0.00015, taks 4.579599857330322 seconds
2020-03-23 17:28:38,324 - RBF - INFO - train epoch 413 of total 5000 epoches
2020-03-23 17:28:42,922 - RBF - ERROR - loss 1.2930357198481262, in epoch 413, in step 199, in global step 206700, learning rate is 0.00015, taks 6.890000343322754 seconds
2020-03-23 17:28:47,503 - RBF - ERROR - loss 1.293059125080178, in epoch 413, in step 399, in global step 206900, learning rate is 0.00015, taks 4.581199884414673 seconds
2020-03-23 17:28:49,822 - RBF - INFO - train epoch 414 of total 5000 epoches
2020-03-23 17:28:54,418 - RBF - ERROR - loss 1.293215242523164, in epoch 414, in step 199, in global step 207200, learning rate is 0.00015, taks 6.913599967956543 seconds
2020-03-23 17:28:59,017 - RBF - ERROR - loss 1.2930511528666018, in epoch 414, in step 399, in global step 207400, learning rate is 0.00015, taks 4.599400043487549 seconds
2020-03-23 17:29:01,316 - RBF - INFO - train epoch 415 of total 5000 epoches
2020-03-23 17:29:05,913 - RBF - ERROR - loss 1.2930373297770599, in epoch 415, in step 199, in global step 207700, learning rate is 0.00015, taks 6.896000146865845 seconds
2020-03-23 17:29:10,533 - RBF - ERROR - loss 1.2930868925696568, in epoch 415, in step 399, in global step 207900, learning rate is 0.00015, taks 4.618200063705444 seconds
2020-03-23 17:29:12,822 - RBF - INFO - train epoch 416 of total 5000 epoches
2020-03-23 17:29:17,411 - RBF - ERROR - loss 1.2930543801883458, in epoch 416, in step 199, in global step 208200, learning rate is 0.00015, taks 6.8788001537323 seconds
2020-03-23 17:29:21,992 - RBF - ERROR - loss 1.292987744603665, in epoch 416, in step 399, in global step 208400, learning rate is 0.00015, taks 4.579599857330322 seconds
2020-03-23 17:29:24,284 - RBF - INFO - train epoch 417 of total 5000 epoches
2020-03-23 17:29:28,851 - RBF - ERROR - loss 1.2933091419373886, in epoch 417, in step 199, in global step 208700, learning rate is 0.00015, taks 6.85860013961792 seconds
2020-03-23 17:29:33,429 - RBF - ERROR - loss 1.2929999375291892, in epoch 417, in step 399, in global step 208900, learning rate is 0.00015, taks 4.578199863433838 seconds
2020-03-23 17:29:35,730 - RBF - INFO - train epoch 418 of total 5000 epoches
2020-03-23 17:29:40,359 - RBF - ERROR - loss 1.2931638520999102, in epoch 418, in step 199, in global step 209200, learning rate is 0.00015, taks 6.930600166320801 seconds
2020-03-23 17:29:44,973 - RBF - ERROR - loss 1.2929929152054958, in epoch 418, in step 399, in global step 209400, learning rate is 0.00015, taks 4.61299991607666 seconds
2020-03-23 17:29:47,264 - RBF - INFO - train epoch 419 of total 5000 epoches
2020-03-23 17:29:51,898 - RBF - ERROR - loss 1.2930409181885607, in epoch 419, in step 199, in global step 209700, learning rate is 0.00015, taks 6.924799919128418 seconds
2020-03-23 17:29:56,476 - RBF - ERROR - loss 1.2930584138595071, in epoch 419, in step 399, in global step 209900, learning rate is 0.00015, taks 4.578200101852417 seconds
2020-03-23 17:30:01,092 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 419. learning_rate is 0.00015, loss is 1.2930723050426682
2020-03-23 17:30:01,093 - RBF - INFO - train epoch 420 of total 5000 epoches
2020-03-23 17:30:07,561 - RBF - ERROR - loss 1.2934074523306132, in epoch 420, in step 199, in global step 210200, learning rate is 0.00015, taks 11.084800004959106 seconds
2020-03-23 17:30:13,869 - RBF - ERROR - loss 1.2929882964453174, in epoch 420, in step 399, in global step 210400, learning rate is 0.00015, taks 6.308000087738037 seconds
2020-03-23 17:30:16,983 - RBF - INFO - train epoch 421 of total 5000 epoches
2020-03-23 17:30:23,230 - RBF - ERROR - loss 1.2930230795702033, in epoch 421, in step 199, in global step 210700, learning rate is 0.00015, taks 9.359399795532227 seconds
2020-03-23 17:30:29,466 - RBF - ERROR - loss 1.293005035215092, in epoch 421, in step 399, in global step 210900, learning rate is 0.00015, taks 6.236200332641602 seconds
2020-03-23 17:30:32,594 - RBF - INFO - train epoch 422 of total 5000 epoches
2020-03-23 17:30:38,887 - RBF - ERROR - loss 1.2932142456929225, in epoch 422, in step 199, in global step 211200, learning rate is 0.00015, taks 9.42139983177185 seconds
2020-03-23 17:30:45,158 - RBF - ERROR - loss 1.2932914419893402, in epoch 422, in step 399, in global step 211400, learning rate is 0.00015, taks 6.2697999477386475 seconds
2020-03-23 17:30:48,295 - RBF - INFO - train epoch 423 of total 5000 epoches
2020-03-23 17:30:54,571 - RBF - ERROR - loss 1.2929805228759017, in epoch 423, in step 199, in global step 211700, learning rate is 0.00015, taks 9.41319990158081 seconds
2020-03-23 17:31:00,827 - RBF - ERROR - loss 1.292999910990712, in epoch 423, in step 399, in global step 211900, learning rate is 0.00015, taks 6.255999803543091 seconds
2020-03-23 17:31:03,962 - RBF - INFO - train epoch 424 of total 5000 epoches
2020-03-23 17:31:10,243 - RBF - ERROR - loss 1.292996471089175, in epoch 424, in step 199, in global step 212200, learning rate is 0.00015, taks 9.41379976272583 seconds
2020-03-23 17:31:16,467 - RBF - ERROR - loss 1.29305125472012, in epoch 424, in step 399, in global step 212400, learning rate is 0.00015, taks 6.224200010299683 seconds
2020-03-23 17:31:19,620 - RBF - INFO - train epoch 425 of total 5000 epoches
2020-03-23 17:31:25,912 - RBF - ERROR - loss 1.2930225095524845, in epoch 425, in step 199, in global step 212700, learning rate is 0.00015, taks 9.444400072097778 seconds
2020-03-23 17:31:32,176 - RBF - ERROR - loss 1.2931070394002873, in epoch 425, in step 399, in global step 212900, learning rate is 0.00015, taks 6.26200008392334 seconds
2020-03-23 17:31:35,323 - RBF - INFO - train epoch 426 of total 5000 epoches
2020-03-23 17:31:41,586 - RBF - ERROR - loss 1.293251878157487, in epoch 426, in step 199, in global step 213200, learning rate is 0.00015, taks 9.410599946975708 seconds
2020-03-23 17:31:47,874 - RBF - ERROR - loss 1.2930202651871199, in epoch 426, in step 399, in global step 213400, learning rate is 0.00015, taks 6.287200212478638 seconds
2020-03-23 17:31:51,122 - RBF - INFO - train epoch 427 of total 5000 epoches
2020-03-23 17:31:57,405 - RBF - ERROR - loss 1.2929409599378028, in epoch 427, in step 199, in global step 213700, learning rate is 0.00015, taks 9.530200004577637 seconds
2020-03-23 17:32:03,740 - RBF - ERROR - loss 1.2930524789842115, in epoch 427, in step 399, in global step 213900, learning rate is 0.00015, taks 6.335200071334839 seconds
2020-03-23 17:32:06,878 - RBF - INFO - train epoch 428 of total 5000 epoches
2020-03-23 17:32:13,139 - RBF - ERROR - loss 1.293040390185265, in epoch 428, in step 199, in global step 214200, learning rate is 0.00015, taks 9.3989999294281 seconds
2020-03-23 17:32:19,434 - RBF - ERROR - loss 1.2929595275443133, in epoch 428, in step 399, in global step 214400, learning rate is 0.00015, taks 6.295399904251099 seconds
2020-03-23 17:32:22,567 - RBF - INFO - train epoch 429 of total 5000 epoches
2020-03-23 17:32:28,900 - RBF - ERROR - loss 1.2930749656063072, in epoch 429, in step 199, in global step 214700, learning rate is 0.00015, taks 9.46500015258789 seconds
2020-03-23 17:32:35,206 - RBF - ERROR - loss 1.2929869005670522, in epoch 429, in step 399, in global step 214900, learning rate is 0.00015, taks 6.305000066757202 seconds
2020-03-23 17:32:38,358 - RBF - INFO - train epoch 430 of total 5000 epoches
2020-03-23 17:32:44,597 - RBF - ERROR - loss 1.2929375973655317, in epoch 430, in step 199, in global step 215200, learning rate is 0.00015, taks 9.391200065612793 seconds
2020-03-23 17:32:50,884 - RBF - ERROR - loss 1.292961956654848, in epoch 430, in step 399, in global step 215400, learning rate is 0.00015, taks 6.28659987449646 seconds
2020-03-23 17:32:54,005 - RBF - INFO - train epoch 431 of total 5000 epoches
2020-03-23 17:33:00,278 - RBF - ERROR - loss 1.2931005896253225, in epoch 431, in step 199, in global step 215700, learning rate is 0.00015, taks 9.392800092697144 seconds
2020-03-23 17:33:06,567 - RBF - ERROR - loss 1.292990151171261, in epoch 431, in step 399, in global step 215900, learning rate is 0.00015, taks 6.2881999015808105 seconds
2020-03-23 17:33:09,620 - RBF - INFO - train epoch 432 of total 5000 epoches
2020-03-23 17:33:15,328 - RBF - ERROR - loss 1.2934715337714764, in epoch 432, in step 199, in global step 216200, learning rate is 0.00015, taks 8.760200023651123 seconds
2020-03-23 17:33:21,091 - RBF - ERROR - loss 1.292953713103081, in epoch 432, in step 399, in global step 216400, learning rate is 0.00015, taks 5.7627997398376465 seconds
2020-03-23 17:33:23,957 - RBF - INFO - train epoch 433 of total 5000 epoches
2020-03-23 17:33:29,693 - RBF - ERROR - loss 1.2929247999832845, in epoch 433, in step 199, in global step 216700, learning rate is 0.00015, taks 8.60200023651123 seconds
2020-03-23 17:33:35,427 - RBF - ERROR - loss 1.2929860805696365, in epoch 433, in step 399, in global step 216900, learning rate is 0.00015, taks 5.733599901199341 seconds
2020-03-23 17:33:38,289 - RBF - INFO - train epoch 434 of total 5000 epoches
2020-03-23 17:33:43,990 - RBF - ERROR - loss 1.293253249261013, in epoch 434, in step 199, in global step 217200, learning rate is 0.00015, taks 8.563199996948242 seconds
2020-03-23 17:33:49,694 - RBF - ERROR - loss 1.2929185704804373, in epoch 434, in step 399, in global step 217400, learning rate is 0.00015, taks 5.704200029373169 seconds
2020-03-23 17:33:52,595 - RBF - INFO - train epoch 435 of total 5000 epoches
2020-03-23 17:33:58,317 - RBF - ERROR - loss 1.2929644601686034, in epoch 435, in step 199, in global step 217700, learning rate is 0.00015, taks 8.623199939727783 seconds
2020-03-23 17:34:04,050 - RBF - ERROR - loss 1.2929472064446028, in epoch 435, in step 399, in global step 217900, learning rate is 0.00015, taks 5.7332000732421875 seconds
2020-03-23 17:34:06,807 - RBF - INFO - train epoch 436 of total 5000 epoches
2020-03-23 17:34:11,662 - RBF - ERROR - loss 1.2929306305458816, in epoch 436, in step 199, in global step 218200, learning rate is 0.00015, taks 7.611999988555908 seconds
2020-03-23 17:34:16,300 - RBF - ERROR - loss 1.293053079330187, in epoch 436, in step 399, in global step 218400, learning rate is 0.00015, taks 4.638000011444092 seconds
2020-03-23 17:34:18,592 - RBF - INFO - train epoch 437 of total 5000 epoches
2020-03-23 17:34:23,188 - RBF - ERROR - loss 1.2929654748059634, in epoch 437, in step 199, in global step 218700, learning rate is 0.00015, taks 6.888000011444092 seconds
2020-03-23 17:34:27,771 - RBF - ERROR - loss 1.2929393464960042, in epoch 437, in step 399, in global step 218900, learning rate is 0.00015, taks 4.58299994468689 seconds
2020-03-23 17:34:30,076 - RBF - INFO - train epoch 438 of total 5000 epoches
2020-03-23 17:34:34,663 - RBF - ERROR - loss 1.2929458168999646, in epoch 438, in step 199, in global step 219200, learning rate is 0.00015, taks 6.891599893569946 seconds
2020-03-23 17:34:39,246 - RBF - ERROR - loss 1.2929053786651188, in epoch 438, in step 399, in global step 219400, learning rate is 0.00015, taks 4.58299994468689 seconds
2020-03-23 17:34:41,537 - RBF - INFO - train epoch 439 of total 5000 epoches
2020-03-23 17:34:46,143 - RBF - ERROR - loss 1.2929184624084016, in epoch 439, in step 199, in global step 219700, learning rate is 0.00015, taks 6.897200345993042 seconds
2020-03-23 17:34:50,778 - RBF - ERROR - loss 1.292933313136273, in epoch 439, in step 399, in global step 219900, learning rate is 0.00015, taks 4.634399890899658 seconds
2020-03-23 17:34:55,515 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 439. learning_rate is 0.00015, loss is 1.2930878483754529
2020-03-23 17:34:55,515 - RBF - INFO - train epoch 440 of total 5000 epoches
2020-03-23 17:35:02,077 - RBF - ERROR - loss 1.2929288508250603, in epoch 440, in step 199, in global step 220200, learning rate is 0.00015, taks 11.2985999584198 seconds
2020-03-23 17:35:08,401 - RBF - ERROR - loss 1.293093181082254, in epoch 440, in step 399, in global step 220400, learning rate is 0.00015, taks 6.323800086975098 seconds
2020-03-23 17:35:11,554 - RBF - INFO - train epoch 441 of total 5000 epoches
2020-03-23 17:35:17,822 - RBF - ERROR - loss 1.2929006221872934, in epoch 441, in step 199, in global step 220700, learning rate is 0.00015, taks 9.419600009918213 seconds
2020-03-23 17:35:24,088 - RBF - ERROR - loss 1.2929081199375883, in epoch 441, in step 399, in global step 220900, learning rate is 0.00015, taks 6.266400098800659 seconds
2020-03-23 17:35:27,204 - RBF - INFO - train epoch 442 of total 5000 epoches
2020-03-23 17:35:33,491 - RBF - ERROR - loss 1.2928836565878108, in epoch 442, in step 199, in global step 221200, learning rate is 0.00015, taks 9.402199983596802 seconds
2020-03-23 17:35:39,744 - RBF - ERROR - loss 1.2929568103814242, in epoch 442, in step 399, in global step 221400, learning rate is 0.00015, taks 6.252200126647949 seconds
2020-03-23 17:35:42,878 - RBF - INFO - train epoch 443 of total 5000 epoches
2020-03-23 17:35:49,123 - RBF - ERROR - loss 1.2929124706654076, in epoch 443, in step 199, in global step 221700, learning rate is 0.00015, taks 9.378999948501587 seconds
2020-03-23 17:35:55,423 - RBF - ERROR - loss 1.2930291799095346, in epoch 443, in step 399, in global step 221900, learning rate is 0.00015, taks 6.299200057983398 seconds
2020-03-23 17:35:58,554 - RBF - INFO - train epoch 444 of total 5000 epoches
2020-03-23 17:36:04,821 - RBF - ERROR - loss 1.2928881805098356, in epoch 444, in step 199, in global step 222200, learning rate is 0.00015, taks 9.398200035095215 seconds
2020-03-23 17:36:11,089 - RBF - ERROR - loss 1.2929865692518079, in epoch 444, in step 399, in global step 222400, learning rate is 0.00015, taks 6.267999887466431 seconds
2020-03-23 17:36:14,225 - RBF - INFO - train epoch 445 of total 5000 epoches
2020-03-23 17:36:20,470 - RBF - ERROR - loss 1.2929338540404216, in epoch 445, in step 199, in global step 222700, learning rate is 0.00015, taks 9.381200313568115 seconds
2020-03-23 17:36:26,765 - RBF - ERROR - loss 1.2928987366929174, in epoch 445, in step 399, in global step 222900, learning rate is 0.00015, taks 6.295399904251099 seconds
2020-03-23 17:36:29,892 - RBF - INFO - train epoch 446 of total 5000 epoches
2020-03-23 17:36:36,116 - RBF - ERROR - loss 1.2930542349781196, in epoch 446, in step 199, in global step 223200, learning rate is 0.00015, taks 9.3510000705719 seconds
2020-03-23 17:36:42,405 - RBF - ERROR - loss 1.2929483226108849, in epoch 446, in step 399, in global step 223400, learning rate is 0.00015, taks 6.288599729537964 seconds
2020-03-23 17:36:45,568 - RBF - INFO - train epoch 447 of total 5000 epoches
2020-03-23 17:36:51,922 - RBF - ERROR - loss 1.2928800833540026, in epoch 447, in step 199, in global step 223700, learning rate is 0.00015, taks 9.516000032424927 seconds
2020-03-23 17:36:58,116 - RBF - ERROR - loss 1.2928609965917857, in epoch 447, in step 399, in global step 223900, learning rate is 0.00015, taks 6.19379997253418 seconds
2020-03-23 17:37:00,963 - RBF - INFO - train epoch 448 of total 5000 epoches
2020-03-23 17:37:06,674 - RBF - ERROR - loss 1.2929391317650412, in epoch 448, in step 199, in global step 224200, learning rate is 0.00015, taks 8.55839991569519 seconds
2020-03-23 17:37:12,404 - RBF - ERROR - loss 1.2929264382177854, in epoch 448, in step 399, in global step 224400, learning rate is 0.00015, taks 5.7302000522613525 seconds
2020-03-23 17:37:15,269 - RBF - INFO - train epoch 449 of total 5000 epoches
2020-03-23 17:37:20,976 - RBF - ERROR - loss 1.2930547117661046, in epoch 449, in step 199, in global step 224700, learning rate is 0.00015, taks 8.571599960327148 seconds
2020-03-23 17:37:26,679 - RBF - ERROR - loss 1.2928741532668686, in epoch 449, in step 399, in global step 224900, learning rate is 0.00015, taks 5.702200174331665 seconds
2020-03-23 17:37:29,577 - RBF - INFO - train epoch 450 of total 5000 epoches
2020-03-23 17:37:35,296 - RBF - ERROR - loss 1.2928848870513157, in epoch 450, in step 199, in global step 225200, learning rate is 0.00015, taks 8.616400003433228 seconds
2020-03-23 17:37:41,005 - RBF - ERROR - loss 1.2930648706686598, in epoch 450, in step 399, in global step 225400, learning rate is 0.00015, taks 5.7098000049591064 seconds
2020-03-23 17:37:43,866 - RBF - INFO - train epoch 451 of total 5000 epoches
2020-03-23 17:37:49,598 - RBF - ERROR - loss 1.2928692507364816, in epoch 451, in step 199, in global step 225700, learning rate is 0.00015, taks 8.592600107192993 seconds
2020-03-23 17:37:55,335 - RBF - ERROR - loss 1.2928878034840947, in epoch 451, in step 399, in global step 225900, learning rate is 0.00015, taks 5.736599683761597 seconds
2020-03-23 17:37:58,187 - RBF - INFO - train epoch 452 of total 5000 epoches
2020-03-23 17:38:03,891 - RBF - ERROR - loss 1.2929188832443566, in epoch 452, in step 199, in global step 226200, learning rate is 0.00015, taks 8.556600093841553 seconds
2020-03-23 17:38:09,632 - RBF - ERROR - loss 1.2928761671841844, in epoch 452, in step 399, in global step 226400, learning rate is 0.00015, taks 5.74120020866394 seconds
2020-03-23 17:38:12,469 - RBF - INFO - train epoch 453 of total 5000 epoches
2020-03-23 17:38:18,220 - RBF - ERROR - loss 1.29284099491121, in epoch 453, in step 199, in global step 226700, learning rate is 0.00015, taks 8.587399959564209 seconds
2020-03-23 17:38:23,918 - RBF - ERROR - loss 1.2928889508075532, in epoch 453, in step 399, in global step 226900, learning rate is 0.00015, taks 5.697399854660034 seconds
2020-03-23 17:38:26,774 - RBF - INFO - train epoch 454 of total 5000 epoches
2020-03-23 17:38:32,484 - RBF - ERROR - loss 1.2928246780414885, in epoch 454, in step 199, in global step 227200, learning rate is 0.00015, taks 8.565799951553345 seconds
2020-03-23 17:38:38,209 - RBF - ERROR - loss 1.2928062532839952, in epoch 454, in step 399, in global step 227400, learning rate is 0.00015, taks 5.7240002155303955 seconds
2020-03-23 17:38:41,075 - RBF - INFO - train epoch 455 of total 5000 epoches
2020-03-23 17:38:46,795 - RBF - ERROR - loss 1.2929690282942943, in epoch 455, in step 199, in global step 227700, learning rate is 0.00015, taks 8.58519983291626 seconds
2020-03-23 17:38:52,551 - RBF - ERROR - loss 1.2928892325364816, in epoch 455, in step 399, in global step 227900, learning rate is 0.00015, taks 5.75600004196167 seconds
2020-03-23 17:38:55,418 - RBF - INFO - train epoch 456 of total 5000 epoches
2020-03-23 17:39:01,191 - RBF - ERROR - loss 1.2928328927625188, in epoch 456, in step 199, in global step 228200, learning rate is 0.00015, taks 8.63919997215271 seconds
2020-03-23 17:39:06,927 - RBF - ERROR - loss 1.2928268544731245, in epoch 456, in step 399, in global step 228400, learning rate is 0.00015, taks 5.735400199890137 seconds
2020-03-23 17:39:09,781 - RBF - INFO - train epoch 457 of total 5000 epoches
2020-03-23 17:39:15,065 - RBF - ERROR - loss 1.2928208670995722, in epoch 457, in step 199, in global step 228700, learning rate is 0.00015, taks 8.138399839401245 seconds
2020-03-23 17:39:19,968 - RBF - ERROR - loss 1.2930294177254342, in epoch 457, in step 399, in global step 228900, learning rate is 0.00015, taks 4.9029998779296875 seconds
2020-03-23 17:39:22,432 - RBF - INFO - train epoch 458 of total 5000 epoches
2020-03-23 17:39:27,338 - RBF - ERROR - loss 1.293008700820745, in epoch 458, in step 199, in global step 229200, learning rate is 0.00015, taks 7.369800329208374 seconds
2020-03-23 17:39:32,276 - RBF - ERROR - loss 1.2928212412011892, in epoch 458, in step 399, in global step 229400, learning rate is 0.00015, taks 4.938399791717529 seconds
2020-03-23 17:39:34,761 - RBF - INFO - train epoch 459 of total 5000 epoches
2020-03-23 17:39:39,695 - RBF - ERROR - loss 1.292914411586773, in epoch 459, in step 199, in global step 229700, learning rate is 0.00015, taks 7.417400121688843 seconds
2020-03-23 17:39:44,612 - RBF - ERROR - loss 1.2928188684867166, in epoch 459, in step 399, in global step 229900, learning rate is 0.00015, taks 4.916800022125244 seconds
2020-03-23 17:39:49,483 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 459. learning_rate is 0.00015, loss is 1.292804100542382
2020-03-23 17:39:49,484 - RBF - INFO - train epoch 460 of total 5000 epoches
2020-03-23 17:39:56,218 - RBF - ERROR - loss 1.2928233464249521, in epoch 460, in step 199, in global step 230200, learning rate is 0.00015, taks 11.605999946594238 seconds
2020-03-23 17:40:02,472 - RBF - ERROR - loss 1.2928276684226117, in epoch 460, in step 399, in global step 230400, learning rate is 0.00015, taks 6.254199981689453 seconds
2020-03-23 17:40:05,619 - RBF - INFO - train epoch 461 of total 5000 epoches
2020-03-23 17:40:11,874 - RBF - ERROR - loss 1.2928484196015937, in epoch 461, in step 199, in global step 230700, learning rate is 0.00015, taks 9.401999950408936 seconds
2020-03-23 17:40:17,974 - RBF - ERROR - loss 1.2928002453259753, in epoch 461, in step 399, in global step 230900, learning rate is 0.00015, taks 6.100200176239014 seconds
2020-03-23 17:40:20,812 - RBF - INFO - train epoch 462 of total 5000 epoches
2020-03-23 17:40:26,546 - RBF - ERROR - loss 1.2931377623296063, in epoch 462, in step 199, in global step 231200, learning rate is 0.00015, taks 8.571799755096436 seconds
2020-03-23 17:40:32,260 - RBF - ERROR - loss 1.2927975071641749, in epoch 462, in step 399, in global step 231400, learning rate is 0.00015, taks 5.71340012550354 seconds
2020-03-23 17:40:35,110 - RBF - INFO - train epoch 463 of total 5000 epoches
2020-03-23 17:40:40,027 - RBF - ERROR - loss 1.292796979777164, in epoch 463, in step 199, in global step 231700, learning rate is 0.00015, taks 7.7669997215271 seconds
2020-03-23 17:40:44,938 - RBF - ERROR - loss 1.2931686853550581, in epoch 463, in step 399, in global step 231900, learning rate is 0.00015, taks 4.9100000858306885 seconds
2020-03-23 17:40:47,427 - RBF - INFO - train epoch 464 of total 5000 epoches
2020-03-23 17:40:52,362 - RBF - ERROR - loss 1.2927972395343874, in epoch 464, in step 199, in global step 232200, learning rate is 0.00015, taks 7.4235999584198 seconds
2020-03-23 17:40:57,265 - RBF - ERROR - loss 1.2929687103102818, in epoch 464, in step 399, in global step 232400, learning rate is 0.00015, taks 4.902000188827515 seconds
2020-03-23 17:40:59,737 - RBF - INFO - train epoch 465 of total 5000 epoches
2020-03-23 17:41:04,672 - RBF - ERROR - loss 1.2927859316450327, in epoch 465, in step 199, in global step 232700, learning rate is 0.00015, taks 7.407599925994873 seconds
2020-03-23 17:41:09,583 - RBF - ERROR - loss 1.2927966906617732, in epoch 465, in step 399, in global step 232900, learning rate is 0.00015, taks 4.91100001335144 seconds
2020-03-23 17:41:12,039 - RBF - INFO - train epoch 466 of total 5000 epoches
2020-03-23 17:41:16,943 - RBF - ERROR - loss 1.2928084917637783, in epoch 466, in step 199, in global step 233200, learning rate is 0.00015, taks 7.358599901199341 seconds
2020-03-23 17:41:21,841 - RBF - ERROR - loss 1.292919336847523, in epoch 466, in step 399, in global step 233400, learning rate is 0.00015, taks 4.898000240325928 seconds
2020-03-23 17:41:24,299 - RBF - INFO - train epoch 467 of total 5000 epoches
2020-03-23 17:41:29,196 - RBF - ERROR - loss 1.2927812265705538, in epoch 467, in step 199, in global step 233700, learning rate is 0.00015, taks 7.354799747467041 seconds
2020-03-23 17:41:34,112 - RBF - ERROR - loss 1.2928297437734508, in epoch 467, in step 399, in global step 233900, learning rate is 0.00015, taks 4.916000127792358 seconds
2020-03-23 17:41:36,553 - RBF - INFO - train epoch 468 of total 5000 epoches
2020-03-23 17:41:41,463 - RBF - ERROR - loss 1.2928346891030253, in epoch 468, in step 199, in global step 234200, learning rate is 0.00015, taks 7.350800037384033 seconds
2020-03-23 17:41:46,371 - RBF - ERROR - loss 1.2927761873031285, in epoch 468, in step 399, in global step 234400, learning rate is 0.00015, taks 4.9070000648498535 seconds
2020-03-23 17:41:48,818 - RBF - INFO - train epoch 469 of total 5000 epoches
2020-03-23 17:41:53,763 - RBF - ERROR - loss 1.2927783515326765, in epoch 469, in step 199, in global step 234700, learning rate is 0.00015, taks 7.392399787902832 seconds
2020-03-23 17:41:58,686 - RBF - ERROR - loss 1.2927506776842974, in epoch 469, in step 399, in global step 234900, learning rate is 0.00015, taks 4.922600269317627 seconds
2020-03-23 17:42:01,142 - RBF - INFO - train epoch 470 of total 5000 epoches
2020-03-23 17:42:06,092 - RBF - ERROR - loss 1.29278140637478, in epoch 470, in step 199, in global step 235200, learning rate is 0.00015, taks 7.405799865722656 seconds
2020-03-23 17:42:11,054 - RBF - ERROR - loss 1.2928058106125833, in epoch 470, in step 399, in global step 235400, learning rate is 0.00015, taks 4.961999893188477 seconds
2020-03-23 17:42:13,506 - RBF - INFO - train epoch 471 of total 5000 epoches
2020-03-23 17:42:18,457 - RBF - ERROR - loss 1.292861791215971, in epoch 471, in step 199, in global step 235700, learning rate is 0.00015, taks 7.403000116348267 seconds
2020-03-23 17:42:23,363 - RBF - ERROR - loss 1.2927453720518478, in epoch 471, in step 399, in global step 235900, learning rate is 0.00015, taks 4.906000137329102 seconds
2020-03-23 17:42:25,821 - RBF - INFO - train epoch 472 of total 5000 epoches
2020-03-23 17:42:30,740 - RBF - ERROR - loss 1.292936570984756, in epoch 472, in step 199, in global step 236200, learning rate is 0.00015, taks 7.375600099563599 seconds
2020-03-23 17:42:35,631 - RBF - ERROR - loss 1.2928394936580487, in epoch 472, in step 399, in global step 236400, learning rate is 0.00015, taks 4.890599966049194 seconds
2020-03-23 17:42:38,107 - RBF - INFO - train epoch 473 of total 5000 epoches
2020-03-23 17:42:42,999 - RBF - ERROR - loss 1.2928600980062985, in epoch 473, in step 199, in global step 236700, learning rate is 0.00015, taks 7.368799924850464 seconds
2020-03-23 17:42:47,915 - RBF - ERROR - loss 1.2929034097874759, in epoch 473, in step 399, in global step 236900, learning rate is 0.00015, taks 4.914999961853027 seconds
2020-03-23 17:42:50,382 - RBF - INFO - train epoch 474 of total 5000 epoches
2020-03-23 17:42:55,308 - RBF - ERROR - loss 1.2927768293387576, in epoch 474, in step 199, in global step 237200, learning rate is 0.00015, taks 7.392999887466431 seconds
2020-03-23 17:43:00,233 - RBF - ERROR - loss 1.2932761273728766, in epoch 474, in step 399, in global step 237400, learning rate is 0.00015, taks 4.924200057983398 seconds
2020-03-23 17:43:02,692 - RBF - INFO - train epoch 475 of total 5000 epoches
2020-03-23 17:43:07,621 - RBF - ERROR - loss 1.2927943215725763, in epoch 475, in step 199, in global step 237700, learning rate is 0.00015, taks 7.388400077819824 seconds
2020-03-23 17:43:12,542 - RBF - ERROR - loss 1.2928249026124141, in epoch 475, in step 399, in global step 237900, learning rate is 0.00015, taks 4.9197998046875 seconds
2020-03-23 17:43:14,995 - RBF - INFO - train epoch 476 of total 5000 epoches
2020-03-23 17:43:19,899 - RBF - ERROR - loss 1.2927435935994396, in epoch 476, in step 199, in global step 238200, learning rate is 0.00015, taks 7.3561999797821045 seconds
2020-03-23 17:43:24,809 - RBF - ERROR - loss 1.292811002877173, in epoch 476, in step 399, in global step 238400, learning rate is 0.00015, taks 4.908999919891357 seconds
2020-03-23 17:43:27,264 - RBF - INFO - train epoch 477 of total 5000 epoches
2020-03-23 17:43:32,156 - RBF - ERROR - loss 1.293251770851655, in epoch 477, in step 199, in global step 238700, learning rate is 0.00015, taks 7.346599817276001 seconds
2020-03-23 17:43:37,059 - RBF - ERROR - loss 1.2928785863918837, in epoch 477, in step 399, in global step 238900, learning rate is 0.00015, taks 4.903000116348267 seconds
2020-03-23 17:43:39,521 - RBF - INFO - train epoch 478 of total 5000 epoches
2020-03-23 17:43:44,429 - RBF - ERROR - loss 1.2929042448131043, in epoch 478, in step 199, in global step 239200, learning rate is 0.00015, taks 7.370199918746948 seconds
2020-03-23 17:43:49,329 - RBF - ERROR - loss 1.2929309729740657, in epoch 478, in step 399, in global step 239400, learning rate is 0.00015, taks 4.900200128555298 seconds
2020-03-23 17:43:51,820 - RBF - INFO - train epoch 479 of total 5000 epoches
2020-03-23 17:43:56,710 - RBF - ERROR - loss 1.2928835596626131, in epoch 479, in step 199, in global step 239700, learning rate is 0.00015, taks 7.380800008773804 seconds
2020-03-23 17:44:01,646 - RBF - ERROR - loss 1.2928766265987621, in epoch 479, in step 399, in global step 239900, learning rate is 0.00015, taks 4.936399936676025 seconds
2020-03-23 17:44:06,141 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 479. learning_rate is 0.00015, loss is 1.2928758792989885
2020-03-23 17:44:06,141 - RBF - INFO - train epoch 480 of total 5000 epoches
2020-03-23 17:44:12,642 - RBF - ERROR - loss 1.2928150582775255, in epoch 480, in step 199, in global step 240200, learning rate is 0.00015, taks 10.99559998512268 seconds
2020-03-23 17:44:18,914 - RBF - ERROR - loss 1.2929531775626109, in epoch 480, in step 399, in global step 240400, learning rate is 0.00015, taks 6.271200180053711 seconds
2020-03-23 17:44:22,142 - RBF - INFO - train epoch 481 of total 5000 epoches
2020-03-23 17:44:28,404 - RBF - ERROR - loss 1.2928090097404896, in epoch 481, in step 199, in global step 240700, learning rate is 0.00015, taks 9.490399837493896 seconds
2020-03-23 17:44:34,702 - RBF - ERROR - loss 1.293095438293095, in epoch 481, in step 399, in global step 240900, learning rate is 0.00015, taks 6.297400236129761 seconds
2020-03-23 17:44:37,822 - RBF - INFO - train epoch 482 of total 5000 epoches
2020-03-23 17:44:44,061 - RBF - ERROR - loss 1.2930461973529723, in epoch 482, in step 199, in global step 241200, learning rate is 0.00015, taks 9.359399795532227 seconds
2020-03-23 17:44:50,342 - RBF - ERROR - loss 1.2929449143556329, in epoch 482, in step 399, in global step 241400, learning rate is 0.00015, taks 6.281000137329102 seconds
2020-03-23 17:44:53,525 - RBF - INFO - train epoch 483 of total 5000 epoches
2020-03-23 17:44:59,795 - RBF - ERROR - loss 1.2929968153043534, in epoch 483, in step 199, in global step 241700, learning rate is 0.00015, taks 9.452199935913086 seconds
2020-03-23 17:45:06,061 - RBF - ERROR - loss 1.2932415214449546, in epoch 483, in step 399, in global step 241900, learning rate is 0.00015, taks 6.264200210571289 seconds
2020-03-23 17:45:09,167 - RBF - INFO - train epoch 484 of total 5000 epoches
2020-03-23 17:45:15,428 - RBF - ERROR - loss 1.2928245787055677, in epoch 484, in step 199, in global step 242200, learning rate is 0.00015, taks 9.367599964141846 seconds
2020-03-23 17:45:21,699 - RBF - ERROR - loss 1.2928673197353675, in epoch 484, in step 399, in global step 242400, learning rate is 0.00015, taks 6.2708001136779785 seconds
2020-03-23 17:45:24,841 - RBF - INFO - train epoch 485 of total 5000 epoches
2020-03-23 17:45:31,121 - RBF - ERROR - loss 1.2928446636593223, in epoch 485, in step 199, in global step 242700, learning rate is 0.00015, taks 9.421799898147583 seconds
2020-03-23 17:45:37,370 - RBF - ERROR - loss 1.2929991885820393, in epoch 485, in step 399, in global step 242900, learning rate is 0.00015, taks 6.248800039291382 seconds
2020-03-23 17:45:40,487 - RBF - INFO - train epoch 486 of total 5000 epoches
2020-03-23 17:45:46,782 - RBF - ERROR - loss 1.2928695282984815, in epoch 486, in step 199, in global step 243200, learning rate is 0.00015, taks 9.411600112915039 seconds
2020-03-23 17:45:53,057 - RBF - ERROR - loss 1.2927971121756876, in epoch 486, in step 399, in global step 243400, learning rate is 0.00015, taks 6.274799823760986 seconds
2020-03-23 17:45:56,199 - RBF - INFO - train epoch 487 of total 5000 epoches
2020-03-23 17:46:02,470 - RBF - ERROR - loss 1.2931981984926408, in epoch 487, in step 199, in global step 243700, learning rate is 0.00015, taks 9.413400173187256 seconds
2020-03-23 17:46:08,706 - RBF - ERROR - loss 1.2928671245110521, in epoch 487, in step 399, in global step 243900, learning rate is 0.00015, taks 6.2342000007629395 seconds
2020-03-23 17:46:11,842 - RBF - INFO - train epoch 488 of total 5000 epoches
2020-03-23 17:46:18,104 - RBF - ERROR - loss 1.292771523829855, in epoch 488, in step 199, in global step 244200, learning rate is 0.00015, taks 9.398400068283081 seconds
2020-03-23 17:46:24,373 - RBF - ERROR - loss 1.2928584048328033, in epoch 488, in step 399, in global step 244400, learning rate is 0.00015, taks 6.269400119781494 seconds
2020-03-23 17:46:27,502 - RBF - INFO - train epoch 489 of total 5000 epoches
2020-03-23 17:46:33,750 - RBF - ERROR - loss 1.2928053123284131, in epoch 489, in step 199, in global step 244700, learning rate is 0.00015, taks 9.376399755477905 seconds
2020-03-23 17:46:40,017 - RBF - ERROR - loss 1.2928006308741133, in epoch 489, in step 399, in global step 244900, learning rate is 0.00015, taks 6.266800165176392 seconds
2020-03-23 17:46:43,149 - RBF - INFO - train epoch 490 of total 5000 epoches
2020-03-23 17:46:49,463 - RBF - ERROR - loss 1.2927889732145508, in epoch 490, in step 199, in global step 245200, learning rate is 0.00015, taks 9.445199966430664 seconds
2020-03-23 17:46:54,694 - RBF - ERROR - loss 1.2927555218183284, in epoch 490, in step 399, in global step 245400, learning rate is 0.00015, taks 5.231600046157837 seconds
2020-03-23 17:46:56,851 - RBF - INFO - train epoch 491 of total 5000 epoches
2020-03-23 17:47:00,969 - RBF - ERROR - loss 1.2928891043051371, in epoch 491, in step 199, in global step 245700, learning rate is 0.00015, taks 6.274199962615967 seconds
2020-03-23 17:47:05,033 - RBF - ERROR - loss 1.2927389444546333, in epoch 491, in step 399, in global step 245900, learning rate is 0.00015, taks 4.064199924468994 seconds
2020-03-23 17:47:07,092 - RBF - INFO - train epoch 492 of total 5000 epoches
2020-03-23 17:47:11,170 - RBF - ERROR - loss 1.2928054828063473, in epoch 492, in step 199, in global step 246200, learning rate is 0.00015, taks 6.136800050735474 seconds
2020-03-23 17:47:15,257 - RBF - ERROR - loss 1.2927325336368722, in epoch 492, in step 399, in global step 246400, learning rate is 0.00015, taks 4.087599992752075 seconds
2020-03-23 17:47:17,286 - RBF - INFO - train epoch 493 of total 5000 epoches
2020-03-23 17:47:21,369 - RBF - ERROR - loss 1.292789441672704, in epoch 493, in step 199, in global step 246700, learning rate is 0.00015, taks 6.110799789428711 seconds
2020-03-23 17:47:25,467 - RBF - ERROR - loss 1.2928448200535536, in epoch 493, in step 399, in global step 246900, learning rate is 0.00015, taks 4.098200082778931 seconds
2020-03-23 17:47:27,513 - RBF - INFO - train epoch 494 of total 5000 epoches
2020-03-23 17:47:31,600 - RBF - ERROR - loss 1.2927845568435279, in epoch 494, in step 199, in global step 247200, learning rate is 0.00015, taks 6.132800102233887 seconds
2020-03-23 17:47:35,668 - RBF - ERROR - loss 1.292807051601955, in epoch 494, in step 399, in global step 247400, learning rate is 0.00015, taks 4.067199945449829 seconds
2020-03-23 17:47:37,709 - RBF - INFO - train epoch 495 of total 5000 epoches
2020-03-23 17:47:41,813 - RBF - ERROR - loss 1.292805694155296, in epoch 495, in step 199, in global step 247700, learning rate is 0.00015, taks 6.14460015296936 seconds
2020-03-23 17:47:45,900 - RBF - ERROR - loss 1.2927686240532714, in epoch 495, in step 399, in global step 247900, learning rate is 0.00015, taks 4.086199998855591 seconds
2020-03-23 17:47:47,940 - RBF - INFO - train epoch 496 of total 5000 epoches
2020-03-23 17:47:52,073 - RBF - ERROR - loss 1.292891926995893, in epoch 496, in step 199, in global step 248200, learning rate is 0.00015, taks 6.172800064086914 seconds
2020-03-23 17:47:56,155 - RBF - ERROR - loss 1.2927382294114205, in epoch 496, in step 399, in global step 248400, learning rate is 0.00015, taks 4.081999778747559 seconds
2020-03-23 17:47:58,200 - RBF - INFO - train epoch 497 of total 5000 epoches
2020-03-23 17:48:02,297 - RBF - ERROR - loss 1.2927784857631757, in epoch 497, in step 199, in global step 248700, learning rate is 0.00015, taks 6.141800165176392 seconds
2020-03-23 17:48:06,365 - RBF - ERROR - loss 1.2930883067128829, in epoch 497, in step 399, in global step 248900, learning rate is 0.00015, taks 4.067199945449829 seconds
2020-03-23 17:48:08,405 - RBF - INFO - train epoch 498 of total 5000 epoches
2020-03-23 17:48:12,506 - RBF - ERROR - loss 1.292743737965724, in epoch 498, in step 199, in global step 249200, learning rate is 0.00015, taks 6.139800071716309 seconds
2020-03-23 17:48:16,577 - RBF - ERROR - loss 1.2927138188558647, in epoch 498, in step 399, in global step 249400, learning rate is 0.00015, taks 4.070200204849243 seconds
2020-03-23 17:48:18,621 - RBF - INFO - train epoch 499 of total 5000 epoches
2020-03-23 17:48:22,708 - RBF - ERROR - loss 1.2927258478499235, in epoch 499, in step 199, in global step 249700, learning rate is 0.00015, taks 6.130799770355225 seconds
2020-03-23 17:48:26,786 - RBF - ERROR - loss 1.2927831158516485, in epoch 499, in step 399, in global step 249900, learning rate is 0.00015, taks 4.07800030708313 seconds
2020-03-23 17:48:31,109 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 499. learning_rate is 0.00015, loss is 1.2928527767699722
2020-03-23 17:48:31,110 - RBF - INFO - train epoch 500 of total 5000 epoches
2020-03-23 17:48:37,622 - RBF - ERROR - loss 1.2927119446982405, in epoch 500, in step 199, in global step 250200, learning rate is 0.00015, taks 10.836399793624878 seconds
2020-03-23 17:48:43,870 - RBF - ERROR - loss 1.2927204141625954, in epoch 500, in step 399, in global step 250400, learning rate is 0.00015, taks 6.246799945831299 seconds
2020-03-23 17:48:46,989 - RBF - INFO - train epoch 501 of total 5000 epoches
2020-03-23 17:48:53,229 - RBF - ERROR - loss 1.2927623954512517, in epoch 501, in step 199, in global step 250700, learning rate is 0.00015, taks 9.35920000076294 seconds
2020-03-23 17:48:59,509 - RBF - ERROR - loss 1.292888817005774, in epoch 501, in step 399, in global step 250900, learning rate is 0.00015, taks 6.278600215911865 seconds
2020-03-23 17:49:02,640 - RBF - INFO - train epoch 502 of total 5000 epoches
2020-03-23 17:49:08,888 - RBF - ERROR - loss 1.2927229648456366, in epoch 502, in step 199, in global step 251200, learning rate is 0.00015, taks 9.378000020980835 seconds
2020-03-23 17:49:15,134 - RBF - ERROR - loss 1.2928031574452228, in epoch 502, in step 399, in global step 251400, learning rate is 0.00015, taks 6.246200084686279 seconds
2020-03-23 17:49:18,278 - RBF - INFO - train epoch 503 of total 5000 epoches
2020-03-23 17:49:24,488 - RBF - ERROR - loss 1.2927262468954992, in epoch 503, in step 199, in global step 251700, learning rate is 0.00015, taks 9.353999853134155 seconds
2020-03-23 17:49:30,759 - RBF - ERROR - loss 1.2927214696836569, in epoch 503, in step 399, in global step 251900, learning rate is 0.00015, taks 6.270600318908691 seconds
2020-03-23 17:49:33,882 - RBF - INFO - train epoch 504 of total 5000 epoches
2020-03-23 17:49:40,104 - RBF - ERROR - loss 1.292778449956609, in epoch 504, in step 199, in global step 252200, learning rate is 0.00015, taks 9.344199895858765 seconds
2020-03-23 17:49:46,356 - RBF - ERROR - loss 1.2929532882978154, in epoch 504, in step 399, in global step 252400, learning rate is 0.00015, taks 6.250400066375732 seconds
2020-03-23 17:49:49,499 - RBF - INFO - train epoch 505 of total 5000 epoches
2020-03-23 17:49:55,748 - RBF - ERROR - loss 1.2930473984840565, in epoch 505, in step 199, in global step 252700, learning rate is 0.00015, taks 9.391799926757812 seconds
2020-03-23 17:50:02,008 - RBF - ERROR - loss 1.2927006731208543, in epoch 505, in step 399, in global step 252900, learning rate is 0.00015, taks 6.25980019569397 seconds
2020-03-23 17:50:05,118 - RBF - INFO - train epoch 506 of total 5000 epoches
2020-03-23 17:50:11,377 - RBF - ERROR - loss 1.2927086076888543, in epoch 506, in step 199, in global step 253200, learning rate is 0.00015, taks 9.36840009689331 seconds
2020-03-23 17:50:17,613 - RBF - ERROR - loss 1.2927062244738978, in epoch 506, in step 399, in global step 253400, learning rate is 0.00015, taks 6.235399961471558 seconds
2020-03-23 17:50:20,716 - RBF - INFO - train epoch 507 of total 5000 epoches
2020-03-23 17:50:26,520 - RBF - ERROR - loss 1.2926778319625003, in epoch 507, in step 199, in global step 253700, learning rate is 0.00015, taks 8.906800031661987 seconds
2020-03-23 17:50:32,211 - RBF - ERROR - loss 1.2927788645786433, in epoch 507, in step 399, in global step 253900, learning rate is 0.00015, taks 5.690400123596191 seconds
2020-03-23 17:50:35,064 - RBF - INFO - train epoch 508 of total 5000 epoches
2020-03-23 17:50:40,732 - RBF - ERROR - loss 1.2929906649602103, in epoch 508, in step 199, in global step 254200, learning rate is 0.00015, taks 8.521399736404419 seconds
2020-03-23 17:50:46,459 - RBF - ERROR - loss 1.2927662442174108, in epoch 508, in step 399, in global step 254400, learning rate is 0.00015, taks 5.726600170135498 seconds
2020-03-23 17:50:49,288 - RBF - INFO - train epoch 509 of total 5000 epoches
2020-03-23 17:50:55,031 - RBF - ERROR - loss 1.2926804857934908, in epoch 509, in step 199, in global step 254700, learning rate is 0.00015, taks 8.572799921035767 seconds
2020-03-23 17:51:00,715 - RBF - ERROR - loss 1.2927149037767998, in epoch 509, in step 399, in global step 254900, learning rate is 0.00015, taks 5.684000015258789 seconds
2020-03-23 17:51:03,570 - RBF - INFO - train epoch 510 of total 5000 epoches
2020-03-23 17:51:09,268 - RBF - ERROR - loss 1.292736038663989, in epoch 510, in step 199, in global step 255200, learning rate is 0.00015, taks 8.552599906921387 seconds
2020-03-23 17:51:14,967 - RBF - ERROR - loss 1.2929136559979189, in epoch 510, in step 399, in global step 255400, learning rate is 0.00015, taks 5.699000120162964 seconds
2020-03-23 17:51:17,821 - RBF - INFO - train epoch 511 of total 5000 epoches
2020-03-23 17:51:23,484 - RBF - ERROR - loss 1.2927708750842442, in epoch 511, in step 199, in global step 255700, learning rate is 0.00015, taks 8.515999794006348 seconds
2020-03-23 17:51:29,186 - RBF - ERROR - loss 1.2926807775960907, in epoch 511, in step 399, in global step 255900, learning rate is 0.00015, taks 5.701600074768066 seconds
2020-03-23 17:51:32,036 - RBF - INFO - train epoch 512 of total 5000 epoches
2020-03-23 17:51:37,734 - RBF - ERROR - loss 1.2927478485711406, in epoch 512, in step 199, in global step 256200, learning rate is 0.00015, taks 8.54800009727478 seconds
2020-03-23 17:51:43,451 - RBF - ERROR - loss 1.2928578708560845, in epoch 512, in step 399, in global step 256400, learning rate is 0.00015, taks 5.717000246047974 seconds
2020-03-23 17:51:46,289 - RBF - INFO - train epoch 513 of total 5000 epoches
2020-03-23 17:51:52,047 - RBF - ERROR - loss 1.292699644578768, in epoch 513, in step 199, in global step 256700, learning rate is 0.00015, taks 8.596399784088135 seconds
2020-03-23 17:51:57,714 - RBF - ERROR - loss 1.2926968710629116, in epoch 513, in step 399, in global step 256900, learning rate is 0.00015, taks 5.66700005531311 seconds
2020-03-23 17:52:00,560 - RBF - INFO - train epoch 514 of total 5000 epoches
2020-03-23 17:52:06,258 - RBF - ERROR - loss 1.2927220556807575, in epoch 514, in step 199, in global step 257200, learning rate is 0.00015, taks 8.543999910354614 seconds
2020-03-23 17:52:11,969 - RBF - ERROR - loss 1.292744589075465, in epoch 514, in step 399, in global step 257400, learning rate is 0.00015, taks 5.711400032043457 seconds
2020-03-23 17:52:14,563 - RBF - INFO - train epoch 515 of total 5000 epoches
2020-03-23 17:52:19,496 - RBF - ERROR - loss 1.2927151198959916, in epoch 515, in step 199, in global step 257700, learning rate is 0.00015, taks 7.525599956512451 seconds
2020-03-23 17:52:24,380 - RBF - ERROR - loss 1.2927689713146342, in epoch 515, in step 399, in global step 257900, learning rate is 0.00015, taks 4.883800029754639 seconds
2020-03-23 17:52:26,830 - RBF - INFO - train epoch 516 of total 5000 epoches
2020-03-23 17:52:31,699 - RBF - ERROR - loss 1.2926523817723288, in epoch 516, in step 199, in global step 258200, learning rate is 0.00015, taks 7.3196001052856445 seconds
2020-03-23 17:52:36,603 - RBF - ERROR - loss 1.2927108852057252, in epoch 516, in step 399, in global step 258400, learning rate is 0.00015, taks 4.9040000438690186 seconds
2020-03-23 17:52:39,040 - RBF - INFO - train epoch 517 of total 5000 epoches
2020-03-23 17:52:43,957 - RBF - ERROR - loss 1.2926864031368845, in epoch 517, in step 199, in global step 258700, learning rate is 0.00015, taks 7.353399753570557 seconds
2020-03-23 17:52:48,829 - RBF - ERROR - loss 1.2927170115049327, in epoch 517, in step 399, in global step 258900, learning rate is 0.00015, taks 4.87220025062561 seconds
2020-03-23 17:52:51,319 - RBF - INFO - train epoch 518 of total 5000 epoches
2020-03-23 17:52:56,210 - RBF - ERROR - loss 1.2929382723901455, in epoch 518, in step 199, in global step 259200, learning rate is 0.00015, taks 7.381399869918823 seconds
2020-03-23 17:53:01,096 - RBF - ERROR - loss 1.2926954893341358, in epoch 518, in step 399, in global step 259400, learning rate is 0.00015, taks 4.884399890899658 seconds
2020-03-23 17:53:03,537 - RBF - INFO - train epoch 519 of total 5000 epoches
2020-03-23 17:53:08,434 - RBF - ERROR - loss 1.2926523400884147, in epoch 519, in step 199, in global step 259700, learning rate is 0.00015, taks 7.337800025939941 seconds
2020-03-23 17:53:13,301 - RBF - ERROR - loss 1.2927324726835725, in epoch 519, in step 399, in global step 259900, learning rate is 0.00015, taks 4.864999771118164 seconds
2020-03-23 17:53:17,749 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 519. learning_rate is 0.00015, loss is 1.292672102500598
2020-03-23 17:53:17,749 - RBF - INFO - train epoch 520 of total 5000 epoches
2020-03-23 17:53:24,164 - RBF - ERROR - loss 1.2926473191427006, in epoch 520, in step 199, in global step 260200, learning rate is 0.00015, taks 10.863200187683105 seconds
2020-03-23 17:53:30,413 - RBF - ERROR - loss 1.2926622592255272, in epoch 520, in step 399, in global step 260400, learning rate is 0.00015, taks 6.248199939727783 seconds
2020-03-23 17:53:33,533 - RBF - INFO - train epoch 521 of total 5000 epoches
2020-03-23 17:53:39,784 - RBF - ERROR - loss 1.2927113211019776, in epoch 521, in step 199, in global step 260700, learning rate is 0.00015, taks 9.370000123977661 seconds
2020-03-23 17:53:46,041 - RBF - ERROR - loss 1.2926658293484106, in epoch 521, in step 399, in global step 260900, learning rate is 0.00015, taks 6.257399797439575 seconds
2020-03-23 17:53:49,167 - RBF - INFO - train epoch 522 of total 5000 epoches
2020-03-23 17:53:55,453 - RBF - ERROR - loss 1.2926403935130764, in epoch 522, in step 199, in global step 261200, learning rate is 0.00015, taks 9.409600019454956 seconds
2020-03-23 17:54:01,706 - RBF - ERROR - loss 1.2927172387592134, in epoch 522, in step 399, in global step 261400, learning rate is 0.00015, taks 6.253199815750122 seconds
2020-03-23 17:54:04,820 - RBF - INFO - train epoch 523 of total 5000 epoches
2020-03-23 17:54:11,082 - RBF - ERROR - loss 1.2927284227628812, in epoch 523, in step 199, in global step 261700, learning rate is 0.00015, taks 9.375999927520752 seconds
2020-03-23 17:54:17,310 - RBF - ERROR - loss 1.2926517435173908, in epoch 523, in step 399, in global step 261900, learning rate is 0.00015, taks 6.225800037384033 seconds
2020-03-23 17:54:20,436 - RBF - INFO - train epoch 524 of total 5000 epoches
2020-03-23 17:54:26,704 - RBF - ERROR - loss 1.2927657540198196, in epoch 524, in step 199, in global step 262200, learning rate is 0.00015, taks 9.394200086593628 seconds
2020-03-23 17:54:32,975 - RBF - ERROR - loss 1.292751810343594, in epoch 524, in step 399, in global step 262400, learning rate is 0.00015, taks 6.270599842071533 seconds
2020-03-23 17:54:36,103 - RBF - INFO - train epoch 525 of total 5000 epoches
2020-03-23 17:54:42,350 - RBF - ERROR - loss 1.292678421413994, in epoch 525, in step 199, in global step 262700, learning rate is 0.00015, taks 9.375200033187866 seconds
2020-03-23 17:54:48,561 - RBF - ERROR - loss 1.2927921627875927, in epoch 525, in step 399, in global step 262900, learning rate is 0.00015, taks 6.211000204086304 seconds
2020-03-23 17:54:51,712 - RBF - INFO - train epoch 526 of total 5000 epoches
2020-03-23 17:54:57,987 - RBF - ERROR - loss 1.2928092709335717, in epoch 526, in step 199, in global step 263200, learning rate is 0.00015, taks 9.425400018692017 seconds
2020-03-23 17:55:04,237 - RBF - ERROR - loss 1.2926749911228261, in epoch 526, in step 399, in global step 263400, learning rate is 0.00015, taks 6.249999761581421 seconds
2020-03-23 17:55:07,371 - RBF - INFO - train epoch 527 of total 5000 epoches
2020-03-23 17:55:13,622 - RBF - ERROR - loss 1.2927502117159204, in epoch 527, in step 199, in global step 263700, learning rate is 0.00015, taks 9.383599996566772 seconds
2020-03-23 17:55:19,888 - RBF - ERROR - loss 1.2926856002294045, in epoch 527, in step 399, in global step 263900, learning rate is 0.00015, taks 6.266400098800659 seconds
2020-03-23 17:55:23,033 - RBF - INFO - train epoch 528 of total 5000 epoches
2020-03-23 17:55:29,275 - RBF - ERROR - loss 1.2927906830984897, in epoch 528, in step 199, in global step 264200, learning rate is 0.00015, taks 9.385999917984009 seconds
2020-03-23 17:55:35,535 - RBF - ERROR - loss 1.2927106471889307, in epoch 528, in step 399, in global step 264400, learning rate is 0.00015, taks 6.259200096130371 seconds
2020-03-23 17:55:38,685 - RBF - INFO - train epoch 529 of total 5000 epoches
2020-03-23 17:55:44,919 - RBF - ERROR - loss 1.29266276682144, in epoch 529, in step 199, in global step 264700, learning rate is 0.00015, taks 9.384199857711792 seconds
2020-03-23 17:55:51,193 - RBF - ERROR - loss 1.2929240251452985, in epoch 529, in step 399, in global step 264900, learning rate is 0.00015, taks 6.27400016784668 seconds
2020-03-23 17:55:54,361 - RBF - INFO - train epoch 530 of total 5000 epoches
2020-03-23 17:56:00,625 - RBF - ERROR - loss 1.2928910932364128, in epoch 530, in step 199, in global step 265200, learning rate is 0.00015, taks 9.432399988174438 seconds
2020-03-23 17:56:06,854 - RBF - ERROR - loss 1.2926197463887823, in epoch 530, in step 399, in global step 265400, learning rate is 0.00015, taks 6.229200124740601 seconds
2020-03-23 17:56:09,984 - RBF - INFO - train epoch 531 of total 5000 epoches
2020-03-23 17:56:16,221 - RBF - ERROR - loss 1.2929024266239995, in epoch 531, in step 199, in global step 265700, learning rate is 0.00015, taks 9.365799903869629 seconds
2020-03-23 17:56:22,498 - RBF - ERROR - loss 1.2928581343849375, in epoch 531, in step 399, in global step 265900, learning rate is 0.00015, taks 6.276600122451782 seconds
2020-03-23 17:56:25,609 - RBF - INFO - train epoch 532 of total 5000 epoches
2020-03-23 17:56:31,871 - RBF - ERROR - loss 1.292677658104338, in epoch 532, in step 199, in global step 266200, learning rate is 0.00015, taks 9.37339997291565 seconds
2020-03-23 17:56:38,140 - RBF - ERROR - loss 1.2927341497461124, in epoch 532, in step 399, in global step 266400, learning rate is 0.00015, taks 6.2688000202178955 seconds
2020-03-23 17:56:41,247 - RBF - INFO - train epoch 533 of total 5000 epoches
2020-03-23 17:56:47,493 - RBF - ERROR - loss 1.292808629361471, in epoch 533, in step 199, in global step 266700, learning rate is 0.00015, taks 9.351799964904785 seconds
2020-03-23 17:56:53,756 - RBF - ERROR - loss 1.2926530018515308, in epoch 533, in step 399, in global step 266900, learning rate is 0.00015, taks 6.262200117111206 seconds
2020-03-23 17:56:56,857 - RBF - INFO - train epoch 534 of total 5000 epoches
2020-03-23 17:57:03,122 - RBF - ERROR - loss 1.292607321778856, in epoch 534, in step 199, in global step 267200, learning rate is 0.00015, taks 9.36620020866394 seconds
2020-03-23 17:57:09,384 - RBF - ERROR - loss 1.2928043676959546, in epoch 534, in step 399, in global step 267400, learning rate is 0.00015, taks 6.261600017547607 seconds
2020-03-23 17:57:12,505 - RBF - INFO - train epoch 535 of total 5000 epoches
2020-03-23 17:57:18,772 - RBF - ERROR - loss 1.2927913961426523, in epoch 535, in step 199, in global step 267700, learning rate is 0.00015, taks 9.388599872589111 seconds
2020-03-23 17:57:25,036 - RBF - ERROR - loss 1.292769979512031, in epoch 535, in step 399, in global step 267900, learning rate is 0.00015, taks 6.247999906539917 seconds
2020-03-23 17:57:28,166 - RBF - INFO - train epoch 536 of total 5000 epoches
2020-03-23 17:57:34,467 - RBF - ERROR - loss 1.2925927799567873, in epoch 536, in step 199, in global step 268200, learning rate is 0.00015, taks 9.430599927902222 seconds
2020-03-23 17:57:40,665 - RBF - ERROR - loss 1.2928596741634404, in epoch 536, in step 399, in global step 268400, learning rate is 0.00015, taks 6.197200059890747 seconds
2020-03-23 17:57:43,518 - RBF - INFO - train epoch 537 of total 5000 epoches
2020-03-23 17:57:49,224 - RBF - ERROR - loss 1.2929338162444615, in epoch 537, in step 199, in global step 268700, learning rate is 0.00015, taks 8.559399843215942 seconds
2020-03-23 17:57:54,965 - RBF - ERROR - loss 1.2928834988197488, in epoch 537, in step 399, in global step 268900, learning rate is 0.00015, taks 5.740799903869629 seconds
2020-03-23 17:57:57,824 - RBF - INFO - train epoch 538 of total 5000 epoches
2020-03-23 17:58:03,536 - RBF - ERROR - loss 1.2926336327993238, in epoch 538, in step 199, in global step 269200, learning rate is 0.00015, taks 8.570800304412842 seconds
2020-03-23 17:58:09,230 - RBF - ERROR - loss 1.2926533486840082, in epoch 538, in step 399, in global step 269400, learning rate is 0.00015, taks 5.694200038909912 seconds
2020-03-23 17:58:12,082 - RBF - INFO - train epoch 539 of total 5000 epoches
2020-03-23 17:58:17,804 - RBF - ERROR - loss 1.2926250312615006, in epoch 539, in step 199, in global step 269700, learning rate is 0.00015, taks 8.572799921035767 seconds
2020-03-23 17:58:23,485 - RBF - ERROR - loss 1.2928041002713684, in epoch 539, in step 399, in global step 269900, learning rate is 0.00015, taks 5.680999994277954 seconds
2020-03-23 17:58:28,629 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 539. learning_rate is 0.00015, loss is 1.292717754122794
2020-03-23 17:58:28,630 - RBF - INFO - train epoch 540 of total 5000 epoches
2020-03-23 17:58:35,130 - RBF - ERROR - loss 1.2926183392573836, in epoch 540, in step 199, in global step 270200, learning rate is 0.00015, taks 11.64520001411438 seconds
2020-03-23 17:58:41,361 - RBF - ERROR - loss 1.292611900577817, in epoch 540, in step 399, in global step 270400, learning rate is 0.00015, taks 6.230799913406372 seconds
2020-03-23 17:58:44,492 - RBF - INFO - train epoch 541 of total 5000 epoches
2020-03-23 17:58:50,719 - RBF - ERROR - loss 1.2927606091983401, in epoch 541, in step 199, in global step 270700, learning rate is 0.00015, taks 9.35859990119934 seconds
2020-03-23 17:58:57,005 - RBF - ERROR - loss 1.2927979889245178, in epoch 541, in step 399, in global step 270900, learning rate is 0.00015, taks 6.284600257873535 seconds
2020-03-23 17:59:00,066 - RBF - INFO - train epoch 542 of total 5000 epoches
2020-03-23 17:59:05,857 - RBF - ERROR - loss 1.2925887736075643, in epoch 542, in step 199, in global step 271200, learning rate is 0.00015, taks 8.851799964904785 seconds
2020-03-23 17:59:11,557 - RBF - ERROR - loss 1.2927364809125885, in epoch 542, in step 399, in global step 271400, learning rate is 0.00015, taks 5.700199842453003 seconds
2020-03-23 17:59:14,403 - RBF - INFO - train epoch 543 of total 5000 epoches
2020-03-23 17:59:20,123 - RBF - ERROR - loss 1.2926321483802004, in epoch 543, in step 199, in global step 271700, learning rate is 0.00015, taks 8.566400051116943 seconds
2020-03-23 17:59:25,820 - RBF - ERROR - loss 1.2926064911572641, in epoch 543, in step 399, in global step 271900, learning rate is 0.00015, taks 5.69700026512146 seconds
2020-03-23 17:59:28,679 - RBF - INFO - train epoch 544 of total 5000 epoches
2020-03-23 17:59:34,368 - RBF - ERROR - loss 1.2926179597839496, in epoch 544, in step 199, in global step 272200, learning rate is 0.00015, taks 8.547599792480469 seconds
2020-03-23 17:59:40,067 - RBF - ERROR - loss 1.292645957421984, in epoch 544, in step 399, in global step 272400, learning rate is 0.00015, taks 5.6986000537872314 seconds
2020-03-23 17:59:42,921 - RBF - INFO - train epoch 545 of total 5000 epoches
2020-03-23 17:59:48,597 - RBF - ERROR - loss 1.292639914145586, in epoch 545, in step 199, in global step 272700, learning rate is 0.00015, taks 8.53060007095337 seconds
2020-03-23 17:59:54,321 - RBF - ERROR - loss 1.2927004013934438, in epoch 545, in step 399, in global step 272900, learning rate is 0.00015, taks 5.724200010299683 seconds
2020-03-23 17:59:57,155 - RBF - INFO - train epoch 546 of total 5000 epoches
2020-03-23 18:00:02,880 - RBF - ERROR - loss 1.2925921076129845, in epoch 546, in step 199, in global step 273200, learning rate is 0.00015, taks 8.557200193405151 seconds
2020-03-23 18:00:08,566 - RBF - ERROR - loss 1.2926703490593108, in epoch 546, in step 399, in global step 273400, learning rate is 0.00015, taks 5.686599969863892 seconds
2020-03-23 18:00:11,418 - RBF - INFO - train epoch 547 of total 5000 epoches
2020-03-23 18:00:17,082 - RBF - ERROR - loss 1.2925971764686672, in epoch 547, in step 199, in global step 273700, learning rate is 0.00015, taks 8.514800071716309 seconds
2020-03-23 18:00:21,978 - RBF - ERROR - loss 1.292544404511982, in epoch 547, in step 399, in global step 273900, learning rate is 0.00015, taks 4.894999980926514 seconds
2020-03-23 18:00:24,432 - RBF - INFO - train epoch 548 of total 5000 epoches
2020-03-23 18:00:29,320 - RBF - ERROR - loss 1.2925649854831691, in epoch 548, in step 199, in global step 274200, learning rate is 0.00015, taks 7.342200040817261 seconds
2020-03-23 18:00:34,263 - RBF - ERROR - loss 1.2926412407108137, in epoch 548, in step 399, in global step 274400, learning rate is 0.00015, taks 4.942399978637695 seconds
2020-03-23 18:00:36,716 - RBF - INFO - train epoch 549 of total 5000 epoches
2020-03-23 18:00:41,621 - RBF - ERROR - loss 1.292599454842431, in epoch 549, in step 199, in global step 274700, learning rate is 0.00015, taks 7.357800006866455 seconds
2020-03-23 18:00:46,512 - RBF - ERROR - loss 1.2927032169631427, in epoch 549, in step 399, in global step 274900, learning rate is 0.00015, taks 4.890200138092041 seconds
2020-03-23 18:00:48,950 - RBF - INFO - train epoch 550 of total 5000 epoches
2020-03-23 18:00:53,900 - RBF - ERROR - loss 1.292736012930662, in epoch 550, in step 199, in global step 275200, learning rate is 0.00015, taks 7.3887999057769775 seconds
2020-03-23 18:00:58,809 - RBF - ERROR - loss 1.2928645575687767, in epoch 550, in step 399, in global step 275400, learning rate is 0.00015, taks 4.9070000648498535 seconds
2020-03-23 18:01:01,250 - RBF - INFO - train epoch 551 of total 5000 epoches
2020-03-23 18:01:06,167 - RBF - ERROR - loss 1.2925873462715112, in epoch 551, in step 199, in global step 275700, learning rate is 0.00015, taks 7.357599973678589 seconds
2020-03-23 18:01:11,067 - RBF - ERROR - loss 1.2927206558309896, in epoch 551, in step 399, in global step 275900, learning rate is 0.00015, taks 4.89900016784668 seconds
2020-03-23 18:01:13,508 - RBF - INFO - train epoch 552 of total 5000 epoches
2020-03-23 18:01:18,409 - RBF - ERROR - loss 1.2925481706441326, in epoch 552, in step 199, in global step 276200, learning rate is 0.00015, taks 7.341799974441528 seconds
2020-03-23 18:01:23,302 - RBF - ERROR - loss 1.2925262022010129, in epoch 552, in step 399, in global step 276400, learning rate is 0.00015, taks 4.891999959945679 seconds
2020-03-23 18:01:25,742 - RBF - INFO - train epoch 553 of total 5000 epoches
2020-03-23 18:01:30,643 - RBF - ERROR - loss 1.2925824805513362, in epoch 553, in step 199, in global step 276700, learning rate is 0.00015, taks 7.341599941253662 seconds
2020-03-23 18:01:35,533 - RBF - ERROR - loss 1.2929034709632043, in epoch 553, in step 399, in global step 276900, learning rate is 0.00015, taks 4.889400005340576 seconds
2020-03-23 18:01:37,974 - RBF - INFO - train epoch 554 of total 5000 epoches
2020-03-23 18:01:42,888 - RBF - ERROR - loss 1.292609794380499, in epoch 554, in step 199, in global step 277200, learning rate is 0.00015, taks 7.355400085449219 seconds
2020-03-23 18:01:47,747 - RBF - ERROR - loss 1.293108533464455, in epoch 554, in step 399, in global step 277400, learning rate is 0.00015, taks 4.8592000007629395 seconds
2020-03-23 18:01:50,218 - RBF - INFO - train epoch 555 of total 5000 epoches
2020-03-23 18:01:55,122 - RBF - ERROR - loss 1.2925868895824875, in epoch 555, in step 199, in global step 277700, learning rate is 0.00015, taks 7.374399900436401 seconds
2020-03-23 18:02:00,026 - RBF - ERROR - loss 1.2925976741801843, in epoch 555, in step 399, in global step 277900, learning rate is 0.00015, taks 4.9040000438690186 seconds
2020-03-23 18:02:02,498 - RBF - INFO - train epoch 556 of total 5000 epoches
2020-03-23 18:02:07,399 - RBF - ERROR - loss 1.2926698508736618, in epoch 556, in step 199, in global step 278200, learning rate is 0.00015, taks 7.372999906539917 seconds
2020-03-23 18:02:12,305 - RBF - ERROR - loss 1.2927104458691467, in epoch 556, in step 399, in global step 278400, learning rate is 0.00015, taks 4.9040000438690186 seconds
2020-03-23 18:02:14,754 - RBF - INFO - train epoch 557 of total 5000 epoches
2020-03-23 18:02:19,661 - RBF - ERROR - loss 1.292617075669205, in epoch 557, in step 199, in global step 278700, learning rate is 0.00015, taks 7.356200218200684 seconds
2020-03-23 18:02:24,565 - RBF - ERROR - loss 1.2926410283489118, in epoch 557, in step 399, in global step 278900, learning rate is 0.00015, taks 4.904399871826172 seconds
2020-03-23 18:02:27,032 - RBF - INFO - train epoch 558 of total 5000 epoches
2020-03-23 18:02:31,926 - RBF - ERROR - loss 1.292864244828761, in epoch 558, in step 199, in global step 279200, learning rate is 0.00015, taks 7.360400199890137 seconds
2020-03-23 18:02:36,818 - RBF - ERROR - loss 1.2925398172738696, in epoch 558, in step 399, in global step 279400, learning rate is 0.00015, taks 4.891999959945679 seconds
2020-03-23 18:02:39,337 - RBF - INFO - train epoch 559 of total 5000 epoches
2020-03-23 18:02:43,911 - RBF - ERROR - loss 1.2925462790381719, in epoch 559, in step 199, in global step 279700, learning rate is 0.00015, taks 7.093600034713745 seconds
2020-03-23 18:02:48,495 - RBF - ERROR - loss 1.2925731263314884, in epoch 559, in step 399, in global step 279900, learning rate is 0.00015, taks 4.583199977874756 seconds
2020-03-23 18:02:53,176 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 559. learning_rate is 0.00015, loss is 1.29252792631256
2020-03-23 18:02:53,176 - RBF - INFO - train epoch 560 of total 5000 epoches
2020-03-23 18:02:59,047 - RBF - ERROR - loss 1.2926263593960228, in epoch 560, in step 199, in global step 280200, learning rate is 0.00015, taks 10.552799940109253 seconds
2020-03-23 18:03:04,738 - RBF - ERROR - loss 1.2925583246431536, in epoch 560, in step 399, in global step 280400, learning rate is 0.00015, taks 5.690999746322632 seconds
2020-03-23 18:03:07,612 - RBF - INFO - train epoch 561 of total 5000 epoches
2020-03-23 18:03:13,299 - RBF - ERROR - loss 1.292663565852912, in epoch 561, in step 199, in global step 280700, learning rate is 0.00015, taks 8.560400247573853 seconds
2020-03-23 18:03:19,002 - RBF - ERROR - loss 1.2925531440513818, in epoch 561, in step 399, in global step 280900, learning rate is 0.00015, taks 5.70359992980957 seconds
2020-03-23 18:03:21,847 - RBF - INFO - train epoch 562 of total 5000 epoches
2020-03-23 18:03:27,531 - RBF - ERROR - loss 1.292514747838999, in epoch 562, in step 199, in global step 281200, learning rate is 0.00015, taks 8.527399778366089 seconds
2020-03-23 18:03:33,217 - RBF - ERROR - loss 1.292544862174567, in epoch 562, in step 399, in global step 281400, learning rate is 0.00015, taks 5.685800075531006 seconds
2020-03-23 18:03:36,077 - RBF - INFO - train epoch 563 of total 5000 epoches
2020-03-23 18:03:41,759 - RBF - ERROR - loss 1.2925543336463234, in epoch 563, in step 199, in global step 281700, learning rate is 0.00015, taks 8.542399883270264 seconds
2020-03-23 18:03:47,450 - RBF - ERROR - loss 1.2925551501818844, in epoch 563, in step 399, in global step 281900, learning rate is 0.00015, taks 5.691200017929077 seconds
2020-03-23 18:03:50,340 - RBF - INFO - train epoch 564 of total 5000 epoches
2020-03-23 18:03:56,039 - RBF - ERROR - loss 1.2926279372912466, in epoch 564, in step 199, in global step 282200, learning rate is 0.00015, taks 8.588800191879272 seconds
2020-03-23 18:04:01,740 - RBF - ERROR - loss 1.2925211935081853, in epoch 564, in step 399, in global step 282400, learning rate is 0.00015, taks 5.7014000415802 seconds
2020-03-23 18:04:04,577 - RBF - INFO - train epoch 565 of total 5000 epoches
2020-03-23 18:04:09,379 - RBF - ERROR - loss 1.2925336585370975, in epoch 565, in step 199, in global step 282700, learning rate is 0.00015, taks 7.638599872589111 seconds
2020-03-23 18:04:13,990 - RBF - ERROR - loss 1.2927071354893067, in epoch 565, in step 399, in global step 282900, learning rate is 0.00015, taks 4.61080002784729 seconds
2020-03-23 18:04:16,256 - RBF - INFO - train epoch 566 of total 5000 epoches
2020-03-23 18:04:20,834 - RBF - ERROR - loss 1.2926031697518363, in epoch 566, in step 199, in global step 283200, learning rate is 0.00015, taks 6.844600200653076 seconds
2020-03-23 18:04:25,439 - RBF - ERROR - loss 1.2926172925941735, in epoch 566, in step 399, in global step 283400, learning rate is 0.00015, taks 4.6041998863220215 seconds
2020-03-23 18:04:27,739 - RBF - INFO - train epoch 567 of total 5000 epoches
2020-03-23 18:04:32,306 - RBF - ERROR - loss 1.292594166710748, in epoch 567, in step 199, in global step 283700, learning rate is 0.00015, taks 6.867600202560425 seconds
2020-03-23 18:04:36,905 - RBF - ERROR - loss 1.2927078851943445, in epoch 567, in step 399, in global step 283900, learning rate is 0.00015, taks 4.597999811172485 seconds
2020-03-23 18:04:39,200 - RBF - INFO - train epoch 568 of total 5000 epoches
2020-03-23 18:04:43,775 - RBF - ERROR - loss 1.2925803674018317, in epoch 568, in step 199, in global step 284200, learning rate is 0.00015, taks 6.869800090789795 seconds
2020-03-23 18:04:48,352 - RBF - ERROR - loss 1.2925442351213077, in epoch 568, in step 399, in global step 284400, learning rate is 0.00015, taks 4.577399969100952 seconds
2020-03-23 18:04:50,649 - RBF - INFO - train epoch 569 of total 5000 epoches
2020-03-23 18:04:54,924 - RBF - ERROR - loss 1.2926245875674314, in epoch 569, in step 199, in global step 284700, learning rate is 0.00015, taks 6.570599794387817 seconds
2020-03-23 18:04:59,017 - RBF - ERROR - loss 1.2926827762558737, in epoch 569, in step 399, in global step 284900, learning rate is 0.00015, taks 4.093199968338013 seconds
2020-03-23 18:05:01,054 - RBF - INFO - train epoch 570 of total 5000 epoches
2020-03-23 18:05:05,159 - RBF - ERROR - loss 1.2924843424116859, in epoch 570, in step 199, in global step 285200, learning rate is 0.00015, taks 6.141800165176392 seconds
2020-03-23 18:05:09,284 - RBF - ERROR - loss 1.292545388256589, in epoch 570, in step 399, in global step 285400, learning rate is 0.00015, taks 4.125199794769287 seconds
2020-03-23 18:05:11,328 - RBF - INFO - train epoch 571 of total 5000 epoches
2020-03-23 18:05:15,418 - RBF - ERROR - loss 1.2925554350451822, in epoch 571, in step 199, in global step 285700, learning rate is 0.00015, taks 6.132800102233887 seconds
2020-03-23 18:05:19,498 - RBF - ERROR - loss 1.2925026184572086, in epoch 571, in step 399, in global step 285900, learning rate is 0.00015, taks 4.0802001953125 seconds
2020-03-23 18:05:21,533 - RBF - INFO - train epoch 572 of total 5000 epoches
2020-03-23 18:05:25,615 - RBF - ERROR - loss 1.2925749234031545, in epoch 572, in step 199, in global step 286200, learning rate is 0.00015, taks 6.11680006980896 seconds
2020-03-23 18:05:29,687 - RBF - ERROR - loss 1.292637277835, in epoch 572, in step 399, in global step 286400, learning rate is 0.00015, taks 4.071599721908569 seconds
2020-03-23 18:05:31,713 - RBF - INFO - train epoch 573 of total 5000 epoches
2020-03-23 18:05:35,782 - RBF - ERROR - loss 1.2924983900186584, in epoch 573, in step 199, in global step 286700, learning rate is 0.00015, taks 6.095400094985962 seconds
2020-03-23 18:05:39,879 - RBF - ERROR - loss 1.2926012305523302, in epoch 573, in step 399, in global step 286900, learning rate is 0.00015, taks 4.095600128173828 seconds
2020-03-23 18:05:41,913 - RBF - INFO - train epoch 574 of total 5000 epoches
2020-03-23 18:05:46,028 - RBF - ERROR - loss 1.2926989539822389, in epoch 574, in step 199, in global step 287200, learning rate is 0.00015, taks 6.149799823760986 seconds
2020-03-23 18:05:50,114 - RBF - ERROR - loss 1.29255535335494, in epoch 574, in step 399, in global step 287400, learning rate is 0.00015, taks 4.085200071334839 seconds
2020-03-23 18:05:52,165 - RBF - INFO - train epoch 575 of total 5000 epoches
2020-03-23 18:05:56,234 - RBF - ERROR - loss 1.2925171276300327, in epoch 575, in step 199, in global step 287700, learning rate is 0.00015, taks 6.120800018310547 seconds
2020-03-23 18:06:00,319 - RBF - ERROR - loss 1.2926595185422973, in epoch 575, in step 399, in global step 287900, learning rate is 0.00015, taks 4.084199905395508 seconds
2020-03-23 18:06:02,366 - RBF - INFO - train epoch 576 of total 5000 epoches
2020-03-23 18:06:06,446 - RBF - ERROR - loss 1.292487566953145, in epoch 576, in step 199, in global step 288200, learning rate is 0.00015, taks 6.127800226211548 seconds
2020-03-23 18:06:10,512 - RBF - ERROR - loss 1.292560617385497, in epoch 576, in step 399, in global step 288400, learning rate is 0.00015, taks 4.065199851989746 seconds
2020-03-23 18:06:12,547 - RBF - INFO - train epoch 577 of total 5000 epoches
2020-03-23 18:06:16,613 - RBF - ERROR - loss 1.2925538697550574, in epoch 577, in step 199, in global step 288700, learning rate is 0.00015, taks 6.101800203323364 seconds
2020-03-23 18:06:20,694 - RBF - ERROR - loss 1.29252836067906, in epoch 577, in step 399, in global step 288900, learning rate is 0.00015, taks 4.080199956893921 seconds
2020-03-23 18:06:22,737 - RBF - INFO - train epoch 578 of total 5000 epoches
2020-03-23 18:06:26,801 - RBF - ERROR - loss 1.2926025036860465, in epoch 578, in step 199, in global step 289200, learning rate is 0.00015, taks 6.107000112533569 seconds
2020-03-23 18:06:30,876 - RBF - ERROR - loss 1.2924527256379905, in epoch 578, in step 399, in global step 289400, learning rate is 0.00015, taks 4.075199842453003 seconds
2020-03-23 18:06:32,918 - RBF - INFO - train epoch 579 of total 5000 epoches
2020-03-23 18:06:37,011 - RBF - ERROR - loss 1.2924599673183617, in epoch 579, in step 199, in global step 289700, learning rate is 0.00015, taks 6.134799957275391 seconds
2020-03-23 18:06:41,086 - RBF - ERROR - loss 1.2924580788767497, in epoch 579, in step 399, in global step 289900, learning rate is 0.00015, taks 4.074399948120117 seconds
2020-03-23 18:06:45,448 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 579. learning_rate is 0.00015, loss is 1.2924574168412633
2020-03-23 18:06:45,448 - RBF - INFO - train epoch 580 of total 5000 epoches
2020-03-23 18:06:52,636 - RBF - ERROR - loss 1.2924562646364397, in epoch 580, in step 199, in global step 290200, learning rate is 0.00015, taks 11.550400018692017 seconds
2020-03-23 18:06:58,887 - RBF - ERROR - loss 1.2924553387907212, in epoch 580, in step 399, in global step 290400, learning rate is 0.00015, taks 6.251000165939331 seconds
2020-03-23 18:07:02,027 - RBF - INFO - train epoch 581 of total 5000 epoches
2020-03-23 18:07:08,271 - RBF - ERROR - loss 1.2924640902293532, in epoch 581, in step 199, in global step 290700, learning rate is 0.00015, taks 9.38319993019104 seconds
2020-03-23 18:07:14,528 - RBF - ERROR - loss 1.2924596456468633, in epoch 581, in step 399, in global step 290900, learning rate is 0.00015, taks 6.256999969482422 seconds
2020-03-23 18:07:17,642 - RBF - INFO - train epoch 582 of total 5000 epoches
2020-03-23 18:07:23,365 - RBF - ERROR - loss 1.2925395673957367, in epoch 582, in step 199, in global step 291200, learning rate is 0.00015, taks 8.837200164794922 seconds
2020-03-23 18:07:29,044 - RBF - ERROR - loss 1.2924753015527897, in epoch 582, in step 399, in global step 291400, learning rate is 0.00015, taks 5.678999900817871 seconds
2020-03-23 18:07:31,902 - RBF - INFO - train epoch 583 of total 5000 epoches
2020-03-23 18:07:36,994 - RBF - ERROR - loss 1.2927115861882876, in epoch 583, in step 199, in global step 291700, learning rate is 0.00015, taks 7.950599908828735 seconds
2020-03-23 18:07:41,961 - RBF - ERROR - loss 1.2924938923312277, in epoch 583, in step 399, in global step 291900, learning rate is 0.00015, taks 4.965400218963623 seconds
2020-03-23 18:07:44,407 - RBF - INFO - train epoch 584 of total 5000 epoches
2020-03-23 18:07:49,309 - RBF - ERROR - loss 1.2926008921984615, in epoch 584, in step 199, in global step 292200, learning rate is 0.00015, taks 7.347800016403198 seconds
2020-03-23 18:07:54,260 - RBF - ERROR - loss 1.2924576348536354, in epoch 584, in step 399, in global step 292400, learning rate is 0.00015, taks 4.9514000415802 seconds
2020-03-23 18:07:56,710 - RBF - INFO - train epoch 585 of total 5000 epoches
2020-03-23 18:08:01,632 - RBF - ERROR - loss 1.2926450553907034, in epoch 585, in step 199, in global step 292700, learning rate is 0.00015, taks 7.3715996742248535 seconds
2020-03-23 18:08:06,569 - RBF - ERROR - loss 1.29253298466198, in epoch 585, in step 399, in global step 292900, learning rate is 0.00015, taks 4.936000108718872 seconds
2020-03-23 18:08:09,006 - RBF - INFO - train epoch 586 of total 5000 epoches
2020-03-23 18:08:13,922 - RBF - ERROR - loss 1.2924773774767568, in epoch 586, in step 199, in global step 293200, learning rate is 0.00015, taks 7.353399991989136 seconds
2020-03-23 18:08:18,837 - RBF - ERROR - loss 1.2926737281451912, in epoch 586, in step 399, in global step 293400, learning rate is 0.00015, taks 4.914999961853027 seconds
2020-03-23 18:08:21,292 - RBF - INFO - train epoch 587 of total 5000 epoches
2020-03-23 18:08:26,212 - RBF - ERROR - loss 1.292488318445176, in epoch 587, in step 199, in global step 293700, learning rate is 0.00015, taks 7.374600172042847 seconds
2020-03-23 18:08:31,125 - RBF - ERROR - loss 1.292488694146901, in epoch 587, in step 399, in global step 293900, learning rate is 0.00015, taks 4.913399696350098 seconds
2020-03-23 18:08:33,582 - RBF - INFO - train epoch 588 of total 5000 epoches
2020-03-23 18:08:38,532 - RBF - ERROR - loss 1.2924832238941721, in epoch 588, in step 199, in global step 294200, learning rate is 0.00015, taks 7.4066002368927 seconds
2020-03-23 18:08:43,432 - RBF - ERROR - loss 1.2925511053612857, in epoch 588, in step 399, in global step 294400, learning rate is 0.00015, taks 4.900000095367432 seconds
2020-03-23 18:08:45,876 - RBF - INFO - train epoch 589 of total 5000 epoches
2020-03-23 18:08:50,772 - RBF - ERROR - loss 1.2925324983666668, in epoch 589, in step 199, in global step 294700, learning rate is 0.00015, taks 7.340399742126465 seconds
2020-03-23 18:08:55,690 - RBF - ERROR - loss 1.2926138478783487, in epoch 589, in step 399, in global step 294900, learning rate is 0.00015, taks 4.918000221252441 seconds
2020-03-23 18:08:58,148 - RBF - INFO - train epoch 590 of total 5000 epoches
2020-03-23 18:09:03,158 - RBF - ERROR - loss 1.2925283332905766, in epoch 590, in step 199, in global step 295200, learning rate is 0.00015, taks 7.4683997631073 seconds
2020-03-23 18:09:08,267 - RBF - ERROR - loss 1.2926629865068486, in epoch 590, in step 399, in global step 295400, learning rate is 0.00015, taks 5.107800006866455 seconds
2020-03-23 18:09:10,606 - RBF - INFO - train epoch 591 of total 5000 epoches
2020-03-23 18:09:14,546 - RBF - ERROR - loss 1.2924776574847867, in epoch 591, in step 199, in global step 295700, learning rate is 0.00015, taks 6.277400016784668 seconds
2020-03-23 18:09:18,451 - RBF - ERROR - loss 1.2927188262498222, in epoch 591, in step 399, in global step 295900, learning rate is 0.00015, taks 3.9049999713897705 seconds
2020-03-23 18:09:20,387 - RBF - INFO - train epoch 592 of total 5000 epoches
2020-03-23 18:09:24,252 - RBF - ERROR - loss 1.2927049073335928, in epoch 592, in step 199, in global step 296200, learning rate is 0.00015, taks 5.801800012588501 seconds
2020-03-23 18:09:28,110 - RBF - ERROR - loss 1.2926556265232894, in epoch 592, in step 399, in global step 296400, learning rate is 0.00015, taks 3.8571999073028564 seconds
2020-03-23 18:09:29,886 - RBF - INFO - train epoch 593 of total 5000 epoches
2020-03-23 18:09:33,429 - RBF - ERROR - loss 1.2926302692909448, in epoch 593, in step 199, in global step 296700, learning rate is 0.00015, taks 5.319000005722046 seconds
2020-03-23 18:09:36,958 - RBF - ERROR - loss 1.292501075886493, in epoch 593, in step 399, in global step 296900, learning rate is 0.00015, taks 3.5292000770568848 seconds
2020-03-23 18:09:38,759 - RBF - INFO - train epoch 594 of total 5000 epoches
2020-03-23 18:09:42,288 - RBF - ERROR - loss 1.292752080175374, in epoch 594, in step 199, in global step 297200, learning rate is 0.00015, taks 5.330399990081787 seconds
2020-03-23 18:09:45,812 - RBF - ERROR - loss 1.293095412943448, in epoch 594, in step 399, in global step 297400, learning rate is 0.00015, taks 3.5236001014709473 seconds
2020-03-23 18:09:47,599 - RBF - INFO - train epoch 595 of total 5000 epoches
2020-03-23 18:09:51,153 - RBF - ERROR - loss 1.292523272660442, in epoch 595, in step 199, in global step 297700, learning rate is 0.00015, taks 5.341599941253662 seconds
2020-03-23 18:09:54,716 - RBF - ERROR - loss 1.2925330283660181, in epoch 595, in step 399, in global step 297900, learning rate is 0.00015, taks 3.5624001026153564 seconds
2020-03-23 18:09:56,481 - RBF - INFO - train epoch 596 of total 5000 epoches
2020-03-23 18:10:00,026 - RBF - ERROR - loss 1.292629120962038, in epoch 596, in step 199, in global step 298200, learning rate is 0.00015, taks 5.310199975967407 seconds
2020-03-23 18:10:03,574 - RBF - ERROR - loss 1.2925127647100552, in epoch 596, in step 399, in global step 298400, learning rate is 0.00015, taks 3.5483999252319336 seconds
2020-03-23 18:10:05,349 - RBF - INFO - train epoch 597 of total 5000 epoches
2020-03-23 18:10:08,883 - RBF - ERROR - loss 1.292587827713951, in epoch 597, in step 199, in global step 298700, learning rate is 0.00015, taks 5.308799982070923 seconds
2020-03-23 18:10:12,424 - RBF - ERROR - loss 1.2924999915961715, in epoch 597, in step 399, in global step 298900, learning rate is 0.00015, taks 3.540799856185913 seconds
2020-03-23 18:10:14,202 - RBF - INFO - train epoch 598 of total 5000 epoches
2020-03-23 18:10:17,729 - RBF - ERROR - loss 1.2927209500644528, in epoch 598, in step 199, in global step 299200, learning rate is 0.00015, taks 5.305000066757202 seconds
2020-03-23 18:10:21,271 - RBF - ERROR - loss 1.2924721908312984, in epoch 598, in step 399, in global step 299400, learning rate is 0.00015, taks 3.5422000885009766 seconds
2020-03-23 18:10:23,048 - RBF - INFO - train epoch 599 of total 5000 epoches
2020-03-23 18:10:26,578 - RBF - ERROR - loss 1.2924617832338274, in epoch 599, in step 199, in global step 299700, learning rate is 0.00015, taks 5.3053998947143555 seconds
2020-03-23 18:10:30,130 - RBF - ERROR - loss 1.292643962473293, in epoch 599, in step 399, in global step 299900, learning rate is 0.00015, taks 3.5522000789642334 seconds
2020-03-23 18:10:34,239 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 599. learning_rate is 0.00015, loss is 1.2924960514647506
2020-03-23 18:10:34,239 - RBF - INFO - train epoch 600 of total 5000 epoches
2020-03-23 18:10:40,735 - RBF - ERROR - loss 1.2927590128352693, in epoch 600, in step 199, in global step 300200, learning rate is 0.00015, taks 10.605599880218506 seconds
2020-03-23 18:10:46,998 - RBF - ERROR - loss 1.2924691663838856, in epoch 600, in step 399, in global step 300400, learning rate is 0.00015, taks 6.261199951171875 seconds
2020-03-23 18:10:50,131 - RBF - INFO - train epoch 601 of total 5000 epoches
2020-03-23 18:10:56,448 - RBF - ERROR - loss 1.2924586510487575, in epoch 601, in step 199, in global step 300700, learning rate is 0.00015, taks 9.448600053787231 seconds
2020-03-23 18:11:02,736 - RBF - ERROR - loss 1.2924362802234417, in epoch 601, in step 399, in global step 300900, learning rate is 0.00015, taks 6.287400245666504 seconds
2020-03-23 18:11:05,891 - RBF - INFO - train epoch 602 of total 5000 epoches
2020-03-23 18:11:12,180 - RBF - ERROR - loss 1.2924301056309264, in epoch 602, in step 199, in global step 301200, learning rate is 0.00015, taks 9.444599866867065 seconds
2020-03-23 18:11:18,452 - RBF - ERROR - loss 1.2928161329462302, in epoch 602, in step 399, in global step 301400, learning rate is 0.00015, taks 6.270600080490112 seconds
2020-03-23 18:11:21,576 - RBF - INFO - train epoch 603 of total 5000 epoches
2020-03-23 18:11:27,912 - RBF - ERROR - loss 1.2924640959054225, in epoch 603, in step 199, in global step 301700, learning rate is 0.00015, taks 9.459800243377686 seconds
2020-03-23 18:11:33,223 - RBF - ERROR - loss 1.292634490766594, in epoch 603, in step 399, in global step 301900, learning rate is 0.00015, taks 5.310999631881714 seconds
2020-03-23 18:11:35,705 - RBF - INFO - train epoch 604 of total 5000 epoches
2020-03-23 18:11:40,616 - RBF - ERROR - loss 1.2930837997467068, in epoch 604, in step 199, in global step 302200, learning rate is 0.00015, taks 7.393800258636475 seconds
2020-03-23 18:11:45,539 - RBF - ERROR - loss 1.2925040935545626, in epoch 604, in step 399, in global step 302400, learning rate is 0.00015, taks 4.922199726104736 seconds
2020-03-23 18:11:47,998 - RBF - INFO - train epoch 605 of total 5000 epoches
2020-03-23 18:11:52,943 - RBF - ERROR - loss 1.2924701678034227, in epoch 605, in step 199, in global step 302700, learning rate is 0.00015, taks 7.404400110244751 seconds
2020-03-23 18:11:57,867 - RBF - ERROR - loss 1.2923308232670656, in epoch 605, in step 399, in global step 302900, learning rate is 0.00015, taks 4.9235999584198 seconds
2020-03-23 18:12:00,305 - RBF - INFO - train epoch 606 of total 5000 epoches
2020-03-23 18:12:05,250 - RBF - ERROR - loss 1.2923396689124067, in epoch 606, in step 199, in global step 303200, learning rate is 0.00015, taks 7.383600234985352 seconds
2020-03-23 18:12:10,209 - RBF - ERROR - loss 1.2923482694993838, in epoch 606, in step 399, in global step 303400, learning rate is 0.00015, taks 4.9579997062683105 seconds
2020-03-23 18:12:12,655 - RBF - INFO - train epoch 607 of total 5000 epoches
2020-03-23 18:12:17,581 - RBF - ERROR - loss 1.2923762723429448, in epoch 607, in step 199, in global step 303700, learning rate is 0.00015, taks 7.371599912643433 seconds
2020-03-23 18:12:22,510 - RBF - ERROR - loss 1.292376408442022, in epoch 607, in step 399, in global step 303900, learning rate is 0.00015, taks 4.928999900817871 seconds
2020-03-23 18:12:24,959 - RBF - INFO - train epoch 608 of total 5000 epoches
2020-03-23 18:12:29,886 - RBF - ERROR - loss 1.2923634838214202, in epoch 608, in step 199, in global step 304200, learning rate is 0.00015, taks 7.3764002323150635 seconds
2020-03-23 18:12:34,853 - RBF - ERROR - loss 1.2923572575590276, in epoch 608, in step 399, in global step 304400, learning rate is 0.00015, taks 4.966399908065796 seconds
2020-03-23 18:12:37,139 - RBF - INFO - train epoch 609 of total 5000 epoches
2020-03-23 18:12:41,760 - RBF - ERROR - loss 1.2924083402260464, in epoch 609, in step 199, in global step 304700, learning rate is 0.00015, taks 6.907800197601318 seconds
2020-03-23 18:12:46,372 - RBF - ERROR - loss 1.2924025918351858, in epoch 609, in step 399, in global step 304900, learning rate is 0.00015, taks 4.611999988555908 seconds
2020-03-23 18:12:48,663 - RBF - INFO - train epoch 610 of total 5000 epoches
2020-03-23 18:12:53,295 - RBF - ERROR - loss 1.292576177251628, in epoch 610, in step 199, in global step 305200, learning rate is 0.00015, taks 6.922599792480469 seconds
2020-03-23 18:12:57,905 - RBF - ERROR - loss 1.2925423476925222, in epoch 610, in step 399, in global step 305400, learning rate is 0.00015, taks 4.609000205993652 seconds
2020-03-23 18:13:00,194 - RBF - INFO - train epoch 611 of total 5000 epoches
2020-03-23 18:13:04,806 - RBF - ERROR - loss 1.2925468350685776, in epoch 611, in step 199, in global step 305700, learning rate is 0.00015, taks 6.900799989700317 seconds
2020-03-23 18:13:09,408 - RBF - ERROR - loss 1.2923706356032738, in epoch 611, in step 399, in global step 305900, learning rate is 0.00015, taks 4.602400064468384 seconds
2020-03-23 18:13:11,714 - RBF - INFO - train epoch 612 of total 5000 epoches
2020-03-23 18:13:16,309 - RBF - ERROR - loss 1.2924324264177578, in epoch 612, in step 199, in global step 306200, learning rate is 0.00015, taks 6.900799989700317 seconds
2020-03-23 18:13:20,904 - RBF - ERROR - loss 1.2924104267380383, in epoch 612, in step 399, in global step 306400, learning rate is 0.00015, taks 4.5950000286102295 seconds
2020-03-23 18:13:23,220 - RBF - INFO - train epoch 613 of total 5000 epoches
2020-03-23 18:13:27,909 - RBF - ERROR - loss 1.2925068541439348, in epoch 613, in step 199, in global step 306700, learning rate is 0.00015, taks 7.004800081253052 seconds
2020-03-23 18:13:32,501 - RBF - ERROR - loss 1.2924513953914583, in epoch 613, in step 399, in global step 306900, learning rate is 0.00015, taks 4.5920000076293945 seconds
2020-03-23 18:13:34,823 - RBF - INFO - train epoch 614 of total 5000 epoches
2020-03-23 18:13:39,449 - RBF - ERROR - loss 1.2924004529131463, in epoch 614, in step 199, in global step 307200, learning rate is 0.00015, taks 6.948599815368652 seconds
2020-03-23 18:13:44,044 - RBF - ERROR - loss 1.2923673398141025, in epoch 614, in step 399, in global step 307400, learning rate is 0.00015, taks 4.5950000286102295 seconds
2020-03-23 18:13:46,357 - RBF - INFO - train epoch 615 of total 5000 epoches
2020-03-23 18:13:50,955 - RBF - ERROR - loss 1.2924476748532894, in epoch 615, in step 199, in global step 307700, learning rate is 0.00015, taks 6.910599946975708 seconds
2020-03-23 18:13:55,582 - RBF - ERROR - loss 1.292410509103169, in epoch 615, in step 399, in global step 307900, learning rate is 0.00015, taks 4.627200126647949 seconds
2020-03-23 18:13:57,883 - RBF - INFO - train epoch 616 of total 5000 epoches
2020-03-23 18:14:02,465 - RBF - ERROR - loss 1.2924182343765374, in epoch 616, in step 199, in global step 308200, learning rate is 0.00015, taks 6.8826000690460205 seconds
2020-03-23 18:14:07,212 - RBF - ERROR - loss 1.292314165771892, in epoch 616, in step 399, in global step 308400, learning rate is 0.00015, taks 4.747200012207031 seconds
2020-03-23 18:14:09,570 - RBF - INFO - train epoch 617 of total 5000 epoches
2020-03-23 18:14:14,094 - RBF - ERROR - loss 1.2924013933474297, in epoch 617, in step 199, in global step 308700, learning rate is 0.00015, taks 6.881999969482422 seconds
2020-03-23 18:14:40,285 - RBF - INFO - now initialize the net with para:
2020-03-23 18:14:40,285 - RBF - INFO - clip
2020-03-23 18:14:40,285 - RBF - INFO - False
2020-03-23 18:14:40,285 - RBF - INFO - -----------------------------
2020-03-23 18:14:40,286 - RBF - INFO - CKPT
2020-03-23 18:14:40,286 - RBF - INFO - ckpt
2020-03-23 18:14:40,286 - RBF - INFO - -----------------------------
2020-03-23 18:14:40,286 - RBF - INFO - BATCHSIZE
2020-03-23 18:14:40,286 - RBF - INFO - 1000
2020-03-23 18:14:40,286 - RBF - INFO - -----------------------------
2020-03-23 18:14:40,286 - RBF - INFO - MAX_ITER
2020-03-23 18:14:40,286 - RBF - INFO - 5000
2020-03-23 18:14:40,286 - RBF - INFO - -----------------------------
2020-03-23 18:14:40,286 - RBF - INFO - STEP_EACH_ITER
2020-03-23 18:14:40,287 - RBF - INFO - 500
2020-03-23 18:14:40,287 - RBF - INFO - -----------------------------
2020-03-23 18:14:40,287 - RBF - INFO - STEP_SHOW
2020-03-23 18:14:40,287 - RBF - INFO - 200
2020-03-23 18:14:40,287 - RBF - INFO - -----------------------------
2020-03-23 18:14:40,287 - RBF - INFO - EPOCH_SAVE
2020-03-23 18:14:40,287 - RBF - INFO - 20
2020-03-23 18:14:40,287 - RBF - INFO - -----------------------------
2020-03-23 18:14:40,287 - RBF - INFO - LEARNING_RATE
2020-03-23 18:14:40,287 - RBF - INFO - 0.00015
2020-03-23 18:14:40,287 - RBF - INFO - -----------------------------
2020-03-23 18:14:40,288 - RBF - INFO - bound_weight
2020-03-23 18:14:40,288 - RBF - INFO - 1
2020-03-23 18:14:40,288 - RBF - INFO - -----------------------------
2020-03-23 18:14:40,288 - RBF - INFO - step_unbound
2020-03-23 18:14:40,288 - RBF - INFO - 5
2020-03-23 18:14:40,288 - RBF - INFO - -----------------------------
2020-03-23 18:14:40,288 - RBF - INFO - decay
2020-03-23 18:14:40,288 - RBF - INFO - False
2020-03-23 18:14:40,288 - RBF - INFO - -----------------------------
2020-03-23 18:14:40,288 - RBF - INFO - test_line
2020-03-23 18:14:40,288 - RBF - INFO - False
2020-03-23 18:14:40,288 - RBF - INFO - -----------------------------
2020-03-23 18:14:40,289 - RBF - INFO - is_plot
2020-03-23 18:14:40,289 - RBF - INFO - True
2020-03-23 18:14:40,289 - RBF - INFO - -----------------------------
2020-03-23 18:14:40,324 - RBF - INFO - openning sess
2020-03-23 18:14:45,140 - RBF - INFO - building net
2020-03-23 18:14:55,008 - RBF - INFO - building opt
2020-03-23 18:14:55,608 - RBF - INFO - init from ckpt 
2020-03-23 18:14:55,609 - RBF - INFO - net initializing
2020-03-23 18:14:55,609 - RBF - INFO - train epoch 0 of total 5000 epoches
2020-03-23 18:15:02,279 - RBF - ERROR - loss 1.2927590128352693, in epoch 0, in step 199, in global step 300200, learning rate is 0.00015, taks 6.669999837875366 seconds
2020-03-23 18:15:04,755 - RBF - ERROR - loss 1.2924691663838856, in epoch 0, in step 399, in global step 300400, learning rate is 0.00015, taks 2.476600170135498 seconds
2020-03-23 18:15:06,000 - RBF - INFO - train epoch 1 of total 5000 epoches
2020-03-23 18:15:08,509 - RBF - ERROR - loss 1.2924586510487575, in epoch 1, in step 199, in global step 300700, learning rate is 0.00015, taks 3.7533998489379883 seconds
2020-03-23 18:15:11,016 - RBF - ERROR - loss 1.2924362802234417, in epoch 1, in step 399, in global step 300900, learning rate is 0.00015, taks 2.5074000358581543 seconds
2020-03-23 18:15:12,272 - RBF - INFO - train epoch 2 of total 5000 epoches
2020-03-23 18:15:14,831 - RBF - ERROR - loss 1.2924301056309264, in epoch 2, in step 199, in global step 301200, learning rate is 0.00015, taks 3.815000057220459 seconds
2020-03-23 18:15:17,675 - RBF - ERROR - loss 1.2928161329462302, in epoch 2, in step 399, in global step 301400, learning rate is 0.00015, taks 2.843599796295166 seconds
2020-03-23 18:15:19,735 - RBF - INFO - train epoch 3 of total 5000 epoches
2020-03-23 18:15:22,800 - RBF - ERROR - loss 1.2924640959054225, in epoch 3, in step 199, in global step 301700, learning rate is 0.00015, taks 5.124600172042847 seconds
2020-03-23 18:15:25,752 - RBF - ERROR - loss 1.292634490766594, in epoch 3, in step 399, in global step 301900, learning rate is 0.00015, taks 2.9516000747680664 seconds
2020-03-23 18:15:27,442 - RBF - INFO - train epoch 4 of total 5000 epoches
2020-03-23 18:15:30,410 - RBF - ERROR - loss 1.2930837997467068, in epoch 4, in step 199, in global step 302200, learning rate is 0.00015, taks 4.657799959182739 seconds
2020-03-23 18:15:33,370 - RBF - ERROR - loss 1.2925040935545626, in epoch 4, in step 399, in global step 302400, learning rate is 0.00015, taks 2.960399866104126 seconds
2020-03-23 18:15:34,850 - RBF - INFO - train epoch 5 of total 5000 epoches
2020-03-23 18:15:37,815 - RBF - ERROR - loss 1.2924701678034227, in epoch 5, in step 199, in global step 302700, learning rate is 0.00015, taks 4.445200204849243 seconds
2020-03-23 18:15:40,787 - RBF - ERROR - loss 1.2923308232670656, in epoch 5, in step 399, in global step 302900, learning rate is 0.00015, taks 2.9718000888824463 seconds
2020-03-23 18:15:42,254 - RBF - INFO - train epoch 6 of total 5000 epoches
2020-03-23 18:15:45,243 - RBF - ERROR - loss 1.2923396689124067, in epoch 6, in step 199, in global step 303200, learning rate is 0.00015, taks 4.454999685287476 seconds
2020-03-23 18:15:48,220 - RBF - ERROR - loss 1.2923482694993838, in epoch 6, in step 399, in global step 303400, learning rate is 0.00015, taks 2.976599931716919 seconds
2020-03-23 18:15:49,701 - RBF - INFO - train epoch 7 of total 5000 epoches
2020-03-23 18:15:52,677 - RBF - ERROR - loss 1.2923762723429448, in epoch 7, in step 199, in global step 303700, learning rate is 0.00015, taks 4.4567999839782715 seconds
2020-03-23 18:15:55,620 - RBF - ERROR - loss 1.292376408442022, in epoch 7, in step 399, in global step 303900, learning rate is 0.00015, taks 2.9434001445770264 seconds
2020-03-23 18:15:57,095 - RBF - INFO - train epoch 8 of total 5000 epoches
2020-03-23 18:16:00,057 - RBF - ERROR - loss 1.2923634838214202, in epoch 8, in step 199, in global step 304200, learning rate is 0.00015, taks 4.4365997314453125 seconds
2020-03-23 18:16:03,042 - RBF - ERROR - loss 1.2923572575590276, in epoch 8, in step 399, in global step 304400, learning rate is 0.00015, taks 2.985599994659424 seconds
2020-03-23 18:16:04,526 - RBF - INFO - train epoch 9 of total 5000 epoches
2020-03-23 18:16:07,494 - RBF - ERROR - loss 1.2924083402260464, in epoch 9, in step 199, in global step 304700, learning rate is 0.00015, taks 4.452200174331665 seconds
2020-03-23 18:16:10,449 - RBF - ERROR - loss 1.2924025918351858, in epoch 9, in step 399, in global step 304900, learning rate is 0.00015, taks 2.9546000957489014 seconds
2020-03-23 18:16:11,958 - RBF - INFO - train epoch 10 of total 5000 epoches
2020-03-23 18:16:14,911 - RBF - ERROR - loss 1.292576177251628, in epoch 10, in step 199, in global step 305200, learning rate is 0.00015, taks 4.461999893188477 seconds
2020-03-23 18:16:17,876 - RBF - ERROR - loss 1.2925423476925222, in epoch 10, in step 399, in global step 305400, learning rate is 0.00015, taks 2.965399980545044 seconds
2020-03-23 18:16:19,347 - RBF - INFO - train epoch 11 of total 5000 epoches
2020-03-23 18:16:22,299 - RBF - ERROR - loss 1.2925468350685776, in epoch 11, in step 199, in global step 305700, learning rate is 0.00015, taks 4.422800064086914 seconds
2020-03-23 18:16:25,254 - RBF - ERROR - loss 1.2923706356032738, in epoch 11, in step 399, in global step 305900, learning rate is 0.00015, taks 2.9546000957489014 seconds
2020-03-23 18:16:26,731 - RBF - INFO - train epoch 12 of total 5000 epoches
2020-03-23 18:16:29,702 - RBF - ERROR - loss 1.2924324264177578, in epoch 12, in step 199, in global step 306200, learning rate is 0.00015, taks 4.4486000537872314 seconds
2020-03-23 18:16:32,677 - RBF - ERROR - loss 1.2924104267380383, in epoch 12, in step 399, in global step 306400, learning rate is 0.00015, taks 2.9731998443603516 seconds
2020-03-23 18:16:34,157 - RBF - INFO - train epoch 13 of total 5000 epoches
2020-03-23 18:16:37,148 - RBF - ERROR - loss 1.2925068541439348, in epoch 13, in step 199, in global step 306700, learning rate is 0.00015, taks 4.4709999561309814 seconds
2020-03-23 18:16:40,110 - RBF - ERROR - loss 1.2924513953914583, in epoch 13, in step 399, in global step 306900, learning rate is 0.00015, taks 2.962399959564209 seconds
2020-03-23 18:16:41,575 - RBF - INFO - train epoch 14 of total 5000 epoches
2020-03-23 18:16:44,536 - RBF - ERROR - loss 1.2924004529131463, in epoch 14, in step 199, in global step 307200, learning rate is 0.00015, taks 4.4262001514434814 seconds
2020-03-23 18:16:47,513 - RBF - ERROR - loss 1.2923673398141025, in epoch 14, in step 399, in global step 307400, learning rate is 0.00015, taks 2.976400136947632 seconds
2020-03-23 18:16:49,002 - RBF - INFO - train epoch 15 of total 5000 epoches
2020-03-23 18:16:51,946 - RBF - ERROR - loss 1.2924476748532894, in epoch 15, in step 199, in global step 307700, learning rate is 0.00015, taks 4.432199954986572 seconds
2020-03-23 18:16:54,906 - RBF - ERROR - loss 1.292410509103169, in epoch 15, in step 399, in global step 307900, learning rate is 0.00015, taks 2.960400104522705 seconds
2020-03-23 18:16:56,393 - RBF - INFO - train epoch 16 of total 5000 epoches
2020-03-23 18:16:59,347 - RBF - ERROR - loss 1.2924182343765374, in epoch 16, in step 199, in global step 308200, learning rate is 0.00015, taks 4.441199779510498 seconds
2020-03-23 18:17:02,303 - RBF - ERROR - loss 1.292314165771892, in epoch 16, in step 399, in global step 308400, learning rate is 0.00015, taks 2.955400228500366 seconds
2020-03-23 18:17:03,797 - RBF - INFO - train epoch 17 of total 5000 epoches
2020-03-23 18:17:06,760 - RBF - ERROR - loss 1.2924013933474297, in epoch 17, in step 199, in global step 308700, learning rate is 0.00015, taks 4.456399917602539 seconds
2020-03-23 18:17:09,696 - RBF - ERROR - loss 1.292493692458236, in epoch 17, in step 399, in global step 308900, learning rate is 0.00015, taks 2.9354002475738525 seconds
2020-03-23 18:17:11,175 - RBF - INFO - train epoch 18 of total 5000 epoches
2020-03-23 18:17:14,162 - RBF - ERROR - loss 1.2924672246035804, in epoch 18, in step 199, in global step 309200, learning rate is 0.00015, taks 4.46619987487793 seconds
2020-03-23 18:17:17,116 - RBF - ERROR - loss 1.2927342527702559, in epoch 18, in step 399, in global step 309400, learning rate is 0.00015, taks 2.9546000957489014 seconds
2020-03-23 18:17:18,593 - RBF - INFO - train epoch 19 of total 5000 epoches
2020-03-23 18:17:21,518 - RBF - ERROR - loss 1.292418172261923, in epoch 19, in step 199, in global step 309700, learning rate is 0.00015, taks 4.400199890136719 seconds
2020-03-23 18:17:24,481 - RBF - ERROR - loss 1.292403741818934, in epoch 19, in step 399, in global step 309900, learning rate is 0.00015, taks 2.963399887084961 seconds
2020-03-23 19:29:33,726 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 19. learning_rate is 0.00015, loss is 1.2926106604039804
2020-03-23 19:29:33,728 - RBF - INFO - train epoch 20 of total 5000 epoches
2020-03-23 19:29:39,337 - RBF - ERROR - loss 1.2925946191244722, in epoch 20, in step 199, in global step 310200, learning rate is 0.00015, taks 4334.855801820755 seconds
2020-03-23 19:29:42,569 - RBF - ERROR - loss 1.2925031532139253, in epoch 20, in step 399, in global step 310400, learning rate is 0.00015, taks 3.232599973678589 seconds
2020-03-23 19:29:44,043 - RBF - INFO - train epoch 21 of total 5000 epoches
2020-03-23 19:29:47,020 - RBF - ERROR - loss 1.2923785461485906, in epoch 21, in step 199, in global step 310700, learning rate is 0.00015, taks 4.450200080871582 seconds
2020-03-23 19:29:50,047 - RBF - ERROR - loss 1.2924930863310877, in epoch 21, in step 399, in global step 310900, learning rate is 0.00015, taks 3.027400016784668 seconds
2020-03-23 19:29:51,353 - RBF - INFO - train epoch 22 of total 5000 epoches
2020-03-23 19:29:54,136 - RBF - ERROR - loss 1.2926483170109557, in epoch 22, in step 199, in global step 311200, learning rate is 0.00015, taks 4.0889997482299805 seconds
2020-03-23 19:29:56,795 - RBF - ERROR - loss 1.2928097134689802, in epoch 22, in step 399, in global step 311400, learning rate is 0.00015, taks 2.6592001914978027 seconds
2020-03-23 19:29:58,044 - RBF - INFO - train epoch 23 of total 5000 epoches
2020-03-23 19:30:00,664 - RBF - ERROR - loss 1.292318898968444, in epoch 23, in step 199, in global step 311700, learning rate is 0.00015, taks 3.868799924850464 seconds
2020-03-23 19:30:03,277 - RBF - ERROR - loss 1.2923222383100001, in epoch 23, in step 399, in global step 311900, learning rate is 0.00015, taks 2.6133999824523926 seconds
2020-03-23 19:30:04,710 - RBF - INFO - train epoch 24 of total 5000 epoches
2020-03-23 19:30:07,709 - RBF - ERROR - loss 1.2924921115635388, in epoch 24, in step 199, in global step 312200, learning rate is 0.00015, taks 4.431800127029419 seconds
2020-03-23 19:30:10,344 - RBF - ERROR - loss 1.292488723913013, in epoch 24, in step 399, in global step 312400, learning rate is 0.00015, taks 2.6338000297546387 seconds
2020-03-23 19:30:11,639 - RBF - INFO - train epoch 25 of total 5000 epoches
2020-03-23 19:30:14,319 - RBF - ERROR - loss 1.2926908392279692, in epoch 25, in step 199, in global step 312700, learning rate is 0.00015, taks 3.9749999046325684 seconds
2020-03-23 19:30:18,118 - RBF - ERROR - loss 1.2923129676521175, in epoch 25, in step 399, in global step 312900, learning rate is 0.00015, taks 3.7990000247955322 seconds
2020-03-23 19:30:19,733 - RBF - INFO - train epoch 26 of total 5000 epoches
2020-03-23 19:30:23,152 - RBF - ERROR - loss 1.2925145019270594, in epoch 26, in step 199, in global step 313200, learning rate is 0.00015, taks 5.033999919891357 seconds
2020-03-23 19:30:26,047 - RBF - ERROR - loss 1.2923744704183209, in epoch 26, in step 399, in global step 313400, learning rate is 0.00015, taks 2.8950002193450928 seconds
2020-03-23 19:30:27,310 - RBF - INFO - train epoch 27 of total 5000 epoches
2020-03-23 19:30:29,897 - RBF - ERROR - loss 1.29236414369458, in epoch 27, in step 199, in global step 313700, learning rate is 0.00015, taks 3.8499999046325684 seconds
2020-03-23 19:30:33,424 - RBF - ERROR - loss 1.292420928606401, in epoch 27, in step 399, in global step 313900, learning rate is 0.00015, taks 3.5269999504089355 seconds
2020-03-23 19:30:34,749 - RBF - INFO - train epoch 28 of total 5000 epoches
2020-03-23 19:30:37,228 - RBF - ERROR - loss 1.292382883406665, in epoch 28, in step 199, in global step 314200, learning rate is 0.00015, taks 3.803999900817871 seconds
2020-03-23 19:30:39,681 - RBF - ERROR - loss 1.292456352545143, in epoch 28, in step 399, in global step 314400, learning rate is 0.00015, taks 2.4526002407073975 seconds
2020-03-23 19:30:41,194 - RBF - INFO - train epoch 29 of total 5000 epoches
2020-03-23 19:30:43,721 - RBF - ERROR - loss 1.292488164033252, in epoch 29, in step 199, in global step 314700, learning rate is 0.00015, taks 4.039999961853027 seconds
2020-03-23 19:30:46,490 - RBF - ERROR - loss 1.2923627065327619, in epoch 29, in step 399, in global step 314900, learning rate is 0.00015, taks 2.7689998149871826 seconds
2020-03-23 19:30:47,808 - RBF - INFO - train epoch 30 of total 5000 epoches
2020-03-23 19:30:50,459 - RBF - ERROR - loss 1.2923314743960463, in epoch 30, in step 199, in global step 315200, learning rate is 0.00015, taks 3.9680001735687256 seconds
2020-03-23 19:30:53,266 - RBF - ERROR - loss 1.292295292012982, in epoch 30, in step 399, in global step 315400, learning rate is 0.00015, taks 2.805999755859375 seconds
2020-03-23 19:30:54,594 - RBF - INFO - train epoch 31 of total 5000 epoches
2020-03-23 19:30:57,117 - RBF - ERROR - loss 1.2925470851951113, in epoch 31, in step 199, in global step 315700, learning rate is 0.00015, taks 3.8499999046325684 seconds
2020-03-23 19:30:59,615 - RBF - ERROR - loss 1.2923140224535181, in epoch 31, in step 399, in global step 315900, learning rate is 0.00015, taks 2.498000144958496 seconds
2020-03-23 19:31:00,893 - RBF - INFO - train epoch 32 of total 5000 epoches
2020-03-23 19:31:03,500 - RBF - ERROR - loss 1.2923430067405768, in epoch 32, in step 199, in global step 316200, learning rate is 0.00015, taks 3.88539981842041 seconds
2020-03-23 19:31:06,038 - RBF - ERROR - loss 1.2923397117383453, in epoch 32, in step 399, in global step 316400, learning rate is 0.00015, taks 2.5380001068115234 seconds
2020-03-23 19:31:07,287 - RBF - INFO - train epoch 33 of total 5000 epoches
2020-03-23 19:31:09,758 - RBF - ERROR - loss 1.292382236621095, in epoch 33, in step 199, in global step 316700, learning rate is 0.00015, taks 3.7202000617980957 seconds
2020-03-23 19:31:12,251 - RBF - ERROR - loss 1.2923366801978258, in epoch 33, in step 399, in global step 316900, learning rate is 0.00015, taks 2.491999864578247 seconds
2020-03-23 19:31:13,528 - RBF - INFO - train epoch 34 of total 5000 epoches
2020-03-23 19:31:16,073 - RBF - ERROR - loss 1.2923810354193452, in epoch 34, in step 199, in global step 317200, learning rate is 0.00015, taks 3.82200026512146 seconds
2020-03-23 19:31:19,062 - RBF - ERROR - loss 1.2923897792792027, in epoch 34, in step 399, in global step 317400, learning rate is 0.00015, taks 2.988999843597412 seconds
2020-03-23 19:31:20,491 - RBF - INFO - train epoch 35 of total 5000 epoches
2020-03-23 19:31:23,503 - RBF - ERROR - loss 1.2923972941074577, in epoch 35, in step 199, in global step 317700, learning rate is 0.00015, taks 4.440999984741211 seconds
2020-03-23 19:31:27,008 - RBF - ERROR - loss 1.2924241741802631, in epoch 35, in step 399, in global step 317900, learning rate is 0.00015, taks 3.505000114440918 seconds
2020-03-23 19:31:28,455 - RBF - INFO - train epoch 36 of total 5000 epoches
2020-03-23 19:31:32,573 - RBF - ERROR - loss 1.2926043503777638, in epoch 36, in step 199, in global step 318200, learning rate is 0.00015, taks 5.565000057220459 seconds
2020-03-23 19:31:36,213 - RBF - ERROR - loss 1.2923474595768913, in epoch 36, in step 399, in global step 318400, learning rate is 0.00015, taks 3.6395998001098633 seconds
2020-03-23 19:31:38,118 - RBF - INFO - train epoch 37 of total 5000 epoches
2020-03-23 19:31:41,007 - RBF - ERROR - loss 1.2928113151890857, in epoch 37, in step 199, in global step 318700, learning rate is 0.00015, taks 4.794600248336792 seconds
2020-03-23 19:31:44,092 - RBF - ERROR - loss 1.29238757484085, in epoch 37, in step 399, in global step 318900, learning rate is 0.00015, taks 3.084399700164795 seconds
2020-03-23 19:31:45,595 - RBF - INFO - train epoch 38 of total 5000 epoches
2020-03-23 19:31:48,643 - RBF - ERROR - loss 1.2923485410961173, in epoch 38, in step 199, in global step 319200, learning rate is 0.00015, taks 4.551000118255615 seconds
2020-03-23 19:31:51,763 - RBF - ERROR - loss 1.2925541665566105, in epoch 38, in step 399, in global step 319400, learning rate is 0.00015, taks 3.120000123977661 seconds
2020-03-23 19:31:53,321 - RBF - INFO - train epoch 39 of total 5000 epoches
2020-03-23 19:31:56,505 - RBF - ERROR - loss 1.2923697144843076, in epoch 39, in step 199, in global step 319700, learning rate is 0.00015, taks 4.741999864578247 seconds
2020-03-23 19:32:00,075 - RBF - ERROR - loss 1.2925558630320908, in epoch 39, in step 399, in global step 319900, learning rate is 0.00015, taks 3.569999933242798 seconds
2020-03-23 19:32:08,142 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 39. learning_rate is 0.00015, loss is 1.2924175272826772
2020-03-23 19:32:08,144 - RBF - INFO - train epoch 40 of total 5000 epoches
2020-03-23 19:32:11,386 - RBF - ERROR - loss 1.2923977256785133, in epoch 40, in step 199, in global step 320200, learning rate is 0.00015, taks 11.311200141906738 seconds
2020-03-23 19:32:14,381 - RBF - ERROR - loss 1.292475720793617, in epoch 40, in step 399, in global step 320400, learning rate is 0.00015, taks 2.994000196456909 seconds
2020-03-23 19:32:15,884 - RBF - INFO - train epoch 41 of total 5000 epoches
2020-03-23 19:32:18,873 - RBF - ERROR - loss 1.2926668947611648, in epoch 41, in step 199, in global step 320700, learning rate is 0.00015, taks 4.491999864578247 seconds
2020-03-23 19:32:21,901 - RBF - ERROR - loss 1.2923402464338796, in epoch 41, in step 399, in global step 320900, learning rate is 0.00015, taks 3.0280001163482666 seconds
2020-03-23 19:32:23,437 - RBF - INFO - train epoch 42 of total 5000 epoches
2020-03-23 19:32:26,489 - RBF - ERROR - loss 1.2924912894573146, in epoch 42, in step 199, in global step 321200, learning rate is 0.00015, taks 4.5879998207092285 seconds
2020-03-23 19:32:29,106 - RBF - ERROR - loss 1.2924559234366075, in epoch 42, in step 399, in global step 321400, learning rate is 0.00015, taks 2.617000102996826 seconds
2020-03-23 19:32:30,340 - RBF - INFO - train epoch 43 of total 5000 epoches
2020-03-23 19:32:32,824 - RBF - ERROR - loss 1.2924241337116114, in epoch 43, in step 199, in global step 321700, learning rate is 0.00015, taks 3.7179996967315674 seconds
2020-03-23 19:32:35,296 - RBF - ERROR - loss 1.2925483227615757, in epoch 43, in step 399, in global step 321900, learning rate is 0.00015, taks 2.4718000888824463 seconds
2020-03-23 19:32:36,533 - RBF - INFO - train epoch 44 of total 5000 epoches
2020-03-23 19:32:39,016 - RBF - ERROR - loss 1.2924967629352246, in epoch 44, in step 199, in global step 322200, learning rate is 0.00015, taks 3.7198002338409424 seconds
2020-03-23 19:32:41,486 - RBF - ERROR - loss 1.2923701099092981, in epoch 44, in step 399, in global step 322400, learning rate is 0.00015, taks 2.470599889755249 seconds
2020-03-23 19:32:42,723 - RBF - INFO - train epoch 45 of total 5000 epoches
2020-03-23 19:32:45,199 - RBF - ERROR - loss 1.2924320618505893, in epoch 45, in step 199, in global step 322700, learning rate is 0.00015, taks 3.7129998207092285 seconds
2020-03-23 19:32:47,725 - RBF - ERROR - loss 1.29247721183086, in epoch 45, in step 399, in global step 322900, learning rate is 0.00015, taks 2.5260002613067627 seconds
2020-03-23 19:32:48,966 - RBF - INFO - train epoch 46 of total 5000 epoches
2020-03-23 19:32:51,512 - RBF - ERROR - loss 1.2923661671793913, in epoch 46, in step 199, in global step 323200, learning rate is 0.00015, taks 3.7869999408721924 seconds
2020-03-23 19:32:54,497 - RBF - ERROR - loss 1.2923987822925895, in epoch 46, in step 399, in global step 323400, learning rate is 0.00015, taks 2.984999895095825 seconds
2020-03-23 19:32:56,125 - RBF - INFO - train epoch 47 of total 5000 epoches
2020-03-23 19:32:58,971 - RBF - ERROR - loss 1.2924837056682046, in epoch 47, in step 199, in global step 323700, learning rate is 0.00015, taks 4.473999977111816 seconds
2020-03-23 19:33:01,560 - RBF - ERROR - loss 1.2923146081190087, in epoch 47, in step 399, in global step 323900, learning rate is 0.00015, taks 2.5890002250671387 seconds
2020-03-23 19:33:02,822 - RBF - INFO - train epoch 48 of total 5000 epoches
2020-03-23 19:33:05,770 - RBF - ERROR - loss 1.2931200576784883, in epoch 48, in step 199, in global step 324200, learning rate is 0.00015, taks 4.2088000774383545 seconds
2020-03-23 19:33:09,071 - RBF - ERROR - loss 1.2923623445893497, in epoch 48, in step 399, in global step 324400, learning rate is 0.00015, taks 3.3013999462127686 seconds
2020-03-23 19:33:10,668 - RBF - INFO - train epoch 49 of total 5000 epoches
2020-03-23 19:33:13,625 - RBF - ERROR - loss 1.292376326391296, in epoch 49, in step 199, in global step 324700, learning rate is 0.00015, taks 4.553999900817871 seconds
2020-03-23 19:33:16,233 - RBF - ERROR - loss 1.2923757985891988, in epoch 49, in step 399, in global step 324900, learning rate is 0.00015, taks 2.6080000400543213 seconds
2020-03-23 19:33:17,536 - RBF - INFO - train epoch 50 of total 5000 epoches
2020-03-23 19:33:20,320 - RBF - ERROR - loss 1.292545772027081, in epoch 50, in step 199, in global step 325200, learning rate is 0.00015, taks 4.086000204086304 seconds
2020-03-23 19:33:22,985 - RBF - ERROR - loss 1.2923411284001476, in epoch 50, in step 399, in global step 325400, learning rate is 0.00015, taks 2.6649997234344482 seconds
2020-03-23 19:33:24,355 - RBF - INFO - train epoch 51 of total 5000 epoches
2020-03-23 19:33:26,986 - RBF - ERROR - loss 1.2923349334719991, in epoch 51, in step 199, in global step 325700, learning rate is 0.00015, taks 4.000999927520752 seconds
2020-03-23 19:33:29,470 - RBF - ERROR - loss 1.2923215057402087, in epoch 51, in step 399, in global step 325900, learning rate is 0.00015, taks 2.483400344848633 seconds
2020-03-23 19:33:30,748 - RBF - INFO - train epoch 52 of total 5000 epoches
2020-03-23 19:33:33,227 - RBF - ERROR - loss 1.2923352510654116, in epoch 52, in step 199, in global step 326200, learning rate is 0.00015, taks 3.7567999362945557 seconds
2020-03-23 19:33:35,810 - RBF - ERROR - loss 1.2925839921290578, in epoch 52, in step 399, in global step 326400, learning rate is 0.00015, taks 2.5837998390197754 seconds
2020-03-23 19:33:37,147 - RBF - INFO - train epoch 53 of total 5000 epoches
2020-03-23 19:33:40,663 - RBF - ERROR - loss 1.2923435630480284, in epoch 53, in step 199, in global step 326700, learning rate is 0.00015, taks 4.853000164031982 seconds
2020-03-23 19:33:43,576 - RBF - ERROR - loss 1.2923749763139234, in epoch 53, in step 399, in global step 326900, learning rate is 0.00015, taks 2.9129998683929443 seconds
2020-03-23 19:33:44,955 - RBF - INFO - train epoch 54 of total 5000 epoches
2020-03-23 19:33:47,961 - RBF - ERROR - loss 1.292423656090798, in epoch 54, in step 199, in global step 327200, learning rate is 0.00015, taks 4.383800268173218 seconds
2020-03-23 19:33:51,157 - RBF - ERROR - loss 1.2923287480973886, in epoch 54, in step 399, in global step 327400, learning rate is 0.00015, taks 3.194999933242798 seconds
2020-03-23 19:33:52,663 - RBF - INFO - train epoch 55 of total 5000 epoches
2020-03-23 19:33:55,583 - RBF - ERROR - loss 1.2923207203465827, in epoch 55, in step 199, in global step 327700, learning rate is 0.00015, taks 4.425999879837036 seconds
2020-03-23 19:33:58,652 - RBF - ERROR - loss 1.292346063687206, in epoch 55, in step 399, in global step 327900, learning rate is 0.00015, taks 3.068000078201294 seconds
2020-03-23 19:33:59,966 - RBF - INFO - train epoch 56 of total 5000 epoches
2020-03-23 19:34:03,868 - RBF - ERROR - loss 1.2924755759497828, in epoch 56, in step 199, in global step 328200, learning rate is 0.00015, taks 5.216000080108643 seconds
2020-03-23 19:34:07,921 - RBF - ERROR - loss 1.2924122029790228, in epoch 56, in step 399, in global step 328400, learning rate is 0.00015, taks 4.05299973487854 seconds
2020-03-23 19:34:09,554 - RBF - INFO - train epoch 57 of total 5000 epoches
2020-03-23 19:34:12,166 - RBF - ERROR - loss 1.2923340501426774, in epoch 57, in step 199, in global step 328700, learning rate is 0.00015, taks 4.244600057601929 seconds
2020-03-23 19:34:14,699 - RBF - ERROR - loss 1.2922780312371924, in epoch 57, in step 399, in global step 328900, learning rate is 0.00015, taks 2.5329999923706055 seconds
2020-03-23 19:34:16,200 - RBF - INFO - train epoch 58 of total 5000 epoches
2020-03-23 19:34:18,723 - RBF - ERROR - loss 1.292412893617739, in epoch 58, in step 199, in global step 329200, learning rate is 0.00015, taks 4.023999929428101 seconds
2020-03-23 19:34:21,238 - RBF - ERROR - loss 1.2923016899902349, in epoch 58, in step 399, in global step 329400, learning rate is 0.00015, taks 2.515000104904175 seconds
2020-03-23 19:34:22,852 - RBF - INFO - train epoch 59 of total 5000 epoches
2020-03-23 19:34:25,482 - RBF - ERROR - loss 1.2923850195457374, in epoch 59, in step 199, in global step 329700, learning rate is 0.00015, taks 4.243000030517578 seconds
2020-03-23 19:34:27,982 - RBF - ERROR - loss 1.2927184048908695, in epoch 59, in step 399, in global step 329900, learning rate is 0.00015, taks 2.499799966812134 seconds
2020-03-23 19:34:35,182 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 59. learning_rate is 0.00015, loss is 1.2922826719400777
2020-03-23 19:34:35,183 - RBF - INFO - train epoch 60 of total 5000 epoches
2020-03-23 19:34:41,608 - RBF - ERROR - loss 1.2924295655129208, in epoch 60, in step 199, in global step 330200, learning rate is 0.00015, taks 13.626399993896484 seconds
2020-03-23 21:11:30,583 - RBF - INFO - now initialize the net with para:
2020-03-23 21:11:30,584 - RBF - INFO - clip
2020-03-23 21:11:30,584 - RBF - INFO - 0.05
2020-03-23 21:11:30,584 - RBF - INFO - -----------------------------
2020-03-23 21:11:30,584 - RBF - INFO - CKPT
2020-03-23 21:11:30,584 - RBF - INFO - ckpt
2020-03-23 21:11:30,584 - RBF - INFO - -----------------------------
2020-03-23 21:11:30,585 - RBF - INFO - BATCHSIZE
2020-03-23 21:11:30,585 - RBF - INFO - 1000
2020-03-23 21:11:30,585 - RBF - INFO - -----------------------------
2020-03-23 21:11:30,585 - RBF - INFO - MAX_ITER
2020-03-23 21:11:30,585 - RBF - INFO - 5000
2020-03-23 21:11:30,585 - RBF - INFO - -----------------------------
2020-03-23 21:11:30,585 - RBF - INFO - STEP_EACH_ITER
2020-03-23 21:11:30,586 - RBF - INFO - 500
2020-03-23 21:11:30,586 - RBF - INFO - -----------------------------
2020-03-23 21:11:30,586 - RBF - INFO - STEP_SHOW
2020-03-23 21:11:30,586 - RBF - INFO - 200
2020-03-23 21:11:30,586 - RBF - INFO - -----------------------------
2020-03-23 21:11:30,586 - RBF - INFO - EPOCH_SAVE
2020-03-23 21:11:30,586 - RBF - INFO - 20
2020-03-23 21:11:30,586 - RBF - INFO - -----------------------------
2020-03-23 21:11:30,587 - RBF - INFO - LEARNING_RATE
2020-03-23 21:11:30,587 - RBF - INFO - 0.00015
2020-03-23 21:11:30,587 - RBF - INFO - -----------------------------
2020-03-23 21:11:30,587 - RBF - INFO - bound_weight
2020-03-23 21:11:30,588 - RBF - INFO - 1
2020-03-23 21:11:30,588 - RBF - INFO - -----------------------------
2020-03-23 21:11:30,588 - RBF - INFO - step_unbound
2020-03-23 21:11:30,588 - RBF - INFO - 5
2020-03-23 21:11:30,588 - RBF - INFO - -----------------------------
2020-03-23 21:11:30,588 - RBF - INFO - decay
2020-03-23 21:11:30,588 - RBF - INFO - False
2020-03-23 21:11:30,588 - RBF - INFO - -----------------------------
2020-03-23 21:11:30,589 - RBF - INFO - test_line
2020-03-23 21:11:30,589 - RBF - INFO - False
2020-03-23 21:11:30,589 - RBF - INFO - -----------------------------
2020-03-23 21:11:30,589 - RBF - INFO - is_plot
2020-03-23 21:11:30,589 - RBF - INFO - True
2020-03-23 21:11:30,589 - RBF - INFO - -----------------------------
2020-03-23 21:11:30,643 - RBF - INFO - openning sess
2020-03-23 21:11:41,109 - RBF - INFO - building net
2020-03-23 21:11:58,751 - RBF - INFO - building opt
2020-03-23 21:12:00,376 - RBF - INFO - net initializing
2020-03-23 21:12:00,376 - RBF - INFO - train epoch 0 of total 5000 epoches
2020-03-23 21:12:12,991 - RBF - ERROR - ,0
2020-03-23 21:12:37,130 - RBF - INFO - now initialize the net with para:
2020-03-23 21:12:37,131 - RBF - INFO - clip
2020-03-23 21:12:37,131 - RBF - INFO - 0.05
2020-03-23 21:12:37,131 - RBF - INFO - -----------------------------
2020-03-23 21:12:37,131 - RBF - INFO - CKPT
2020-03-23 21:12:37,131 - RBF - INFO - ckpt
2020-03-23 21:12:37,131 - RBF - INFO - -----------------------------
2020-03-23 21:12:37,131 - RBF - INFO - BATCHSIZE
2020-03-23 21:12:37,131 - RBF - INFO - 1000
2020-03-23 21:12:37,131 - RBF - INFO - -----------------------------
2020-03-23 21:12:37,131 - RBF - INFO - MAX_ITER
2020-03-23 21:12:37,131 - RBF - INFO - 5000
2020-03-23 21:12:37,131 - RBF - INFO - -----------------------------
2020-03-23 21:12:37,131 - RBF - INFO - STEP_EACH_ITER
2020-03-23 21:12:37,132 - RBF - INFO - 500
2020-03-23 21:12:37,132 - RBF - INFO - -----------------------------
2020-03-23 21:12:37,132 - RBF - INFO - STEP_SHOW
2020-03-23 21:12:37,132 - RBF - INFO - 200
2020-03-23 21:12:37,132 - RBF - INFO - -----------------------------
2020-03-23 21:12:37,132 - RBF - INFO - EPOCH_SAVE
2020-03-23 21:12:37,132 - RBF - INFO - 20
2020-03-23 21:12:37,132 - RBF - INFO - -----------------------------
2020-03-23 21:12:37,132 - RBF - INFO - LEARNING_RATE
2020-03-23 21:12:37,132 - RBF - INFO - 1e-05
2020-03-23 21:12:37,132 - RBF - INFO - -----------------------------
2020-03-23 21:12:37,132 - RBF - INFO - bound_weight
2020-03-23 21:12:37,132 - RBF - INFO - 1
2020-03-23 21:12:37,133 - RBF - INFO - -----------------------------
2020-03-23 21:12:37,133 - RBF - INFO - step_unbound
2020-03-23 21:12:37,133 - RBF - INFO - 5
2020-03-23 21:12:37,133 - RBF - INFO - -----------------------------
2020-03-23 21:12:37,133 - RBF - INFO - decay
2020-03-23 21:12:37,133 - RBF - INFO - False
2020-03-23 21:12:37,133 - RBF - INFO - -----------------------------
2020-03-23 21:12:37,133 - RBF - INFO - test_line
2020-03-23 21:12:37,133 - RBF - INFO - False
2020-03-23 21:12:37,133 - RBF - INFO - -----------------------------
2020-03-23 21:12:37,133 - RBF - INFO - is_plot
2020-03-23 21:12:37,133 - RBF - INFO - True
2020-03-23 21:12:37,133 - RBF - INFO - -----------------------------
2020-03-23 21:12:37,158 - RBF - INFO - openning sess
2020-03-23 21:12:43,135 - RBF - INFO - building net
2020-03-23 21:12:58,147 - RBF - INFO - building opt
2020-03-23 21:12:59,583 - RBF - INFO - net initializing
2020-03-23 21:12:59,583 - RBF - INFO - train epoch 0 of total 5000 epoches
2020-03-23 21:13:08,157 - RBF - ERROR - ,0
2020-03-23 21:13:49,042 - RBF - INFO - now initialize the net with para:
2020-03-23 21:13:49,042 - RBF - INFO - clip
2020-03-23 21:13:49,042 - RBF - INFO - 0.05
2020-03-23 21:13:49,042 - RBF - INFO - -----------------------------
2020-03-23 21:13:49,042 - RBF - INFO - CKPT
2020-03-23 21:13:49,042 - RBF - INFO - ckpt
2020-03-23 21:13:49,042 - RBF - INFO - -----------------------------
2020-03-23 21:13:49,042 - RBF - INFO - BATCHSIZE
2020-03-23 21:13:49,043 - RBF - INFO - 1000
2020-03-23 21:13:49,043 - RBF - INFO - -----------------------------
2020-03-23 21:13:49,043 - RBF - INFO - MAX_ITER
2020-03-23 21:13:49,043 - RBF - INFO - 5000
2020-03-23 21:13:49,043 - RBF - INFO - -----------------------------
2020-03-23 21:13:49,043 - RBF - INFO - STEP_EACH_ITER
2020-03-23 21:13:49,043 - RBF - INFO - 500
2020-03-23 21:13:49,043 - RBF - INFO - -----------------------------
2020-03-23 21:13:49,043 - RBF - INFO - STEP_SHOW
2020-03-23 21:13:49,043 - RBF - INFO - 200
2020-03-23 21:13:49,043 - RBF - INFO - -----------------------------
2020-03-23 21:13:49,043 - RBF - INFO - EPOCH_SAVE
2020-03-23 21:13:49,043 - RBF - INFO - 20
2020-03-23 21:13:49,043 - RBF - INFO - -----------------------------
2020-03-23 21:13:49,044 - RBF - INFO - LEARNING_RATE
2020-03-23 21:13:49,044 - RBF - INFO - 1e-05
2020-03-23 21:13:49,044 - RBF - INFO - -----------------------------
2020-03-23 21:13:49,044 - RBF - INFO - bound_weight
2020-03-23 21:13:49,044 - RBF - INFO - 1
2020-03-23 21:13:49,044 - RBF - INFO - -----------------------------
2020-03-23 21:13:49,044 - RBF - INFO - step_unbound
2020-03-23 21:13:49,044 - RBF - INFO - 5
2020-03-23 21:13:49,044 - RBF - INFO - -----------------------------
2020-03-23 21:13:49,044 - RBF - INFO - decay
2020-03-23 21:13:49,044 - RBF - INFO - False
2020-03-23 21:13:49,044 - RBF - INFO - -----------------------------
2020-03-23 21:13:49,044 - RBF - INFO - test_line
2020-03-23 21:13:49,044 - RBF - INFO - False
2020-03-23 21:13:49,045 - RBF - INFO - -----------------------------
2020-03-23 21:13:49,045 - RBF - INFO - is_plot
2020-03-23 21:13:49,045 - RBF - INFO - True
2020-03-23 21:13:49,045 - RBF - INFO - -----------------------------
2020-03-23 21:13:49,073 - RBF - INFO - openning sess
2020-03-23 21:13:52,809 - RBF - INFO - building net
2020-03-23 21:14:00,375 - RBF - INFO - building opt
2020-03-23 21:14:01,085 - RBF - INFO - net initializing
2020-03-23 21:14:01,085 - RBF - INFO - train epoch 0 of total 5000 epoches
2020-03-23 21:14:05,282 - RBF - ERROR - ,0
2020-03-23 21:14:39,483 - RBF - INFO - now initialize the net with para:
2020-03-23 21:14:39,483 - RBF - INFO - clip
2020-03-23 21:14:39,483 - RBF - INFO - False
2020-03-23 21:14:39,483 - RBF - INFO - -----------------------------
2020-03-23 21:14:39,483 - RBF - INFO - CKPT
2020-03-23 21:14:39,483 - RBF - INFO - ckpt
2020-03-23 21:14:39,483 - RBF - INFO - -----------------------------
2020-03-23 21:14:39,483 - RBF - INFO - BATCHSIZE
2020-03-23 21:14:39,484 - RBF - INFO - 1000
2020-03-23 21:14:39,484 - RBF - INFO - -----------------------------
2020-03-23 21:14:39,484 - RBF - INFO - MAX_ITER
2020-03-23 21:14:39,484 - RBF - INFO - 5000
2020-03-23 21:14:39,484 - RBF - INFO - -----------------------------
2020-03-23 21:14:39,484 - RBF - INFO - STEP_EACH_ITER
2020-03-23 21:14:39,484 - RBF - INFO - 500
2020-03-23 21:14:39,484 - RBF - INFO - -----------------------------
2020-03-23 21:14:39,484 - RBF - INFO - STEP_SHOW
2020-03-23 21:14:39,484 - RBF - INFO - 200
2020-03-23 21:14:39,484 - RBF - INFO - -----------------------------
2020-03-23 21:14:39,484 - RBF - INFO - EPOCH_SAVE
2020-03-23 21:14:39,484 - RBF - INFO - 20
2020-03-23 21:14:39,484 - RBF - INFO - -----------------------------
2020-03-23 21:14:39,485 - RBF - INFO - LEARNING_RATE
2020-03-23 21:14:39,485 - RBF - INFO - 1e-05
2020-03-23 21:14:39,485 - RBF - INFO - -----------------------------
2020-03-23 21:14:39,485 - RBF - INFO - bound_weight
2020-03-23 21:14:39,485 - RBF - INFO - 1
2020-03-23 21:14:39,485 - RBF - INFO - -----------------------------
2020-03-23 21:14:39,485 - RBF - INFO - step_unbound
2020-03-23 21:14:39,485 - RBF - INFO - 5
2020-03-23 21:14:39,485 - RBF - INFO - -----------------------------
2020-03-23 21:14:39,485 - RBF - INFO - decay
2020-03-23 21:14:39,485 - RBF - INFO - False
2020-03-23 21:14:39,485 - RBF - INFO - -----------------------------
2020-03-23 21:14:39,485 - RBF - INFO - test_line
2020-03-23 21:14:39,485 - RBF - INFO - False
2020-03-23 21:14:39,486 - RBF - INFO - -----------------------------
2020-03-23 21:14:39,486 - RBF - INFO - is_plot
2020-03-23 21:14:39,486 - RBF - INFO - True
2020-03-23 21:14:39,486 - RBF - INFO - -----------------------------
2020-03-23 21:14:39,517 - RBF - INFO - openning sess
2020-03-23 21:14:43,385 - RBF - INFO - building net
2020-03-23 21:14:51,761 - RBF - INFO - building opt
2020-03-23 21:14:52,475 - RBF - INFO - net initializing
2020-03-23 21:14:52,476 - RBF - INFO - train epoch 0 of total 5000 epoches
2020-03-23 21:14:56,537 - RBF - ERROR - ,0
2020-03-23 21:16:09,886 - RBF - INFO - now initialize the net with para:
2020-03-23 21:16:09,886 - RBF - INFO - clip
2020-03-23 21:16:09,887 - RBF - INFO - False
2020-03-23 21:16:09,887 - RBF - INFO - -----------------------------
2020-03-23 21:16:09,887 - RBF - INFO - CKPT
2020-03-23 21:16:09,887 - RBF - INFO - ckpt
2020-03-23 21:16:09,887 - RBF - INFO - -----------------------------
2020-03-23 21:16:09,887 - RBF - INFO - BATCHSIZE
2020-03-23 21:16:09,887 - RBF - INFO - 1000
2020-03-23 21:16:09,887 - RBF - INFO - -----------------------------
2020-03-23 21:16:09,887 - RBF - INFO - MAX_ITER
2020-03-23 21:16:09,888 - RBF - INFO - 5000
2020-03-23 21:16:09,888 - RBF - INFO - -----------------------------
2020-03-23 21:16:09,888 - RBF - INFO - STEP_EACH_ITER
2020-03-23 21:16:09,888 - RBF - INFO - 500
2020-03-23 21:16:09,888 - RBF - INFO - -----------------------------
2020-03-23 21:16:09,888 - RBF - INFO - STEP_SHOW
2020-03-23 21:16:09,888 - RBF - INFO - 200
2020-03-23 21:16:09,888 - RBF - INFO - -----------------------------
2020-03-23 21:16:09,888 - RBF - INFO - EPOCH_SAVE
2020-03-23 21:16:09,888 - RBF - INFO - 20
2020-03-23 21:16:09,888 - RBF - INFO - -----------------------------
2020-03-23 21:16:09,889 - RBF - INFO - LEARNING_RATE
2020-03-23 21:16:09,889 - RBF - INFO - 1e-05
2020-03-23 21:16:09,889 - RBF - INFO - -----------------------------
2020-03-23 21:16:09,889 - RBF - INFO - bound_weight
2020-03-23 21:16:09,889 - RBF - INFO - 1
2020-03-23 21:16:09,889 - RBF - INFO - -----------------------------
2020-03-23 21:16:09,889 - RBF - INFO - step_unbound
2020-03-23 21:16:09,889 - RBF - INFO - 5
2020-03-23 21:16:09,889 - RBF - INFO - -----------------------------
2020-03-23 21:16:09,889 - RBF - INFO - decay
2020-03-23 21:16:09,889 - RBF - INFO - False
2020-03-23 21:16:09,890 - RBF - INFO - -----------------------------
2020-03-23 21:16:09,890 - RBF - INFO - test_line
2020-03-23 21:16:09,890 - RBF - INFO - False
2020-03-23 21:16:09,890 - RBF - INFO - -----------------------------
2020-03-23 21:16:09,890 - RBF - INFO - is_plot
2020-03-23 21:16:09,890 - RBF - INFO - True
2020-03-23 21:16:09,890 - RBF - INFO - -----------------------------
2020-03-23 21:16:09,925 - RBF - INFO - openning sess
2020-03-23 21:16:16,952 - RBF - INFO - building net
2020-03-23 21:16:28,222 - RBF - INFO - building opt
2020-03-23 21:16:28,925 - RBF - INFO - net initializing
2020-03-23 21:16:28,925 - RBF - INFO - train epoch 0 of total 5000 epoches
2020-03-23 21:16:32,992 - RBF - ERROR - ,0
2020-03-23 21:17:38,814 - RBF - INFO - now initialize the net with para:
2020-03-23 21:17:38,814 - RBF - INFO - clip
2020-03-23 21:17:38,814 - RBF - INFO - False
2020-03-23 21:17:38,814 - RBF - INFO - -----------------------------
2020-03-23 21:17:38,814 - RBF - INFO - CKPT
2020-03-23 21:17:38,815 - RBF - INFO - ckpt
2020-03-23 21:17:38,815 - RBF - INFO - -----------------------------
2020-03-23 21:17:38,815 - RBF - INFO - BATCHSIZE
2020-03-23 21:17:38,815 - RBF - INFO - 10
2020-03-23 21:17:38,815 - RBF - INFO - -----------------------------
2020-03-23 21:17:38,815 - RBF - INFO - MAX_ITER
2020-03-23 21:17:38,815 - RBF - INFO - 5000
2020-03-23 21:17:38,815 - RBF - INFO - -----------------------------
2020-03-23 21:17:38,815 - RBF - INFO - STEP_EACH_ITER
2020-03-23 21:17:38,815 - RBF - INFO - 500
2020-03-23 21:17:38,815 - RBF - INFO - -----------------------------
2020-03-23 21:17:38,816 - RBF - INFO - STEP_SHOW
2020-03-23 21:17:38,816 - RBF - INFO - 200
2020-03-23 21:17:38,816 - RBF - INFO - -----------------------------
2020-03-23 21:17:38,816 - RBF - INFO - EPOCH_SAVE
2020-03-23 21:17:38,816 - RBF - INFO - 20
2020-03-23 21:17:38,816 - RBF - INFO - -----------------------------
2020-03-23 21:17:38,816 - RBF - INFO - LEARNING_RATE
2020-03-23 21:17:38,816 - RBF - INFO - 1e-05
2020-03-23 21:17:38,816 - RBF - INFO - -----------------------------
2020-03-23 21:17:38,817 - RBF - INFO - bound_weight
2020-03-23 21:17:38,817 - RBF - INFO - 1
2020-03-23 21:17:38,817 - RBF - INFO - -----------------------------
2020-03-23 21:17:38,817 - RBF - INFO - step_unbound
2020-03-23 21:17:38,817 - RBF - INFO - 5
2020-03-23 21:17:38,817 - RBF - INFO - -----------------------------
2020-03-23 21:17:38,817 - RBF - INFO - decay
2020-03-23 21:17:38,817 - RBF - INFO - False
2020-03-23 21:17:38,817 - RBF - INFO - -----------------------------
2020-03-23 21:17:38,817 - RBF - INFO - test_line
2020-03-23 21:17:38,817 - RBF - INFO - False
2020-03-23 21:17:38,818 - RBF - INFO - -----------------------------
2020-03-23 21:17:38,818 - RBF - INFO - is_plot
2020-03-23 21:17:38,818 - RBF - INFO - True
2020-03-23 21:17:38,818 - RBF - INFO - -----------------------------
2020-03-23 21:17:38,853 - RBF - INFO - openning sess
2020-03-23 21:17:44,241 - RBF - INFO - building net
2020-03-23 21:17:56,728 - RBF - INFO - building opt
2020-03-23 21:17:57,434 - RBF - INFO - net initializing
2020-03-23 21:17:57,435 - RBF - INFO - train epoch 0 of total 5000 epoches
2020-03-23 21:18:02,671 - RBF - ERROR - loss 32.45302541552206, in epoch 0, in step 199, in global step 200, learning rate is 1e-05, taks 5.236000061035156 seconds
2020-03-23 21:18:04,030 - RBF - ERROR - loss 32.292650858734035, in epoch 0, in step 399, in global step 400, learning rate is 1e-05, taks 1.3580000400543213 seconds
2020-03-23 21:18:04,713 - RBF - INFO - train epoch 1 of total 5000 epoches
2020-03-23 21:18:06,093 - RBF - ERROR - loss 32.23432453310834, in epoch 1, in step 199, in global step 700, learning rate is 1e-05, taks 2.061999797821045 seconds
2020-03-23 21:18:07,846 - RBF - ERROR - loss 32.19920284156544, in epoch 1, in step 399, in global step 900, learning rate is 1e-05, taks 1.752000093460083 seconds
2020-03-23 21:18:09,748 - RBF - INFO - train epoch 2 of total 5000 epoches
2020-03-23 21:18:13,653 - RBF - ERROR - loss 32.15106980985835, in epoch 2, in step 199, in global step 1200, learning rate is 1e-05, taks 5.807000160217285 seconds
2020-03-23 21:18:24,764 - RBF - INFO - now initialize the net with para:
2020-03-23 21:18:24,764 - RBF - INFO - clip
2020-03-23 21:18:24,765 - RBF - INFO - False
2020-03-23 21:18:24,765 - RBF - INFO - -----------------------------
2020-03-23 21:18:24,765 - RBF - INFO - CKPT
2020-03-23 21:18:24,765 - RBF - INFO - ckpt
2020-03-23 21:18:24,765 - RBF - INFO - -----------------------------
2020-03-23 21:18:24,765 - RBF - INFO - BATCHSIZE
2020-03-23 21:18:24,765 - RBF - INFO - 1000
2020-03-23 21:18:24,765 - RBF - INFO - -----------------------------
2020-03-23 21:18:24,765 - RBF - INFO - MAX_ITER
2020-03-23 21:18:24,765 - RBF - INFO - 5000
2020-03-23 21:18:24,765 - RBF - INFO - -----------------------------
2020-03-23 21:18:24,765 - RBF - INFO - STEP_EACH_ITER
2020-03-23 21:18:24,765 - RBF - INFO - 500
2020-03-23 21:18:24,765 - RBF - INFO - -----------------------------
2020-03-23 21:18:24,765 - RBF - INFO - STEP_SHOW
2020-03-23 21:18:24,766 - RBF - INFO - 200
2020-03-23 21:18:24,766 - RBF - INFO - -----------------------------
2020-03-23 21:18:24,766 - RBF - INFO - EPOCH_SAVE
2020-03-23 21:18:24,766 - RBF - INFO - 20
2020-03-23 21:18:24,766 - RBF - INFO - -----------------------------
2020-03-23 21:18:24,766 - RBF - INFO - LEARNING_RATE
2020-03-23 21:18:24,766 - RBF - INFO - 1e-05
2020-03-23 21:18:24,766 - RBF - INFO - -----------------------------
2020-03-23 21:18:24,766 - RBF - INFO - bound_weight
2020-03-23 21:18:24,766 - RBF - INFO - 1
2020-03-23 21:18:24,766 - RBF - INFO - -----------------------------
2020-03-23 21:18:24,766 - RBF - INFO - step_unbound
2020-03-23 21:18:24,766 - RBF - INFO - 5
2020-03-23 21:18:24,766 - RBF - INFO - -----------------------------
2020-03-23 21:18:24,766 - RBF - INFO - decay
2020-03-23 21:18:24,766 - RBF - INFO - False
2020-03-23 21:18:24,767 - RBF - INFO - -----------------------------
2020-03-23 21:18:24,767 - RBF - INFO - test_line
2020-03-23 21:18:24,767 - RBF - INFO - False
2020-03-23 21:18:24,767 - RBF - INFO - -----------------------------
2020-03-23 21:18:24,767 - RBF - INFO - is_plot
2020-03-23 21:18:24,767 - RBF - INFO - True
2020-03-23 21:18:24,767 - RBF - INFO - -----------------------------
2020-03-23 21:18:24,793 - RBF - INFO - openning sess
2020-03-23 21:18:30,250 - RBF - INFO - building net
2020-03-23 21:18:42,907 - RBF - INFO - building opt
2020-03-23 21:18:43,794 - RBF - INFO - net initializing
2020-03-23 21:18:43,794 - RBF - INFO - train epoch 0 of total 5000 epoches
2020-03-23 21:18:50,652 - RBF - ERROR - loss 2.097631716067237, in epoch 0, in step 199, in global step 200, learning rate is 1e-05, taks 6.858000040054321 seconds
2020-03-23 21:18:53,111 - RBF - ERROR - loss 1.9076753684412007, in epoch 0, in step 399, in global step 400, learning rate is 1e-05, taks 2.4589998722076416 seconds
2020-03-23 21:18:54,346 - RBF - INFO - train epoch 1 of total 5000 epoches
2020-03-23 21:18:56,838 - RBF - ERROR - loss 1.7158653254062426, in epoch 1, in step 199, in global step 700, learning rate is 1e-05, taks 3.7270002365112305 seconds
2020-03-23 21:18:59,321 - RBF - ERROR - loss 1.6136136299899546, in epoch 1, in step 399, in global step 900, learning rate is 1e-05, taks 2.4830000400543213 seconds
2020-03-23 21:19:00,557 - RBF - INFO - train epoch 2 of total 5000 epoches
2020-03-23 21:19:03,168 - RBF - ERROR - loss 1.4792102311952426, in epoch 2, in step 199, in global step 1200, learning rate is 1e-05, taks 3.8459997177124023 seconds
2020-03-23 21:19:05,671 - RBF - ERROR - loss 1.422951719808418, in epoch 2, in step 399, in global step 1400, learning rate is 1e-05, taks 2.503000259399414 seconds
2020-03-23 21:19:06,909 - RBF - INFO - train epoch 3 of total 5000 epoches
2020-03-23 21:19:09,395 - RBF - ERROR - loss 1.376521364838602, in epoch 3, in step 199, in global step 1700, learning rate is 1e-05, taks 3.7239999771118164 seconds
2020-03-23 21:19:11,869 - RBF - ERROR - loss 1.3620187438872335, in epoch 3, in step 399, in global step 1900, learning rate is 1e-05, taks 2.4739999771118164 seconds
2020-03-23 21:19:13,107 - RBF - INFO - train epoch 4 of total 5000 epoches
2020-03-23 21:19:15,584 - RBF - ERROR - loss 1.3499976394152666, in epoch 4, in step 199, in global step 2200, learning rate is 1e-05, taks 3.7149999141693115 seconds
2020-03-23 21:19:18,064 - RBF - ERROR - loss 1.3449985924167538, in epoch 4, in step 399, in global step 2400, learning rate is 1e-05, taks 2.4800000190734863 seconds
2020-03-23 21:19:19,300 - RBF - INFO - train epoch 5 of total 5000 epoches
2020-03-23 21:19:21,782 - RBF - ERROR - loss 1.3400324889208959, in epoch 5, in step 199, in global step 2700, learning rate is 1e-05, taks 3.7180001735687256 seconds
2020-03-23 21:19:24,253 - RBF - ERROR - loss 1.3377508631834083, in epoch 5, in step 399, in global step 2900, learning rate is 1e-05, taks 2.4709999561309814 seconds
2020-03-23 21:19:25,492 - RBF - INFO - train epoch 6 of total 5000 epoches
2020-03-23 21:19:27,969 - RBF - ERROR - loss 1.3351408223924452, in epoch 6, in step 199, in global step 3200, learning rate is 1e-05, taks 3.7160000801086426 seconds
2020-03-23 21:19:30,447 - RBF - ERROR - loss 1.3337364800362752, in epoch 6, in step 399, in global step 3400, learning rate is 1e-05, taks 2.4779999256134033 seconds
2020-03-23 21:19:31,681 - RBF - INFO - train epoch 7 of total 5000 epoches
2020-03-23 21:19:34,157 - RBF - ERROR - loss 1.3319549110101387, in epoch 7, in step 199, in global step 3700, learning rate is 1e-05, taks 3.7100000381469727 seconds
2020-03-23 21:19:36,631 - RBF - ERROR - loss 1.3309312793303896, in epoch 7, in step 399, in global step 3900, learning rate is 1e-05, taks 2.4739997386932373 seconds
2020-03-23 21:19:37,869 - RBF - INFO - train epoch 8 of total 5000 epoches
2020-03-23 21:19:40,344 - RBF - ERROR - loss 1.3295908438363988, in epoch 8, in step 199, in global step 4200, learning rate is 1e-05, taks 3.7130000591278076 seconds
2020-03-23 21:19:42,823 - RBF - ERROR - loss 1.328808241443578, in epoch 8, in step 399, in global step 4400, learning rate is 1e-05, taks 2.4790000915527344 seconds
2020-03-23 21:19:44,061 - RBF - INFO - train epoch 9 of total 5000 epoches
2020-03-23 21:19:46,542 - RBF - ERROR - loss 1.3277765930191883, in epoch 9, in step 199, in global step 4700, learning rate is 1e-05, taks 3.7190001010894775 seconds
2020-03-23 21:19:49,019 - RBF - ERROR - loss 1.3271717767916242, in epoch 9, in step 399, in global step 4900, learning rate is 1e-05, taks 2.4761998653411865 seconds
2020-03-23 21:19:50,266 - RBF - INFO - train epoch 10 of total 5000 epoches
2020-03-23 21:19:56,466 - RBF - ERROR - loss 1.3263696204665547, in epoch 10, in step 199, in global step 5200, learning rate is 1e-05, taks 7.445800065994263 seconds
2020-03-23 21:20:02,602 - RBF - ERROR - loss 1.3258934179803472, in epoch 10, in step 399, in global step 5400, learning rate is 1e-05, taks 6.135999917984009 seconds
2020-03-23 21:20:05,726 - RBF - INFO - train epoch 11 of total 5000 epoches
2020-03-23 21:20:11,814 - RBF - ERROR - loss 1.3252482768187166, in epoch 11, in step 199, in global step 5700, learning rate is 1e-05, taks 9.211999893188477 seconds
2020-03-23 21:20:17,925 - RBF - ERROR - loss 1.3248553593683723, in epoch 11, in step 399, in global step 5900, learning rate is 1e-05, taks 6.109999895095825 seconds
2020-03-23 21:20:20,919 - RBF - INFO - train epoch 12 of total 5000 epoches
2020-03-23 21:20:26,540 - RBF - ERROR - loss 1.32431064154292, in epoch 12, in step 199, in global step 6200, learning rate is 1e-05, taks 8.614000082015991 seconds
2020-03-23 21:20:32,046 - RBF - ERROR - loss 1.3239724601606888, in epoch 12, in step 399, in global step 6400, learning rate is 1e-05, taks 5.50600004196167 seconds
2020-03-23 21:20:34,492 - RBF - INFO - train epoch 13 of total 5000 epoches
2020-03-23 21:20:39,378 - RBF - ERROR - loss 1.3234961625091441, in epoch 13, in step 199, in global step 6700, learning rate is 1e-05, taks 7.332000017166138 seconds
2020-03-23 21:20:44,255 - RBF - ERROR - loss 1.3231915430504264, in epoch 13, in step 399, in global step 6900, learning rate is 1e-05, taks 4.876999855041504 seconds
2020-03-23 21:20:46,715 - RBF - INFO - train epoch 14 of total 5000 epoches
2020-03-23 21:20:51,614 - RBF - ERROR - loss 1.3227645274803326, in epoch 14, in step 199, in global step 7200, learning rate is 1e-05, taks 7.3580002784729 seconds
2020-03-23 21:20:56,525 - RBF - ERROR - loss 1.3224968465111115, in epoch 14, in step 399, in global step 7400, learning rate is 1e-05, taks 4.9100000858306885 seconds
2020-03-23 21:20:58,954 - RBF - INFO - train epoch 15 of total 5000 epoches
2020-03-23 21:21:03,895 - RBF - ERROR - loss 1.3221048653998952, in epoch 15, in step 199, in global step 7700, learning rate is 1e-05, taks 7.370199680328369 seconds
2020-03-23 21:21:08,780 - RBF - ERROR - loss 1.3218437935871719, in epoch 15, in step 399, in global step 7900, learning rate is 1e-05, taks 4.885000228881836 seconds
2020-03-23 21:21:11,200 - RBF - INFO - train epoch 16 of total 5000 epoches
2020-03-23 21:21:16,762 - RBF - ERROR - loss 1.3214876018380093, in epoch 16, in step 199, in global step 8200, learning rate is 1e-05, taks 7.98199987411499 seconds
2020-03-23 21:21:20,894 - RBF - ERROR - loss 1.3212791931059924, in epoch 16, in step 399, in global step 8400, learning rate is 1e-05, taks 4.131999969482422 seconds
2020-03-23 21:21:22,715 - RBF - INFO - train epoch 17 of total 5000 epoches
2020-03-23 21:21:25,890 - RBF - ERROR - loss 1.3209296623221296, in epoch 17, in step 199, in global step 8700, learning rate is 1e-05, taks 4.996000051498413 seconds
2020-03-23 21:21:28,545 - RBF - ERROR - loss 1.3207214360559856, in epoch 17, in step 399, in global step 8900, learning rate is 1e-05, taks 2.6549999713897705 seconds
2020-03-23 21:21:30,007 - RBF - INFO - train epoch 18 of total 5000 epoches
2020-03-23 21:21:32,709 - RBF - ERROR - loss 1.32042358934957, in epoch 18, in step 199, in global step 9200, learning rate is 1e-05, taks 4.164000034332275 seconds
2020-03-23 21:21:35,388 - RBF - ERROR - loss 1.3202573180209038, in epoch 18, in step 399, in global step 9400, learning rate is 1e-05, taks 2.67900013923645 seconds
2020-03-23 21:21:36,715 - RBF - INFO - train epoch 19 of total 5000 epoches
2020-03-23 21:21:39,356 - RBF - ERROR - loss 1.3200015529835427, in epoch 19, in step 199, in global step 9700, learning rate is 1e-05, taks 3.9679999351501465 seconds
2020-03-23 21:21:41,903 - RBF - ERROR - loss 1.3198009224775904, in epoch 19, in step 399, in global step 9900, learning rate is 1e-05, taks 2.546999931335449 seconds
2020-03-23 21:21:54,631 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 19. learning_rate is 1e-05, loss is 1.3197366855778843
2020-03-23 21:21:54,632 - RBF - INFO - train epoch 20 of total 5000 epoches
2020-03-23 21:22:01,500 - RBF - ERROR - loss 1.319575228038726, in epoch 20, in step 199, in global step 10200, learning rate is 1e-05, taks 19.597000122070312 seconds
2020-03-23 21:22:05,645 - RBF - ERROR - loss 1.3194156701200335, in epoch 20, in step 399, in global step 10400, learning rate is 1e-05, taks 4.144999980926514 seconds
2020-03-23 21:22:07,430 - RBF - INFO - train epoch 21 of total 5000 epoches
2020-03-23 21:22:10,998 - RBF - ERROR - loss 1.3191912232513727, in epoch 21, in step 199, in global step 10700, learning rate is 1e-05, taks 5.352999925613403 seconds
2020-03-23 21:22:14,573 - RBF - ERROR - loss 1.3190549893381727, in epoch 21, in step 399, in global step 10900, learning rate is 1e-05, taks 3.575000047683716 seconds
2020-03-23 21:22:16,340 - RBF - INFO - train epoch 22 of total 5000 epoches
2020-03-23 21:22:19,898 - RBF - ERROR - loss 1.3188656187864165, in epoch 22, in step 199, in global step 11200, learning rate is 1e-05, taks 5.325000047683716 seconds
2020-03-23 21:22:23,167 - RBF - ERROR - loss 1.31875130565482, in epoch 22, in step 399, in global step 11400, learning rate is 1e-05, taks 3.2689998149871826 seconds
2020-03-23 21:22:24,820 - RBF - INFO - train epoch 23 of total 5000 epoches
2020-03-23 21:22:28,184 - RBF - ERROR - loss 1.318568200015141, in epoch 23, in step 199, in global step 11700, learning rate is 1e-05, taks 5.017000198364258 seconds
2020-03-23 21:22:31,698 - RBF - ERROR - loss 1.3184597683430883, in epoch 23, in step 399, in global step 11900, learning rate is 1e-05, taks 3.5139999389648438 seconds
2020-03-23 21:22:33,528 - RBF - INFO - train epoch 24 of total 5000 epoches
2020-03-23 21:22:36,876 - RBF - ERROR - loss 1.318317315010778, in epoch 24, in step 199, in global step 12200, learning rate is 1e-05, taks 5.177999973297119 seconds
2020-03-23 21:22:40,328 - RBF - ERROR - loss 1.3182127530652599, in epoch 24, in step 399, in global step 12400, learning rate is 1e-05, taks 3.452000141143799 seconds
2020-03-23 21:22:42,068 - RBF - INFO - train epoch 25 of total 5000 epoches
2020-03-23 21:22:45,829 - RBF - ERROR - loss 1.3180777694915202, in epoch 25, in step 199, in global step 12700, learning rate is 1e-05, taks 5.500999927520752 seconds
2020-03-23 21:22:48,623 - RBF - ERROR - loss 1.317987111626171, in epoch 25, in step 399, in global step 12900, learning rate is 1e-05, taks 2.7929999828338623 seconds
2020-03-23 21:22:50,082 - RBF - INFO - train epoch 26 of total 5000 epoches
2020-03-23 21:22:52,808 - RBF - ERROR - loss 1.3178672733467915, in epoch 26, in step 199, in global step 13200, learning rate is 1e-05, taks 4.18500018119812 seconds
2020-03-23 21:22:55,492 - RBF - ERROR - loss 1.31780169940808, in epoch 26, in step 399, in global step 13400, learning rate is 1e-05, taks 2.684000015258789 seconds
2020-03-23 21:22:56,732 - RBF - INFO - train epoch 27 of total 5000 epoches
2020-03-23 21:22:59,215 - RBF - ERROR - loss 1.3176749968282107, in epoch 27, in step 199, in global step 13700, learning rate is 1e-05, taks 3.7219998836517334 seconds
2020-03-23 21:23:01,709 - RBF - ERROR - loss 1.3176052153264304, in epoch 27, in step 399, in global step 13900, learning rate is 1e-05, taks 2.492999792098999 seconds
2020-03-23 21:23:02,956 - RBF - INFO - train epoch 28 of total 5000 epoches
2020-03-23 21:23:05,540 - RBF - ERROR - loss 1.317500718052224, in epoch 28, in step 199, in global step 14200, learning rate is 1e-05, taks 3.8310000896453857 seconds
2020-03-23 21:23:08,126 - RBF - ERROR - loss 1.3174347427804844, in epoch 28, in step 399, in global step 14400, learning rate is 1e-05, taks 2.5859999656677246 seconds
2020-03-23 21:23:09,426 - RBF - INFO - train epoch 29 of total 5000 epoches
2020-03-23 21:23:11,983 - RBF - ERROR - loss 1.3173380063851656, in epoch 29, in step 199, in global step 14700, learning rate is 1e-05, taks 3.8569998741149902 seconds
2020-03-23 21:23:14,613 - RBF - ERROR - loss 1.3172740756701138, in epoch 29, in step 399, in global step 14900, learning rate is 1e-05, taks 2.630000114440918 seconds
2020-03-23 21:23:16,010 - RBF - INFO - train epoch 30 of total 5000 epoches
2020-03-23 21:23:18,732 - RBF - ERROR - loss 1.3171782785543764, in epoch 30, in step 199, in global step 15200, learning rate is 1e-05, taks 4.119000196456909 seconds
2020-03-23 21:23:21,489 - RBF - ERROR - loss 1.3171154127417948, in epoch 30, in step 399, in global step 15400, learning rate is 1e-05, taks 2.7569997310638428 seconds
2020-03-23 21:23:22,894 - RBF - INFO - train epoch 31 of total 5000 epoches
2020-03-23 21:23:26,103 - RBF - ERROR - loss 1.317023265811118, in epoch 31, in step 199, in global step 15700, learning rate is 1e-05, taks 4.613000154495239 seconds
2020-03-23 21:23:29,939 - RBF - ERROR - loss 1.3169612370794181, in epoch 31, in step 399, in global step 15900, learning rate is 1e-05, taks 3.8359999656677246 seconds
2020-03-23 21:23:31,413 - RBF - INFO - train epoch 32 of total 5000 epoches
2020-03-23 21:23:34,104 - RBF - ERROR - loss 1.3168930752869699, in epoch 32, in step 199, in global step 16200, learning rate is 1e-05, taks 4.164000034332275 seconds
2020-03-23 21:23:37,393 - RBF - ERROR - loss 1.3168124822950034, in epoch 32, in step 399, in global step 16400, learning rate is 1e-05, taks 3.2889997959136963 seconds
2020-03-23 21:23:39,043 - RBF - INFO - train epoch 33 of total 5000 epoches
2020-03-23 21:23:41,875 - RBF - ERROR - loss 1.3167243649054206, in epoch 33, in step 199, in global step 16700, learning rate is 1e-05, taks 4.480999946594238 seconds
2020-03-23 21:23:44,808 - RBF - ERROR - loss 1.316658833805299, in epoch 33, in step 399, in global step 16900, learning rate is 1e-05, taks 2.933000326156616 seconds
2020-03-23 21:23:46,385 - RBF - INFO - train epoch 34 of total 5000 epoches
2020-03-23 21:23:49,325 - RBF - ERROR - loss 1.3165610092851834, in epoch 34, in step 199, in global step 17200, learning rate is 1e-05, taks 4.516999959945679 seconds
2020-03-23 21:23:52,064 - RBF - ERROR - loss 1.316511299051758, in epoch 34, in step 399, in global step 17400, learning rate is 1e-05, taks 2.739000082015991 seconds
2020-03-23 21:23:53,330 - RBF - INFO - train epoch 35 of total 5000 epoches
2020-03-23 21:23:55,832 - RBF - ERROR - loss 1.3164034262222406, in epoch 35, in step 199, in global step 17700, learning rate is 1e-05, taks 3.7669999599456787 seconds
2020-03-23 21:23:58,354 - RBF - ERROR - loss 1.3163481945325357, in epoch 35, in step 399, in global step 17900, learning rate is 1e-05, taks 2.5209999084472656 seconds
2020-03-23 21:23:59,749 - RBF - INFO - train epoch 36 of total 5000 epoches
2020-03-23 21:24:02,418 - RBF - ERROR - loss 1.3162512565992677, in epoch 36, in step 199, in global step 18200, learning rate is 1e-05, taks 4.064000129699707 seconds
2020-03-23 21:24:05,201 - RBF - ERROR - loss 1.316183937398863, in epoch 36, in step 399, in global step 18400, learning rate is 1e-05, taks 2.7829999923706055 seconds
2020-03-23 21:24:06,712 - RBF - INFO - train epoch 37 of total 5000 epoches
2020-03-23 21:24:09,936 - RBF - ERROR - loss 1.3160949657076677, in epoch 37, in step 199, in global step 18700, learning rate is 1e-05, taks 4.735000133514404 seconds
2020-03-23 21:24:12,873 - RBF - ERROR - loss 1.316023575380445, in epoch 37, in step 399, in global step 18900, learning rate is 1e-05, taks 2.936999797821045 seconds
2020-03-23 21:24:15,149 - RBF - INFO - train epoch 38 of total 5000 epoches
2020-03-23 21:24:18,595 - RBF - ERROR - loss 1.3159277916179501, in epoch 38, in step 199, in global step 19200, learning rate is 1e-05, taks 5.7209999561309814 seconds
2020-03-23 21:24:21,465 - RBF - ERROR - loss 1.3158789617319895, in epoch 38, in step 399, in global step 19400, learning rate is 1e-05, taks 2.870000123977661 seconds
2020-03-23 21:24:22,753 - RBF - INFO - train epoch 39 of total 5000 epoches
2020-03-23 21:24:25,377 - RBF - ERROR - loss 1.3157690369370734, in epoch 39, in step 199, in global step 19700, learning rate is 1e-05, taks 3.9110000133514404 seconds
2020-03-23 21:24:27,982 - RBF - ERROR - loss 1.3157080785602993, in epoch 39, in step 399, in global step 19900, learning rate is 1e-05, taks 2.6050000190734863 seconds
2020-03-23 21:24:39,028 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 39. learning_rate is 1e-05, loss is 1.3156674848943688
2020-03-23 21:24:39,029 - RBF - INFO - train epoch 40 of total 5000 epoches
2020-03-23 21:24:46,622 - RBF - ERROR - loss 1.3156196719356454, in epoch 40, in step 199, in global step 20200, learning rate is 1e-05, taks 18.640000104904175 seconds
2020-03-23 21:24:52,960 - RBF - ERROR - loss 1.3155405199187, in epoch 40, in step 399, in global step 20400, learning rate is 1e-05, taks 6.337199926376343 seconds
2020-03-23 21:24:56,004 - RBF - INFO - train epoch 41 of total 5000 epoches
2020-03-23 21:25:01,341 - RBF - ERROR - loss 1.3154416679944587, in epoch 41, in step 199, in global step 20700, learning rate is 1e-05, taks 8.380600214004517 seconds
2020-03-23 21:25:06,242 - RBF - ERROR - loss 1.3153744518218655, in epoch 41, in step 399, in global step 20900, learning rate is 1e-05, taks 4.9009997844696045 seconds
2020-03-23 21:25:08,654 - RBF - INFO - train epoch 42 of total 5000 epoches
2020-03-23 21:25:13,333 - RBF - ERROR - loss 1.3152948187270317, in epoch 42, in step 199, in global step 21200, learning rate is 1e-05, taks 7.091000080108643 seconds
2020-03-23 21:25:18,103 - RBF - ERROR - loss 1.3152429525344131, in epoch 42, in step 399, in global step 21400, learning rate is 1e-05, taks 4.769999980926514 seconds
2020-03-23 21:25:20,508 - RBF - INFO - train epoch 43 of total 5000 epoches
2020-03-23 21:25:25,407 - RBF - ERROR - loss 1.315111458021655, in epoch 43, in step 199, in global step 21700, learning rate is 1e-05, taks 7.303999900817871 seconds
2020-03-23 21:25:30,271 - RBF - ERROR - loss 1.3150644214058884, in epoch 43, in step 399, in global step 21900, learning rate is 1e-05, taks 4.864000082015991 seconds
2020-03-23 21:25:32,643 - RBF - INFO - train epoch 44 of total 5000 epoches
2020-03-23 21:25:37,351 - RBF - ERROR - loss 1.3149456191540059, in epoch 44, in step 199, in global step 22200, learning rate is 1e-05, taks 7.079999923706055 seconds
2020-03-23 21:25:41,925 - RBF - ERROR - loss 1.314883492183754, in epoch 44, in step 399, in global step 22400, learning rate is 1e-05, taks 4.573000192642212 seconds
2020-03-23 21:25:44,170 - RBF - INFO - train epoch 45 of total 5000 epoches
2020-03-23 21:25:48,671 - RBF - ERROR - loss 1.314806844349068, in epoch 45, in step 199, in global step 22700, learning rate is 1e-05, taks 6.746000051498413 seconds
2020-03-23 21:25:53,155 - RBF - ERROR - loss 1.3147195064676662, in epoch 45, in step 399, in global step 22900, learning rate is 1e-05, taks 4.483000040054321 seconds
2020-03-23 21:25:55,399 - RBF - INFO - train epoch 46 of total 5000 epoches
2020-03-23 21:25:59,898 - RBF - ERROR - loss 1.3146210490682815, in epoch 46, in step 199, in global step 23200, learning rate is 1e-05, taks 6.743000030517578 seconds
2020-03-23 21:26:04,401 - RBF - ERROR - loss 1.3145732074086343, in epoch 46, in step 399, in global step 23400, learning rate is 1e-05, taks 4.503000020980835 seconds
2020-03-23 21:26:06,672 - RBF - INFO - train epoch 47 of total 5000 epoches
2020-03-23 21:26:11,165 - RBF - ERROR - loss 1.3144673600413421, in epoch 47, in step 199, in global step 23700, learning rate is 1e-05, taks 6.763999938964844 seconds
2020-03-23 21:26:15,744 - RBF - ERROR - loss 1.3143886847816033, in epoch 47, in step 399, in global step 23900, learning rate is 1e-05, taks 4.579599857330322 seconds
2020-03-23 21:26:17,995 - RBF - INFO - train epoch 48 of total 5000 epoches
2020-03-23 21:26:22,699 - RBF - ERROR - loss 1.3142943917067795, in epoch 48, in step 199, in global step 24200, learning rate is 1e-05, taks 6.955000162124634 seconds
2020-03-23 21:26:27,033 - RBF - ERROR - loss 1.314224782613485, in epoch 48, in step 399, in global step 24400, learning rate is 1e-05, taks 4.333999872207642 seconds
2020-03-23 21:26:29,057 - RBF - INFO - train epoch 49 of total 5000 epoches
2020-03-23 21:26:33,071 - RBF - ERROR - loss 1.3141124967198392, in epoch 49, in step 199, in global step 24700, learning rate is 1e-05, taks 6.038000106811523 seconds
2020-03-23 21:26:37,080 - RBF - ERROR - loss 1.3140490472293906, in epoch 49, in step 399, in global step 24900, learning rate is 1e-05, taks 4.009000062942505 seconds
2020-03-23 21:26:39,092 - RBF - INFO - train epoch 50 of total 5000 epoches
2020-03-23 21:26:43,121 - RBF - ERROR - loss 1.3139982026493051, in epoch 50, in step 199, in global step 25200, learning rate is 1e-05, taks 6.040999889373779 seconds
2020-03-23 21:26:47,142 - RBF - ERROR - loss 1.3138906723574282, in epoch 50, in step 399, in global step 25400, learning rate is 1e-05, taks 4.019999980926514 seconds
2020-03-23 21:26:49,147 - RBF - INFO - train epoch 51 of total 5000 epoches
2020-03-23 21:26:53,167 - RBF - ERROR - loss 1.3137822464866147, in epoch 51, in step 199, in global step 25700, learning rate is 1e-05, taks 6.0249998569488525 seconds
2020-03-23 21:26:57,171 - RBF - ERROR - loss 1.313710183183059, in epoch 51, in step 399, in global step 25900, learning rate is 1e-05, taks 4.003000020980835 seconds
2020-03-23 21:26:59,179 - RBF - INFO - train epoch 52 of total 5000 epoches
2020-03-23 21:27:03,262 - RBF - ERROR - loss 1.3136160554923615, in epoch 52, in step 199, in global step 26200, learning rate is 1e-05, taks 6.091000080108643 seconds
2020-03-23 21:27:07,305 - RBF - ERROR - loss 1.3135538967899316, in epoch 52, in step 399, in global step 26400, learning rate is 1e-05, taks 4.042999982833862 seconds
2020-03-23 21:27:09,346 - RBF - INFO - train epoch 53 of total 5000 epoches
2020-03-23 21:27:13,409 - RBF - ERROR - loss 1.313448155269747, in epoch 53, in step 199, in global step 26700, learning rate is 1e-05, taks 6.102999687194824 seconds
2020-03-23 21:27:17,455 - RBF - ERROR - loss 1.313378991523955, in epoch 53, in step 399, in global step 26900, learning rate is 1e-05, taks 4.046000242233276 seconds
2020-03-23 21:27:19,464 - RBF - INFO - train epoch 54 of total 5000 epoches
2020-03-23 21:27:23,487 - RBF - ERROR - loss 1.3132807076924145, in epoch 54, in step 199, in global step 27200, learning rate is 1e-05, taks 6.0320000648498535 seconds
2020-03-23 21:27:27,507 - RBF - ERROR - loss 1.3132213303050402, in epoch 54, in step 399, in global step 27400, learning rate is 1e-05, taks 4.019999980926514 seconds
2020-03-23 21:27:29,517 - RBF - INFO - train epoch 55 of total 5000 epoches
2020-03-23 21:27:33,532 - RBF - ERROR - loss 1.3131197606637535, in epoch 55, in step 199, in global step 27700, learning rate is 1e-05, taks 6.0249998569488525 seconds
2020-03-23 21:27:37,545 - RBF - ERROR - loss 1.3130534939266567, in epoch 55, in step 399, in global step 27900, learning rate is 1e-05, taks 4.01200008392334 seconds
2020-03-23 21:27:39,549 - RBF - INFO - train epoch 56 of total 5000 epoches
2020-03-23 21:27:43,560 - RBF - ERROR - loss 1.3129544790884562, in epoch 56, in step 199, in global step 28200, learning rate is 1e-05, taks 6.014999866485596 seconds
2020-03-23 21:27:47,577 - RBF - ERROR - loss 1.3128887318148017, in epoch 56, in step 399, in global step 28400, learning rate is 1e-05, taks 4.016999959945679 seconds
2020-03-23 21:27:49,595 - RBF - INFO - train epoch 57 of total 5000 epoches
2020-03-23 21:27:53,609 - RBF - ERROR - loss 1.3127904156938066, in epoch 57, in step 199, in global step 28700, learning rate is 1e-05, taks 6.0320000648498535 seconds
2020-03-23 21:27:57,628 - RBF - ERROR - loss 1.3127250770472727, in epoch 57, in step 399, in global step 28900, learning rate is 1e-05, taks 4.017399787902832 seconds
2020-03-23 21:27:59,619 - RBF - INFO - train epoch 58 of total 5000 epoches
2020-03-23 21:28:03,638 - RBF - ERROR - loss 1.3126274857304367, in epoch 58, in step 199, in global step 29200, learning rate is 1e-05, taks 6.010000228881836 seconds
2020-03-23 21:28:07,674 - RBF - ERROR - loss 1.3125625801020018, in epoch 58, in step 399, in global step 29400, learning rate is 1e-05, taks 4.0350000858306885 seconds
2020-03-23 21:28:09,683 - RBF - INFO - train epoch 59 of total 5000 epoches
2020-03-23 21:28:13,694 - RBF - ERROR - loss 1.31246572846029, in epoch 59, in step 199, in global step 29700, learning rate is 1e-05, taks 6.019000053405762 seconds
2020-03-23 21:28:17,715 - RBF - ERROR - loss 1.3124014407600815, in epoch 59, in step 399, in global step 29900, learning rate is 1e-05, taks 4.020999908447266 seconds
2020-03-23 21:28:48,087 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 59. learning_rate is 1e-05, loss is 1.3123689948242503
2020-03-23 21:28:48,089 - RBF - INFO - train epoch 60 of total 5000 epoches
2020-03-23 21:28:55,374 - RBF - ERROR - loss 1.3123054862044048, in epoch 60, in step 199, in global step 30200, learning rate is 1e-05, taks 37.65900015830994 seconds
2020-03-23 21:29:01,495 - RBF - ERROR - loss 1.3122418274642667, in epoch 60, in step 399, in global step 30400, learning rate is 1e-05, taks 6.120800018310547 seconds
2020-03-23 21:29:04,544 - RBF - INFO - train epoch 61 of total 5000 epoches
2020-03-23 21:29:10,660 - RBF - ERROR - loss 1.3121468331972526, in epoch 61, in step 199, in global step 30700, learning rate is 1e-05, taks 9.16540002822876 seconds
2020-03-23 21:29:16,759 - RBF - ERROR - loss 1.3120838531013486, in epoch 61, in step 399, in global step 30900, learning rate is 1e-05, taks 6.098599910736084 seconds
2020-03-23 21:29:19,815 - RBF - INFO - train epoch 62 of total 5000 epoches
2020-03-23 21:29:25,911 - RBF - ERROR - loss 1.3119899139764981, in epoch 62, in step 199, in global step 31200, learning rate is 1e-05, taks 9.151999950408936 seconds
2020-03-23 21:29:31,984 - RBF - ERROR - loss 1.311927647393745, in epoch 62, in step 399, in global step 31400, learning rate is 1e-05, taks 6.072999954223633 seconds
2020-03-23 21:29:35,046 - RBF - INFO - train epoch 63 of total 5000 epoches
2020-03-23 21:29:41,131 - RBF - ERROR - loss 1.311834842431852, in epoch 63, in step 199, in global step 31700, learning rate is 1e-05, taks 9.147000074386597 seconds
2020-03-23 21:29:47,250 - RBF - ERROR - loss 1.3117733426389937, in epoch 63, in step 399, in global step 31900, learning rate is 1e-05, taks 6.11899995803833 seconds
2020-03-23 21:29:50,316 - RBF - INFO - train epoch 64 of total 5000 epoches
2020-03-23 21:29:56,422 - RBF - ERROR - loss 1.3116816834919784, in epoch 64, in step 199, in global step 32200, learning rate is 1e-05, taks 9.172199964523315 seconds
2020-03-23 21:30:02,538 - RBF - ERROR - loss 1.3116209766278455, in epoch 64, in step 399, in global step 32400, learning rate is 1e-05, taks 6.115999937057495 seconds
2020-03-23 21:30:05,622 - RBF - INFO - train epoch 65 of total 5000 epoches
2020-03-23 21:30:11,739 - RBF - ERROR - loss 1.3115305364158605, in epoch 65, in step 199, in global step 32700, learning rate is 1e-05, taks 9.199999809265137 seconds
2020-03-23 21:30:17,855 - RBF - ERROR - loss 1.311470661483571, in epoch 65, in step 399, in global step 32900, learning rate is 1e-05, taks 6.115000247955322 seconds
2020-03-23 21:30:20,939 - RBF - INFO - train epoch 66 of total 5000 epoches
2020-03-23 21:30:27,074 - RBF - ERROR - loss 1.3113813918573993, in epoch 66, in step 199, in global step 33200, learning rate is 1e-05, taks 9.218999862670898 seconds
2020-03-23 21:30:33,172 - RBF - ERROR - loss 1.3113223063715265, in epoch 66, in step 399, in global step 33400, learning rate is 1e-05, taks 6.0970001220703125 seconds
2020-03-23 21:30:36,226 - RBF - INFO - train epoch 67 of total 5000 epoches
2020-03-23 21:30:42,347 - RBF - ERROR - loss 1.3112342890333208, in epoch 67, in step 199, in global step 33700, learning rate is 1e-05, taks 9.174999952316284 seconds
2020-03-23 21:30:48,461 - RBF - ERROR - loss 1.3111759952278141, in epoch 67, in step 399, in global step 33900, learning rate is 1e-05, taks 6.114000082015991 seconds
2020-03-23 21:30:51,504 - RBF - INFO - train epoch 68 of total 5000 epoches
2020-03-23 21:30:57,602 - RBF - ERROR - loss 1.3110891472266246, in epoch 68, in step 199, in global step 34200, learning rate is 1e-05, taks 9.141000032424927 seconds
2020-03-23 21:31:03,733 - RBF - ERROR - loss 1.3110316233636987, in epoch 68, in step 399, in global step 34400, learning rate is 1e-05, taks 6.131200075149536 seconds
2020-03-23 21:31:06,816 - RBF - INFO - train epoch 69 of total 5000 epoches
2020-03-23 21:31:12,933 - RBF - ERROR - loss 1.310945888123253, in epoch 69, in step 199, in global step 34700, learning rate is 1e-05, taks 9.199999809265137 seconds
2020-03-23 21:31:19,059 - RBF - ERROR - loss 1.3108890815264422, in epoch 69, in step 399, in global step 34900, learning rate is 1e-05, taks 6.126000165939331 seconds
2020-03-23 21:31:22,091 - RBF - INFO - train epoch 70 of total 5000 epoches
2020-03-23 21:31:27,338 - RBF - ERROR - loss 1.3108043787189794, in epoch 70, in step 199, in global step 35200, learning rate is 1e-05, taks 8.279000043869019 seconds
2020-03-23 21:31:31,852 - RBF - ERROR - loss 1.3107482380285358, in epoch 70, in step 399, in global step 35400, learning rate is 1e-05, taks 4.513000011444092 seconds
2020-03-23 21:31:33,941 - RBF - INFO - train epoch 71 of total 5000 epoches
2020-03-23 21:31:38,063 - RBF - ERROR - loss 1.3106644932077927, in epoch 71, in step 199, in global step 35700, learning rate is 1e-05, taks 6.211400032043457 seconds
2020-03-23 21:31:42,050 - RBF - ERROR - loss 1.3106089353792276, in epoch 71, in step 399, in global step 35900, learning rate is 1e-05, taks 3.986999988555908 seconds
2020-03-23 21:31:43,832 - RBF - INFO - train epoch 72 of total 5000 epoches
2020-03-23 21:31:47,310 - RBF - ERROR - loss 1.3105260424124257, in epoch 72, in step 199, in global step 36200, learning rate is 1e-05, taks 5.259999990463257 seconds
2020-03-23 21:31:50,804 - RBF - ERROR - loss 1.3104710417733911, in epoch 72, in step 399, in global step 36400, learning rate is 1e-05, taks 3.493000030517578 seconds
2020-03-23 21:31:52,533 - RBF - INFO - train epoch 73 of total 5000 epoches
2020-03-23 21:31:56,022 - RBF - ERROR - loss 1.3103889005110712, in epoch 73, in step 199, in global step 36700, learning rate is 1e-05, taks 5.217999696731567 seconds
2020-03-23 21:31:59,514 - RBF - ERROR - loss 1.3103343811705126, in epoch 73, in step 399, in global step 36900, learning rate is 1e-05, taks 3.492000102996826 seconds
2020-03-23 21:32:01,267 - RBF - INFO - train epoch 74 of total 5000 epoches
2020-03-23 21:32:04,752 - RBF - ERROR - loss 1.310252930553579, in epoch 74, in step 199, in global step 37200, learning rate is 1e-05, taks 5.238000154495239 seconds
2020-03-23 21:32:08,264 - RBF - ERROR - loss 1.310198830422949, in epoch 74, in step 399, in global step 37400, learning rate is 1e-05, taks 3.51200008392334 seconds
2020-03-23 21:32:10,010 - RBF - INFO - train epoch 75 of total 5000 epoches
2020-03-23 21:32:13,507 - RBF - ERROR - loss 1.310117992693349, in epoch 75, in step 199, in global step 37700, learning rate is 1e-05, taks 5.242999792098999 seconds
2020-03-23 21:32:17,000 - RBF - ERROR - loss 1.3100642776454778, in epoch 75, in step 399, in global step 37900, learning rate is 1e-05, taks 3.493000030517578 seconds
2020-03-23 21:32:18,728 - RBF - INFO - train epoch 76 of total 5000 epoches
2020-03-23 21:32:22,288 - RBF - ERROR - loss 1.3099840042076267, in epoch 76, in step 199, in global step 38200, learning rate is 1e-05, taks 5.288000106811523 seconds
2020-03-23 21:32:25,771 - RBF - ERROR - loss 1.309930683846353, in epoch 76, in step 399, in global step 38400, learning rate is 1e-05, taks 3.482999801635742 seconds
2020-03-23 21:32:27,534 - RBF - INFO - train epoch 77 of total 5000 epoches
2020-03-23 21:32:31,010 - RBF - ERROR - loss 1.3098509373008973, in epoch 77, in step 199, in global step 38700, learning rate is 1e-05, taks 5.239000082015991 seconds
2020-03-23 21:32:34,490 - RBF - ERROR - loss 1.3097979379437414, in epoch 77, in step 399, in global step 38900, learning rate is 1e-05, taks 3.4800000190734863 seconds
2020-03-23 21:32:36,233 - RBF - INFO - train epoch 78 of total 5000 epoches
2020-03-23 21:32:39,712 - RBF - ERROR - loss 1.3097187154837535, in epoch 78, in step 199, in global step 39200, learning rate is 1e-05, taks 5.2220001220703125 seconds
2020-03-23 21:32:43,202 - RBF - ERROR - loss 1.3096660668311706, in epoch 78, in step 399, in global step 39400, learning rate is 1e-05, taks 3.489999771118164 seconds
2020-03-23 21:32:44,927 - RBF - INFO - train epoch 79 of total 5000 epoches
2020-03-23 21:32:48,410 - RBF - ERROR - loss 1.309587362610913, in epoch 79, in step 199, in global step 39700, learning rate is 1e-05, taks 5.20799994468689 seconds
2020-03-23 21:32:51,888 - RBF - ERROR - loss 1.3095350514984663, in epoch 79, in step 399, in global step 39900, learning rate is 1e-05, taks 3.4780001640319824 seconds
2020-03-23 21:33:12,300 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 79. learning_rate is 1e-05, loss is 1.3095085677911444
2020-03-23 21:33:12,302 - RBF - INFO - train epoch 80 of total 5000 epoches
2020-03-23 21:33:19,165 - RBF - ERROR - loss 1.3094568325810656, in epoch 80, in step 199, in global step 40200, learning rate is 1e-05, taks 27.276999950408936 seconds
2020-03-23 21:33:25,274 - RBF - ERROR - loss 1.309404919786115, in epoch 80, in step 399, in global step 40400, learning rate is 1e-05, taks 6.108999967575073 seconds
2020-03-23 21:33:28,314 - RBF - INFO - train epoch 81 of total 5000 epoches
2020-03-23 21:33:34,381 - RBF - ERROR - loss 1.3093271622075655, in epoch 81, in step 199, in global step 40700, learning rate is 1e-05, taks 9.106000185012817 seconds
2020-03-23 21:33:40,479 - RBF - ERROR - loss 1.3092755401678438, in epoch 81, in step 399, in global step 40900, learning rate is 1e-05, taks 6.097999811172485 seconds
2020-03-23 21:33:43,537 - RBF - INFO - train epoch 82 of total 5000 epoches
2020-03-23 21:33:49,618 - RBF - ERROR - loss 1.3091983701660865, in epoch 82, in step 199, in global step 41200, learning rate is 1e-05, taks 9.138000011444092 seconds
2020-03-23 21:33:55,706 - RBF - ERROR - loss 1.3091470942471208, in epoch 82, in step 399, in global step 41400, learning rate is 1e-05, taks 6.0879998207092285 seconds
2020-03-23 21:33:58,764 - RBF - INFO - train epoch 83 of total 5000 epoches
2020-03-23 21:34:04,873 - RBF - ERROR - loss 1.3090704623940481, in epoch 83, in step 199, in global step 41700, learning rate is 1e-05, taks 9.16700005531311 seconds
2020-03-23 21:34:11,002 - RBF - ERROR - loss 1.3090195946513017, in epoch 83, in step 399, in global step 41900, learning rate is 1e-05, taks 6.128999948501587 seconds
2020-03-23 21:34:14,066 - RBF - INFO - train epoch 84 of total 5000 epoches
2020-03-23 21:34:20,176 - RBF - ERROR - loss 1.3089434856557272, in epoch 84, in step 199, in global step 42200, learning rate is 1e-05, taks 9.17300009727478 seconds
2020-03-23 21:34:26,255 - RBF - ERROR - loss 1.3088929642626124, in epoch 84, in step 399, in global step 42400, learning rate is 1e-05, taks 6.078999757766724 seconds
2020-03-23 21:34:29,309 - RBF - INFO - train epoch 85 of total 5000 epoches
2020-03-23 21:34:35,443 - RBF - ERROR - loss 1.3088174724867376, in epoch 85, in step 199, in global step 42700, learning rate is 1e-05, taks 9.187999963760376 seconds
2020-03-23 21:34:41,551 - RBF - ERROR - loss 1.308767393605723, in epoch 85, in step 399, in global step 42900, learning rate is 1e-05, taks 6.108000040054321 seconds
2020-03-23 21:34:44,596 - RBF - INFO - train epoch 86 of total 5000 epoches
2020-03-23 21:34:50,713 - RBF - ERROR - loss 1.3086924778731688, in epoch 86, in step 199, in global step 43200, learning rate is 1e-05, taks 9.162000179290771 seconds
2020-03-23 21:34:56,783 - RBF - ERROR - loss 1.3086427658237114, in epoch 86, in step 399, in global step 43400, learning rate is 1e-05, taks 6.069000005722046 seconds
2020-03-23 21:34:59,819 - RBF - INFO - train epoch 87 of total 5000 epoches
2020-03-23 21:35:05,977 - RBF - ERROR - loss 1.3085684819259567, in epoch 87, in step 199, in global step 43700, learning rate is 1e-05, taks 9.194000005722046 seconds
2020-03-23 21:35:12,059 - RBF - ERROR - loss 1.308519199015874, in epoch 87, in step 399, in global step 43900, learning rate is 1e-05, taks 6.081999778747559 seconds
2020-03-23 21:35:15,103 - RBF - INFO - train epoch 88 of total 5000 epoches
2020-03-23 21:35:21,035 - RBF - ERROR - loss 1.3084455814465197, in epoch 88, in step 199, in global step 44200, learning rate is 1e-05, taks 8.9760000705719 seconds
2020-03-23 21:35:26,624 - RBF - ERROR - loss 1.3083967270796883, in epoch 88, in step 399, in global step 44400, learning rate is 1e-05, taks 5.589000225067139 seconds
2020-03-23 21:35:29,407 - RBF - INFO - train epoch 89 of total 5000 epoches
2020-03-23 21:35:34,976 - RBF - ERROR - loss 1.3083238131240096, in epoch 89, in step 199, in global step 44700, learning rate is 1e-05, taks 8.351799726486206 seconds
2020-03-23 21:35:40,552 - RBF - ERROR - loss 1.308275398517803, in epoch 89, in step 399, in global step 44900, learning rate is 1e-05, taks 5.575999975204468 seconds
2020-03-23 21:35:43,329 - RBF - INFO - train epoch 90 of total 5000 epoches
2020-03-23 21:35:48,880 - RBF - ERROR - loss 1.3082031536336862, in epoch 90, in step 199, in global step 45200, learning rate is 1e-05, taks 8.32800006866455 seconds
2020-03-23 21:35:54,431 - RBF - ERROR - loss 1.3081552195306982, in epoch 90, in step 399, in global step 45400, learning rate is 1e-05, taks 5.549999952316284 seconds
2020-03-23 21:35:57,226 - RBF - INFO - train epoch 91 of total 5000 epoches
2020-03-23 21:36:02,808 - RBF - ERROR - loss 1.3080836985980482, in epoch 91, in step 199, in global step 45700, learning rate is 1e-05, taks 8.376999855041504 seconds
2020-03-23 21:36:08,395 - RBF - ERROR - loss 1.3080362720441743, in epoch 91, in step 399, in global step 45900, learning rate is 1e-05, taks 5.587000131607056 seconds
2020-03-23 21:36:11,202 - RBF - INFO - train epoch 92 of total 5000 epoches
2020-03-23 21:36:16,778 - RBF - ERROR - loss 1.3079654500869344, in epoch 92, in step 199, in global step 46200, learning rate is 1e-05, taks 8.382000207901001 seconds
2020-03-23 21:36:22,353 - RBF - ERROR - loss 1.3079185024946, in epoch 92, in step 399, in global step 46400, learning rate is 1e-05, taks 5.575000047683716 seconds
2020-03-23 21:36:25,153 - RBF - INFO - train epoch 93 of total 5000 epoches
2020-03-23 21:36:30,729 - RBF - ERROR - loss 1.3078484555769558, in epoch 93, in step 199, in global step 46700, learning rate is 1e-05, taks 8.375999927520752 seconds
2020-03-23 21:36:36,290 - RBF - ERROR - loss 1.3078020281482625, in epoch 93, in step 399, in global step 46900, learning rate is 1e-05, taks 5.560999870300293 seconds
2020-03-23 21:36:39,078 - RBF - INFO - train epoch 94 of total 5000 epoches
2020-03-23 21:36:44,680 - RBF - ERROR - loss 1.3077327428696977, in epoch 94, in step 199, in global step 47200, learning rate is 1e-05, taks 8.389999866485596 seconds
2020-03-23 21:36:50,243 - RBF - ERROR - loss 1.307686820747649, in epoch 94, in step 399, in global step 47400, learning rate is 1e-05, taks 5.563000202178955 seconds
2020-03-23 21:36:53,046 - RBF - INFO - train epoch 95 of total 5000 epoches
2020-03-23 21:36:58,620 - RBF - ERROR - loss 1.3076183667203385, in epoch 95, in step 199, in global step 47700, learning rate is 1e-05, taks 8.375999927520752 seconds
2020-03-23 21:37:04,210 - RBF - ERROR - loss 1.307572944945127, in epoch 95, in step 399, in global step 47900, learning rate is 1e-05, taks 5.58899998664856 seconds
2020-03-23 21:37:07,055 - RBF - INFO - train epoch 96 of total 5000 epoches
2020-03-23 21:37:12,609 - RBF - ERROR - loss 1.3075052690217195, in epoch 96, in step 199, in global step 48200, learning rate is 1e-05, taks 8.39900016784668 seconds
2020-03-23 21:37:18,190 - RBF - ERROR - loss 1.3074604228834115, in epoch 96, in step 399, in global step 48400, learning rate is 1e-05, taks 5.579999923706055 seconds
2020-03-23 21:37:20,993 - RBF - INFO - train epoch 97 of total 5000 epoches
2020-03-23 21:37:26,577 - RBF - ERROR - loss 1.3073935373914587, in epoch 97, in step 199, in global step 48700, learning rate is 1e-05, taks 8.386799812316895 seconds
2020-03-23 21:37:32,140 - RBF - ERROR - loss 1.3073492345151265, in epoch 97, in step 399, in global step 48900, learning rate is 1e-05, taks 5.563199996948242 seconds
2020-03-23 21:37:34,941 - RBF - INFO - train epoch 98 of total 5000 epoches
2020-03-23 21:37:40,526 - RBF - ERROR - loss 1.3072831879828366, in epoch 98, in step 199, in global step 49200, learning rate is 1e-05, taks 8.386000156402588 seconds
2020-03-23 21:37:46,104 - RBF - ERROR - loss 1.3072394309602096, in epoch 98, in step 399, in global step 49400, learning rate is 1e-05, taks 5.57699990272522 seconds
2020-03-23 21:37:48,886 - RBF - INFO - train epoch 99 of total 5000 epoches
2020-03-23 21:37:54,472 - RBF - ERROR - loss 1.3071742201870877, in epoch 99, in step 199, in global step 49700, learning rate is 1e-05, taks 8.366999864578247 seconds
2020-03-23 21:38:00,045 - RBF - ERROR - loss 1.3071310236700076, in epoch 99, in step 399, in global step 49900, learning rate is 1e-05, taks 5.573000192642212 seconds
2020-03-23 21:38:10,316 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 99. learning_rate is 1e-05, loss is 1.3071091583834504
2020-03-23 21:38:10,317 - RBF - INFO - train epoch 100 of total 5000 epoches
2020-03-23 21:38:17,656 - RBF - ERROR - loss 1.3070666536653155, in epoch 100, in step 199, in global step 50200, learning rate is 1e-05, taks 17.610999822616577 seconds
2020-03-23 21:38:22,569 - RBF - ERROR - loss 1.307024025252296, in epoch 100, in step 399, in global step 50400, learning rate is 1e-05, taks 4.913000106811523 seconds
2020-03-23 21:38:24,879 - RBF - INFO - train epoch 101 of total 5000 epoches
2020-03-23 21:38:29,516 - RBF - ERROR - loss 1.3069605050306272, in epoch 101, in step 199, in global step 50700, learning rate is 1e-05, taks 6.94599986076355 seconds
2020-03-23 21:38:34,104 - RBF - ERROR - loss 1.3069184592635839, in epoch 101, in step 399, in global step 50900, learning rate is 1e-05, taks 4.5879998207092285 seconds
2020-03-23 21:38:36,567 - RBF - INFO - train epoch 102 of total 5000 epoches
2020-03-23 21:38:40,883 - RBF - ERROR - loss 1.3068557674845453, in epoch 102, in step 199, in global step 51200, learning rate is 1e-05, taks 6.7790000438690186 seconds
2020-03-23 21:38:45,141 - RBF - ERROR - loss 1.3068142568533645, in epoch 102, in step 399, in global step 51400, learning rate is 1e-05, taks 4.257000207901001 seconds
2020-03-23 21:38:47,209 - RBF - INFO - train epoch 103 of total 5000 epoches
2020-03-23 21:38:51,583 - RBF - ERROR - loss 1.306752431674098, in epoch 103, in step 199, in global step 51700, learning rate is 1e-05, taks 6.441999912261963 seconds
2020-03-23 21:38:55,482 - RBF - ERROR - loss 1.3067115035464807, in epoch 103, in step 399, in global step 51900, learning rate is 1e-05, taks 3.8980002403259277 seconds
2020-03-23 21:38:57,103 - RBF - INFO - train epoch 104 of total 5000 epoches
2020-03-23 21:39:00,475 - RBF - ERROR - loss 1.3066505140983946, in epoch 104, in step 199, in global step 52200, learning rate is 1e-05, taks 4.991999864578247 seconds
2020-03-23 21:39:03,936 - RBF - ERROR - loss 1.30661015733116, in epoch 104, in step 399, in global step 52400, learning rate is 1e-05, taks 3.4609999656677246 seconds
2020-03-23 21:39:06,261 - RBF - INFO - train epoch 105 of total 5000 epoches
2020-03-23 21:39:09,186 - RBF - ERROR - loss 1.306549997985397, in epoch 105, in step 199, in global step 52700, learning rate is 1e-05, taks 5.250000238418579 seconds
2020-03-23 21:39:12,490 - RBF - ERROR - loss 1.30651018444011, in epoch 105, in step 399, in global step 52900, learning rate is 1e-05, taks 3.303999900817871 seconds
2020-03-23 21:39:13,818 - RBF - INFO - train epoch 106 of total 5000 epoches
2020-03-23 21:39:16,526 - RBF - ERROR - loss 1.3064508830198167, in epoch 106, in step 199, in global step 53200, learning rate is 1e-05, taks 4.0350000858306885 seconds
2020-03-23 21:39:19,958 - RBF - ERROR - loss 1.3064116508038082, in epoch 106, in step 399, in global step 53400, learning rate is 1e-05, taks 3.430999994277954 seconds
2020-03-23 21:39:21,481 - RBF - INFO - train epoch 107 of total 5000 epoches
2020-03-23 21:39:24,973 - RBF - ERROR - loss 1.3063532068331545, in epoch 107, in step 199, in global step 53700, learning rate is 1e-05, taks 5.015000104904175 seconds
2020-03-23 21:39:27,738 - RBF - ERROR - loss 1.3063145416749204, in epoch 107, in step 399, in global step 53900, learning rate is 1e-05, taks 2.765000104904175 seconds
2020-03-23 21:39:29,005 - RBF - INFO - train epoch 108 of total 5000 epoches
2020-03-23 21:39:31,561 - RBF - ERROR - loss 1.306256996892064, in epoch 108, in step 199, in global step 54200, learning rate is 1e-05, taks 3.8219997882843018 seconds
2020-03-23 21:39:34,025 - RBF - ERROR - loss 1.3062189392594061, in epoch 108, in step 399, in global step 54400, learning rate is 1e-05, taks 2.4639999866485596 seconds
2020-03-23 21:39:35,249 - RBF - INFO - train epoch 109 of total 5000 epoches
2020-03-23 21:39:37,699 - RBF - ERROR - loss 1.306162315821992, in epoch 109, in step 199, in global step 54700, learning rate is 1e-05, taks 3.672999858856201 seconds
2020-03-23 21:39:40,136 - RBF - ERROR - loss 1.306124874235878, in epoch 109, in step 399, in global step 54900, learning rate is 1e-05, taks 2.437000036239624 seconds
2020-03-23 21:39:41,364 - RBF - INFO - train epoch 110 of total 5000 epoches
2020-03-23 21:39:43,862 - RBF - ERROR - loss 1.3060691662135329, in epoch 110, in step 199, in global step 55200, learning rate is 1e-05, taks 3.7260000705718994 seconds
2020-03-23 21:39:46,404 - RBF - ERROR - loss 1.306032345248906, in epoch 110, in step 399, in global step 55400, learning rate is 1e-05, taks 2.5419998168945312 seconds
2020-03-23 21:39:47,644 - RBF - INFO - train epoch 111 of total 5000 epoches
2020-03-23 21:39:50,094 - RBF - ERROR - loss 1.3059775300930172, in epoch 111, in step 199, in global step 55700, learning rate is 1e-05, taks 3.690000295639038 seconds
2020-03-23 21:39:52,534 - RBF - ERROR - loss 1.3059413072750001, in epoch 111, in step 399, in global step 55900, learning rate is 1e-05, taks 2.438999891281128 seconds
2020-03-23 21:39:53,757 - RBF - INFO - train epoch 112 of total 5000 epoches
2020-03-23 21:39:56,206 - RBF - ERROR - loss 1.3058874032776953, in epoch 112, in step 199, in global step 56200, learning rate is 1e-05, taks 3.671999931335449 seconds
2020-03-23 21:39:58,647 - RBF - ERROR - loss 1.3058517873721667, in epoch 112, in step 399, in global step 56400, learning rate is 1e-05, taks 2.440000057220459 seconds
2020-03-23 21:39:59,867 - RBF - INFO - train epoch 113 of total 5000 epoches
2020-03-23 21:40:02,309 - RBF - ERROR - loss 1.3057988683083785, in epoch 113, in step 199, in global step 56700, learning rate is 1e-05, taks 3.6619999408721924 seconds
2020-03-23 21:40:04,753 - RBF - ERROR - loss 1.3057637451568214, in epoch 113, in step 399, in global step 56900, learning rate is 1e-05, taks 2.443000078201294 seconds
2020-03-23 21:40:05,992 - RBF - INFO - train epoch 114 of total 5000 epoches
2020-03-23 21:40:08,442 - RBF - ERROR - loss 1.3057116378717433, in epoch 114, in step 199, in global step 57200, learning rate is 1e-05, taks 3.689000129699707 seconds
2020-03-23 21:40:10,886 - RBF - ERROR - loss 1.3056771957847737, in epoch 114, in step 399, in global step 57400, learning rate is 1e-05, taks 2.444000005722046 seconds
2020-03-23 21:40:12,108 - RBF - INFO - train epoch 115 of total 5000 epoches
2020-03-23 21:40:14,552 - RBF - ERROR - loss 1.3056259977155589, in epoch 115, in step 199, in global step 57700, learning rate is 1e-05, taks 3.6649997234344482 seconds
2020-03-23 21:40:17,002 - RBF - ERROR - loss 1.30559212114373, in epoch 115, in step 399, in global step 57900, learning rate is 1e-05, taks 2.450000286102295 seconds
2020-03-23 21:40:18,239 - RBF - INFO - train epoch 116 of total 5000 epoches
2020-03-23 21:40:20,697 - RBF - ERROR - loss 1.3055417787963775, in epoch 116, in step 199, in global step 58200, learning rate is 1e-05, taks 3.693999767303467 seconds
2020-03-23 21:40:23,139 - RBF - ERROR - loss 1.3055085038537504, in epoch 116, in step 399, in global step 58400, learning rate is 1e-05, taks 2.441999912261963 seconds
2020-03-23 21:40:24,359 - RBF - INFO - train epoch 117 of total 5000 epoches
2020-03-23 21:40:26,803 - RBF - ERROR - loss 1.3054590358073992, in epoch 117, in step 199, in global step 58700, learning rate is 1e-05, taks 3.6640000343322754 seconds
2020-03-23 21:40:29,262 - RBF - ERROR - loss 1.3054263436119666, in epoch 117, in step 399, in global step 58900, learning rate is 1e-05, taks 2.4590001106262207 seconds
2020-03-23 21:40:30,486 - RBF - INFO - train epoch 118 of total 5000 epoches
2020-03-23 21:40:32,935 - RBF - ERROR - loss 1.305377738357369, in epoch 118, in step 199, in global step 59200, learning rate is 1e-05, taks 3.672999858856201 seconds
2020-03-23 21:40:35,423 - RBF - ERROR - loss 1.3053456269939083, in epoch 118, in step 399, in global step 59400, learning rate is 1e-05, taks 2.4880001544952393 seconds
2020-03-23 21:40:36,651 - RBF - INFO - train epoch 119 of total 5000 epoches
2020-03-23 21:40:39,087 - RBF - ERROR - loss 1.3052978926649126, in epoch 119, in step 199, in global step 59700, learning rate is 1e-05, taks 3.6639997959136963 seconds
2020-03-23 21:40:41,524 - RBF - ERROR - loss 1.3052663655912087, in epoch 119, in step 399, in global step 59900, learning rate is 1e-05, taks 2.437000036239624 seconds
2020-03-23 21:40:49,407 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 119. learning_rate is 1e-05, loss is 1.3052503286251531
2020-03-23 21:40:49,410 - RBF - INFO - train epoch 120 of total 5000 epoches
2020-03-23 21:40:56,470 - RBF - ERROR - loss 1.305219489549667, in epoch 120, in step 199, in global step 60200, learning rate is 1e-05, taks 14.945800065994263 seconds
2020-03-23 21:41:02,494 - RBF - ERROR - loss 1.3051885065859246, in epoch 120, in step 399, in global step 60400, learning rate is 1e-05, taks 6.023000001907349 seconds
2020-03-23 21:41:05,528 - RBF - INFO - train epoch 121 of total 5000 epoches
2020-03-23 21:41:11,594 - RBF - ERROR - loss 1.3051424771354514, in epoch 121, in step 199, in global step 60700, learning rate is 1e-05, taks 9.099999904632568 seconds
2020-03-23 21:41:17,669 - RBF - ERROR - loss 1.3051120520778898, in epoch 121, in step 399, in global step 60900, learning rate is 1e-05, taks 6.073999881744385 seconds
2020-03-23 21:41:20,406 - RBF - INFO - train epoch 122 of total 5000 epoches
2020-03-23 21:41:25,414 - RBF - ERROR - loss 1.3050668653439585, in epoch 122, in step 199, in global step 61200, learning rate is 1e-05, taks 7.745000123977661 seconds
2020-03-23 21:41:30,441 - RBF - ERROR - loss 1.3050370261536717, in epoch 122, in step 399, in global step 61400, learning rate is 1e-05, taks 5.0269999504089355 seconds
2020-03-23 21:41:32,932 - RBF - INFO - train epoch 123 of total 5000 epoches
2020-03-23 21:41:37,914 - RBF - ERROR - loss 1.3049926873444673, in epoch 123, in step 199, in global step 61700, learning rate is 1e-05, taks 7.4730000495910645 seconds
2020-03-23 21:41:42,813 - RBF - ERROR - loss 1.3049634053123873, in epoch 123, in step 399, in global step 61900, learning rate is 1e-05, taks 4.898999929428101 seconds
2020-03-23 21:41:45,290 - RBF - INFO - train epoch 124 of total 5000 epoches
2020-03-23 21:41:50,152 - RBF - ERROR - loss 1.3049199385102044, in epoch 124, in step 199, in global step 62200, learning rate is 1e-05, taks 7.33899998664856 seconds
2020-03-23 21:41:55,137 - RBF - ERROR - loss 1.3048912086871354, in epoch 124, in step 399, in global step 62400, learning rate is 1e-05, taks 4.984999895095825 seconds
2020-03-23 21:41:57,600 - RBF - INFO - train epoch 125 of total 5000 epoches
2020-03-23 21:42:02,532 - RBF - ERROR - loss 1.304848518595241, in epoch 125, in step 199, in global step 62700, learning rate is 1e-05, taks 7.394000291824341 seconds
2020-03-23 21:42:07,566 - RBF - ERROR - loss 1.3048203481554703, in epoch 125, in step 399, in global step 62900, learning rate is 1e-05, taks 5.0340001583099365 seconds
2020-03-23 21:42:10,067 - RBF - INFO - train epoch 126 of total 5000 epoches
2020-03-23 21:42:14,995 - RBF - ERROR - loss 1.3047785024009022, in epoch 126, in step 199, in global step 63200, learning rate is 1e-05, taks 7.428999900817871 seconds
2020-03-23 21:42:19,945 - RBF - ERROR - loss 1.3047508760868938, in epoch 126, in step 399, in global step 63400, learning rate is 1e-05, taks 4.949999809265137 seconds
2020-03-23 21:42:22,447 - RBF - INFO - train epoch 127 of total 5000 epoches
2020-03-23 21:42:27,414 - RBF - ERROR - loss 1.3047098417511729, in epoch 127, in step 199, in global step 63700, learning rate is 1e-05, taks 7.469200134277344 seconds
2020-03-23 21:42:32,529 - RBF - ERROR - loss 1.3046827478410976, in epoch 127, in step 399, in global step 63900, learning rate is 1e-05, taks 5.1143999099731445 seconds
2020-03-23 21:42:35,014 - RBF - INFO - train epoch 128 of total 5000 epoches
2020-03-23 21:42:39,804 - RBF - ERROR - loss 1.3046425089870513, in epoch 128, in step 199, in global step 64200, learning rate is 1e-05, taks 7.2758002281188965 seconds
2020-03-23 21:42:44,582 - RBF - ERROR - loss 1.304615948540028, in epoch 128, in step 399, in global step 64400, learning rate is 1e-05, taks 4.7779998779296875 seconds
2020-03-23 21:42:46,986 - RBF - INFO - train epoch 129 of total 5000 epoches
2020-03-23 21:42:51,972 - RBF - ERROR - loss 1.3045765599706491, in epoch 129, in step 199, in global step 64700, learning rate is 1e-05, taks 7.390000104904175 seconds
2020-03-23 21:42:57,026 - RBF - ERROR - loss 1.3045504574741158, in epoch 129, in step 399, in global step 64900, learning rate is 1e-05, taks 5.053999900817871 seconds
2020-03-23 21:42:59,539 - RBF - INFO - train epoch 130 of total 5000 epoches
2020-03-23 21:43:04,582 - RBF - ERROR - loss 1.3045117971438067, in epoch 130, in step 199, in global step 65200, learning rate is 1e-05, taks 7.555999994277954 seconds
2020-03-23 21:43:09,512 - RBF - ERROR - loss 1.3044862621858844, in epoch 130, in step 399, in global step 65400, learning rate is 1e-05, taks 4.930000066757202 seconds
2020-03-23 21:43:11,940 - RBF - INFO - train epoch 131 of total 5000 epoches
2020-03-23 21:43:17,059 - RBF - ERROR - loss 1.304448392711754, in epoch 131, in step 199, in global step 65700, learning rate is 1e-05, taks 7.54699969291687 seconds
2020-03-23 21:43:21,960 - RBF - ERROR - loss 1.3044233438441524, in epoch 131, in step 399, in global step 65900, learning rate is 1e-05, taks 4.901000261306763 seconds
2020-03-23 21:43:24,341 - RBF - INFO - train epoch 132 of total 5000 epoches
2020-03-23 21:43:29,203 - RBF - ERROR - loss 1.3043863050878806, in epoch 132, in step 199, in global step 66200, learning rate is 1e-05, taks 7.241999864578247 seconds
2020-03-23 21:43:34,254 - RBF - ERROR - loss 1.3043616829423945, in epoch 132, in step 399, in global step 66400, learning rate is 1e-05, taks 5.051000118255615 seconds
2020-03-23 21:43:36,779 - RBF - INFO - train epoch 133 of total 5000 epoches
2020-03-23 21:43:41,705 - RBF - ERROR - loss 1.304325307779294, in epoch 133, in step 199, in global step 66700, learning rate is 1e-05, taks 7.450999975204468 seconds
2020-03-23 21:43:46,646 - RBF - ERROR - loss 1.3043012768450586, in epoch 133, in step 399, in global step 66900, learning rate is 1e-05, taks 4.940999984741211 seconds
2020-03-23 21:43:49,056 - RBF - INFO - train epoch 134 of total 5000 epoches
2020-03-23 21:43:53,830 - RBF - ERROR - loss 1.304265611782181, in epoch 134, in step 199, in global step 67200, learning rate is 1e-05, taks 7.183000087738037 seconds
2020-03-23 21:43:58,596 - RBF - ERROR - loss 1.3042420851343242, in epoch 134, in step 399, in global step 67400, learning rate is 1e-05, taks 4.766000032424927 seconds
2020-03-23 21:44:01,003 - RBF - INFO - train epoch 135 of total 5000 epoches
2020-03-23 21:44:05,782 - RBF - ERROR - loss 1.3042071469563412, in epoch 135, in step 199, in global step 67700, learning rate is 1e-05, taks 7.186000108718872 seconds
2020-03-23 21:44:10,586 - RBF - ERROR - loss 1.3041841047416367, in epoch 135, in step 399, in global step 67900, learning rate is 1e-05, taks 4.803999900817871 seconds
2020-03-23 21:44:12,976 - RBF - INFO - train epoch 136 of total 5000 epoches
2020-03-23 21:44:17,760 - RBF - ERROR - loss 1.3041498799867348, in epoch 136, in step 199, in global step 68200, learning rate is 1e-05, taks 7.174000024795532 seconds
2020-03-23 21:44:22,543 - RBF - ERROR - loss 1.304127338729518, in epoch 136, in step 399, in global step 68400, learning rate is 1e-05, taks 4.7829999923706055 seconds
2020-03-23 21:44:24,949 - RBF - INFO - train epoch 137 of total 5000 epoches
2020-03-23 21:44:29,752 - RBF - ERROR - loss 1.3040937928357812, in epoch 137, in step 199, in global step 68700, learning rate is 1e-05, taks 7.209000110626221 seconds
2020-03-23 21:44:34,252 - RBF - ERROR - loss 1.3040716823612473, in epoch 137, in step 399, in global step 68900, learning rate is 1e-05, taks 4.498999834060669 seconds
2020-03-23 21:44:36,493 - RBF - INFO - train epoch 138 of total 5000 epoches
2020-03-23 21:44:41,164 - RBF - ERROR - loss 1.30403886896957, in epoch 138, in step 199, in global step 69200, learning rate is 1e-05, taks 6.911999940872192 seconds
2020-03-23 21:44:45,441 - RBF - ERROR - loss 1.3040172103678893, in epoch 138, in step 399, in global step 69400, learning rate is 1e-05, taks 4.2769999504089355 seconds
2020-03-23 21:44:47,586 - RBF - INFO - train epoch 139 of total 5000 epoches
2020-03-23 21:44:51,781 - RBF - ERROR - loss 1.3039850731964358, in epoch 139, in step 199, in global step 69700, learning rate is 1e-05, taks 6.3399999141693115 seconds
2020-03-23 21:44:55,904 - RBF - ERROR - loss 1.3039638742522643, in epoch 139, in step 399, in global step 69900, learning rate is 1e-05, taks 4.121999979019165 seconds
2020-03-23 21:45:09,398 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 139. learning_rate is 1e-05, loss is 1.3039530385176834
2020-03-23 21:45:09,399 - RBF - INFO - train epoch 140 of total 5000 epoches
2020-03-23 21:45:16,726 - RBF - ERROR - loss 1.3039324001199626, in epoch 140, in step 199, in global step 70200, learning rate is 1e-05, taks 20.821799993515015 seconds
2020-03-23 21:45:22,180 - RBF - ERROR - loss 1.3039116674515396, in epoch 140, in step 399, in global step 70400, learning rate is 1e-05, taks 5.454200029373169 seconds
2020-03-23 21:45:24,409 - RBF - INFO - train epoch 141 of total 5000 epoches
2020-03-23 21:45:28,884 - RBF - ERROR - loss 1.3038808332270475, in epoch 141, in step 199, in global step 70700, learning rate is 1e-05, taks 6.703999996185303 seconds
2020-03-23 21:45:33,336 - RBF - ERROR - loss 1.3038605013705666, in epoch 141, in step 399, in global step 70900, learning rate is 1e-05, taks 4.450999975204468 seconds
2020-03-23 21:45:35,572 - RBF - INFO - train epoch 142 of total 5000 epoches
2020-03-23 21:45:40,114 - RBF - ERROR - loss 1.3038303522413646, in epoch 142, in step 199, in global step 71200, learning rate is 1e-05, taks 6.7779998779296875 seconds
2020-03-23 21:45:44,590 - RBF - ERROR - loss 1.3038104312957857, in epoch 142, in step 399, in global step 71400, learning rate is 1e-05, taks 4.476000070571899 seconds
2020-03-23 21:45:46,816 - RBF - INFO - train epoch 143 of total 5000 epoches
2020-03-23 21:45:51,368 - RBF - ERROR - loss 1.3037809114608032, in epoch 143, in step 199, in global step 71700, learning rate is 1e-05, taks 6.778000116348267 seconds
2020-03-23 21:45:55,882 - RBF - ERROR - loss 1.3037614135789952, in epoch 143, in step 399, in global step 71900, learning rate is 1e-05, taks 4.513999938964844 seconds
2020-03-23 21:45:58,184 - RBF - INFO - train epoch 144 of total 5000 epoches
2020-03-23 21:46:02,757 - RBF - ERROR - loss 1.3037324904331262, in epoch 144, in step 199, in global step 72200, learning rate is 1e-05, taks 6.875 seconds
2020-03-23 21:46:07,425 - RBF - ERROR - loss 1.3037134277864963, in epoch 144, in step 399, in global step 72400, learning rate is 1e-05, taks 4.667999982833862 seconds
2020-03-23 21:46:09,672 - RBF - INFO - train epoch 145 of total 5000 epoches
2020-03-23 21:46:14,133 - RBF - ERROR - loss 1.303685126608958, in epoch 145, in step 199, in global step 72700, learning rate is 1e-05, taks 6.70799994468689 seconds
2020-03-23 21:46:18,670 - RBF - ERROR - loss 1.3036664254616015, in epoch 145, in step 399, in global step 72900, learning rate is 1e-05, taks 4.536999940872192 seconds
2020-03-23 21:46:21,049 - RBF - INFO - train epoch 146 of total 5000 epoches
2020-03-23 21:46:25,568 - RBF - ERROR - loss 1.3036387203118573, in epoch 146, in step 199, in global step 73200, learning rate is 1e-05, taks 6.898000240325928 seconds
2020-03-23 21:46:30,056 - RBF - ERROR - loss 1.3036204169904722, in epoch 146, in step 399, in global step 73400, learning rate is 1e-05, taks 4.48799991607666 seconds
2020-03-23 21:46:32,346 - RBF - INFO - train epoch 147 of total 5000 epoches
2020-03-23 21:46:36,839 - RBF - ERROR - loss 1.3035932769632375, in epoch 147, in step 199, in global step 73700, learning rate is 1e-05, taks 6.782199859619141 seconds
2020-03-23 21:46:40,937 - RBF - ERROR - loss 1.3035753760971924, in epoch 147, in step 399, in global step 73900, learning rate is 1e-05, taks 4.096999883651733 seconds
2020-03-23 21:46:43,042 - RBF - INFO - train epoch 148 of total 5000 epoches
2020-03-23 21:46:47,107 - RBF - ERROR - loss 1.3035488386842016, in epoch 148, in step 199, in global step 74200, learning rate is 1e-05, taks 6.169000148773193 seconds
2020-03-23 21:46:51,105 - RBF - ERROR - loss 1.3035312635444902, in epoch 148, in step 399, in global step 74400, learning rate is 1e-05, taks 3.996999979019165 seconds
2020-03-23 21:46:53,186 - RBF - INFO - train epoch 149 of total 5000 epoches
2020-03-23 21:46:57,491 - RBF - ERROR - loss 1.3035052339536168, in epoch 149, in step 199, in global step 74700, learning rate is 1e-05, taks 6.384999752044678 seconds
2020-03-23 21:47:01,797 - RBF - ERROR - loss 1.3034881025356284, in epoch 149, in step 399, in global step 74900, learning rate is 1e-05, taks 4.305000066757202 seconds
2020-03-23 21:47:03,820 - RBF - INFO - train epoch 150 of total 5000 epoches
2020-03-23 21:47:07,865 - RBF - ERROR - loss 1.303462584697177, in epoch 150, in step 199, in global step 75200, learning rate is 1e-05, taks 6.067000150680542 seconds
2020-03-23 21:47:11,856 - RBF - ERROR - loss 1.3034457486262065, in epoch 150, in step 399, in global step 75400, learning rate is 1e-05, taks 3.990999937057495 seconds
2020-03-23 21:47:13,846 - RBF - INFO - train epoch 151 of total 5000 epoches
2020-03-23 21:47:17,838 - RBF - ERROR - loss 1.3034207872412418, in epoch 151, in step 199, in global step 75700, learning rate is 1e-05, taks 5.98199987411499 seconds
2020-03-23 21:47:21,844 - RBF - ERROR - loss 1.3034042984885925, in epoch 151, in step 399, in global step 75900, learning rate is 1e-05, taks 4.00600004196167 seconds
2020-03-23 21:47:23,845 - RBF - INFO - train epoch 152 of total 5000 epoches
2020-03-23 21:47:27,859 - RBF - ERROR - loss 1.303379836010008, in epoch 152, in step 199, in global step 76200, learning rate is 1e-05, taks 6.014999866485596 seconds
2020-03-23 21:47:31,859 - RBF - ERROR - loss 1.3033637009539372, in epoch 152, in step 399, in global step 76400, learning rate is 1e-05, taks 4.0 seconds
2020-03-23 21:47:33,841 - RBF - INFO - train epoch 153 of total 5000 epoches
2020-03-23 21:47:37,869 - RBF - ERROR - loss 1.3033397307775265, in epoch 153, in step 199, in global step 76700, learning rate is 1e-05, taks 6.010000228881836 seconds
2020-03-23 21:47:41,863 - RBF - ERROR - loss 1.3033239142873076, in epoch 153, in step 399, in global step 76900, learning rate is 1e-05, taks 3.993999719619751 seconds
2020-03-23 21:47:43,856 - RBF - INFO - train epoch 154 of total 5000 epoches
2020-03-23 21:47:47,855 - RBF - ERROR - loss 1.3033004322256792, in epoch 154, in step 199, in global step 77200, learning rate is 1e-05, taks 5.990999698638916 seconds
2020-03-23 21:47:51,860 - RBF - ERROR - loss 1.303284960352327, in epoch 154, in step 399, in global step 77400, learning rate is 1e-05, taks 4.005000114440918 seconds
2020-03-23 21:47:53,871 - RBF - INFO - train epoch 155 of total 5000 epoches
2020-03-23 21:47:57,955 - RBF - ERROR - loss 1.3032619224514073, in epoch 155, in step 199, in global step 77700, learning rate is 1e-05, taks 6.09499979019165 seconds
2020-03-23 21:48:01,954 - RBF - ERROR - loss 1.3032467324857788, in epoch 155, in step 399, in global step 77900, learning rate is 1e-05, taks 3.999000072479248 seconds
2020-03-23 21:48:03,946 - RBF - INFO - train epoch 156 of total 5000 epoches
2020-03-23 21:48:07,962 - RBF - ERROR - loss 1.3032242195196797, in epoch 156, in step 199, in global step 78200, learning rate is 1e-05, taks 6.008000135421753 seconds
2020-03-23 21:48:11,991 - RBF - ERROR - loss 1.3032092772650101, in epoch 156, in step 399, in global step 78400, learning rate is 1e-05, taks 4.0289998054504395 seconds
2020-03-23 21:48:13,987 - RBF - INFO - train epoch 157 of total 5000 epoches
2020-03-23 21:48:17,552 - RBF - ERROR - loss 1.3031871610197319, in epoch 157, in step 199, in global step 78700, learning rate is 1e-05, taks 5.561000347137451 seconds
2020-03-23 21:48:20,974 - RBF - ERROR - loss 1.3031725605126991, in epoch 157, in step 399, in global step 78900, learning rate is 1e-05, taks 3.42199969291687 seconds
2020-03-23 21:48:22,683 - RBF - INFO - train epoch 158 of total 5000 epoches
2020-03-23 21:48:26,127 - RBF - ERROR - loss 1.3031508412947788, in epoch 158, in step 199, in global step 79200, learning rate is 1e-05, taks 5.153000116348267 seconds
2020-03-23 21:48:29,557 - RBF - ERROR - loss 1.3031365256337981, in epoch 158, in step 399, in global step 79400, learning rate is 1e-05, taks 3.430000066757202 seconds
2020-03-23 21:48:31,267 - RBF - INFO - train epoch 159 of total 5000 epoches
2020-03-23 21:48:34,691 - RBF - ERROR - loss 1.3031152082691013, in epoch 159, in step 199, in global step 79700, learning rate is 1e-05, taks 5.132999897003174 seconds
2020-03-23 21:48:38,106 - RBF - ERROR - loss 1.3031011650750668, in epoch 159, in step 399, in global step 79900, learning rate is 1e-05, taks 3.4150002002716064 seconds
2020-03-23 21:48:56,939 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 159. learning_rate is 1e-05, loss is 1.3030938652692123
2020-03-23 21:48:56,940 - RBF - INFO - train epoch 160 of total 5000 epoches
2020-03-24 09:19:01,840 - RBF - INFO - now initialize the net with para:
2020-03-24 09:19:01,840 - RBF - INFO - clip
2020-03-24 09:19:01,840 - RBF - INFO - False
2020-03-24 09:19:01,840 - RBF - INFO - -----------------------------
2020-03-24 09:19:01,841 - RBF - INFO - CKPT
2020-03-24 09:19:01,841 - RBF - INFO - ckpt
2020-03-24 09:19:01,841 - RBF - INFO - -----------------------------
2020-03-24 09:19:01,841 - RBF - INFO - BATCHSIZE
2020-03-24 09:19:01,841 - RBF - INFO - 1000
2020-03-24 09:19:01,841 - RBF - INFO - -----------------------------
2020-03-24 09:19:01,841 - RBF - INFO - MAX_ITER
2020-03-24 09:19:01,841 - RBF - INFO - 5000
2020-03-24 09:19:01,841 - RBF - INFO - -----------------------------
2020-03-24 09:19:01,841 - RBF - INFO - STEP_EACH_ITER
2020-03-24 09:19:01,841 - RBF - INFO - 500
2020-03-24 09:19:01,842 - RBF - INFO - -----------------------------
2020-03-24 09:19:01,842 - RBF - INFO - STEP_SHOW
2020-03-24 09:19:01,842 - RBF - INFO - 200
2020-03-24 09:19:01,842 - RBF - INFO - -----------------------------
2020-03-24 09:19:01,842 - RBF - INFO - EPOCH_SAVE
2020-03-24 09:19:01,842 - RBF - INFO - 20
2020-03-24 09:19:01,842 - RBF - INFO - -----------------------------
2020-03-24 09:19:01,842 - RBF - INFO - LEARNING_RATE
2020-03-24 09:19:01,842 - RBF - INFO - 8e-05
2020-03-24 09:19:01,842 - RBF - INFO - -----------------------------
2020-03-24 09:19:01,842 - RBF - INFO - bound_weight
2020-03-24 09:19:01,843 - RBF - INFO - 1
2020-03-24 09:19:01,843 - RBF - INFO - -----------------------------
2020-03-24 09:19:01,843 - RBF - INFO - step_unbound
2020-03-24 09:19:01,843 - RBF - INFO - 5
2020-03-24 09:19:01,843 - RBF - INFO - -----------------------------
2020-03-24 09:19:01,843 - RBF - INFO - decay
2020-03-24 09:19:01,843 - RBF - INFO - False
2020-03-24 09:19:01,843 - RBF - INFO - -----------------------------
2020-03-24 09:19:01,843 - RBF - INFO - test_line
2020-03-24 09:19:01,843 - RBF - INFO - False
2020-03-24 09:19:01,843 - RBF - INFO - -----------------------------
2020-03-24 09:19:01,843 - RBF - INFO - is_plot
2020-03-24 09:19:01,844 - RBF - INFO - True
2020-03-24 09:19:01,844 - RBF - INFO - -----------------------------
2020-03-24 09:19:01,880 - RBF - INFO - openning sess
2020-03-24 09:19:06,989 - RBF - INFO - building net
2020-03-24 09:19:12,249 - RBF - INFO - building opt
2020-03-24 09:19:13,175 - RBF - INFO - net initializing
2020-03-24 09:19:13,175 - RBF - INFO - train epoch 0 of total 5000 epoches
2020-03-24 09:19:16,031 - RBF - ERROR - loss 1.1180104542559144, in epoch 0, in step 199, in global step 200, learning rate is 8e-05, taks 2.8559999465942383 seconds
2020-03-24 09:19:17,159 - RBF - ERROR - loss 1.0448883133244746, in epoch 0, in step 399, in global step 400, learning rate is 8e-05, taks 1.128000020980835 seconds
2020-03-24 09:19:17,738 - RBF - INFO - train epoch 1 of total 5000 epoches
2020-03-24 09:19:18,919 - RBF - ERROR - loss 0.9453943556325644, in epoch 1, in step 199, in global step 700, learning rate is 8e-05, taks 1.7599999904632568 seconds
2020-03-24 09:19:20,134 - RBF - ERROR - loss 0.8820451311167868, in epoch 1, in step 399, in global step 900, learning rate is 8e-05, taks 1.2150001525878906 seconds
2020-03-24 09:19:20,735 - RBF - INFO - train epoch 2 of total 5000 epoches
2020-03-24 09:19:21,912 - RBF - ERROR - loss 0.7870531443060198, in epoch 2, in step 199, in global step 1200, learning rate is 8e-05, taks 1.7769999504089355 seconds
2020-03-24 09:19:22,987 - RBF - ERROR - loss 0.7220773841410897, in epoch 2, in step 399, in global step 1400, learning rate is 8e-05, taks 1.0750000476837158 seconds
2020-03-24 09:19:23,531 - RBF - INFO - train epoch 3 of total 5000 epoches
2020-03-24 09:19:24,617 - RBF - ERROR - loss 0.6196495529610704, in epoch 3, in step 199, in global step 1700, learning rate is 8e-05, taks 1.630000114440918 seconds
2020-03-24 09:19:25,706 - RBF - ERROR - loss 0.5479731778308037, in epoch 3, in step 399, in global step 1900, learning rate is 8e-05, taks 1.0889999866485596 seconds
2020-03-24 09:19:26,255 - RBF - INFO - train epoch 4 of total 5000 epoches
2020-03-24 09:19:27,379 - RBF - ERROR - loss 0.4385087683141842, in epoch 4, in step 199, in global step 2200, learning rate is 8e-05, taks 1.6719999313354492 seconds
2020-03-24 09:19:28,488 - RBF - ERROR - loss 0.3674342316960084, in epoch 4, in step 399, in global step 2400, learning rate is 8e-05, taks 1.1089999675750732 seconds
2020-03-24 09:19:29,043 - RBF - INFO - train epoch 5 of total 5000 epoches
2020-03-24 09:19:30,156 - RBF - ERROR - loss 0.27003877771874857, in epoch 5, in step 199, in global step 2700, learning rate is 8e-05, taks 1.6669998168945312 seconds
2020-03-24 09:19:31,276 - RBF - ERROR - loss 0.21428853908131737, in epoch 5, in step 399, in global step 2900, learning rate is 8e-05, taks 1.119999885559082 seconds
2020-03-24 09:19:31,836 - RBF - INFO - train epoch 6 of total 5000 epoches
2020-03-24 09:19:32,954 - RBF - ERROR - loss 0.14727821491929594, in epoch 6, in step 199, in global step 3200, learning rate is 8e-05, taks 1.6780002117156982 seconds
2020-03-24 09:19:34,066 - RBF - ERROR - loss 0.11389906544614656, in epoch 6, in step 399, in global step 3400, learning rate is 8e-05, taks 1.1119999885559082 seconds
2020-03-24 09:19:34,633 - RBF - INFO - train epoch 7 of total 5000 epoches
2020-03-24 09:19:35,745 - RBF - ERROR - loss 0.07906170160023346, in epoch 7, in step 199, in global step 3700, learning rate is 8e-05, taks 1.6790001392364502 seconds
2020-03-24 09:19:36,857 - RBF - ERROR - loss 0.06415543578339866, in epoch 7, in step 399, in global step 3900, learning rate is 8e-05, taks 1.1119999885559082 seconds
2020-03-24 09:19:37,413 - RBF - INFO - train epoch 8 of total 5000 epoches
2020-03-24 09:19:38,531 - RBF - ERROR - loss 0.05056126032790053, in epoch 8, in step 199, in global step 4200, learning rate is 8e-05, taks 1.6739997863769531 seconds
2020-03-24 09:19:39,646 - RBF - ERROR - loss 0.04530263368181034, in epoch 8, in step 399, in global step 4400, learning rate is 8e-05, taks 1.1150000095367432 seconds
2020-03-24 09:19:40,207 - RBF - INFO - train epoch 9 of total 5000 epoches
2020-03-24 09:19:41,325 - RBF - ERROR - loss 0.04042508121114983, in epoch 9, in step 199, in global step 4700, learning rate is 8e-05, taks 1.6780002117156982 seconds
2020-03-24 09:19:42,440 - RBF - ERROR - loss 0.038178327388510624, in epoch 9, in step 399, in global step 4900, learning rate is 8e-05, taks 1.114999771118164 seconds
2020-03-24 09:19:43,004 - RBF - INFO - train epoch 10 of total 5000 epoches
2020-03-24 09:19:44,117 - RBF - ERROR - loss 0.03541630168928899, in epoch 10, in step 199, in global step 5200, learning rate is 8e-05, taks 1.6770002841949463 seconds
2020-03-24 09:19:45,229 - RBF - ERROR - loss 0.03376082508284761, in epoch 10, in step 399, in global step 5400, learning rate is 8e-05, taks 1.1119999885559082 seconds
2020-03-24 09:19:45,783 - RBF - INFO - train epoch 11 of total 5000 epoches
2020-03-24 09:19:46,894 - RBF - ERROR - loss 0.03142522585806236, in epoch 11, in step 199, in global step 5700, learning rate is 8e-05, taks 1.6649999618530273 seconds
2020-03-24 09:19:48,005 - RBF - ERROR - loss 0.029945927833823587, in epoch 11, in step 399, in global step 5900, learning rate is 8e-05, taks 1.1110000610351562 seconds
2020-03-24 09:19:48,567 - RBF - INFO - train epoch 12 of total 5000 epoches
2020-03-24 09:19:49,686 - RBF - ERROR - loss 0.027796261982481574, in epoch 12, in step 199, in global step 6200, learning rate is 8e-05, taks 1.680999994277954 seconds
2020-03-24 09:19:50,800 - RBF - ERROR - loss 0.02600770064699477, in epoch 12, in step 399, in global step 6400, learning rate is 8e-05, taks 1.113999843597412 seconds
2020-03-24 09:19:51,358 - RBF - INFO - train epoch 13 of total 5000 epoches
2020-03-24 09:19:52,480 - RBF - ERROR - loss 0.022433174501920835, in epoch 13, in step 199, in global step 6700, learning rate is 8e-05, taks 1.679999828338623 seconds
2020-03-24 09:19:53,613 - RBF - ERROR - loss 0.020444869836844046, in epoch 13, in step 399, in global step 6900, learning rate is 8e-05, taks 1.133000373840332 seconds
2020-03-24 09:19:54,168 - RBF - INFO - train epoch 14 of total 5000 epoches
2020-03-24 09:19:55,281 - RBF - ERROR - loss 0.018045924484700306, in epoch 14, in step 199, in global step 7200, learning rate is 8e-05, taks 1.6679999828338623 seconds
2020-03-24 09:19:56,425 - RBF - ERROR - loss 0.01670931805843987, in epoch 14, in step 399, in global step 7400, learning rate is 8e-05, taks 1.1429996490478516 seconds
2020-03-24 09:19:56,979 - RBF - INFO - train epoch 15 of total 5000 epoches
2020-03-24 09:19:58,098 - RBF - ERROR - loss 0.01496466415943881, in epoch 15, in step 199, in global step 7700, learning rate is 8e-05, taks 1.6730000972747803 seconds
2020-03-24 09:19:59,211 - RBF - ERROR - loss 0.013928675341820745, in epoch 15, in step 399, in global step 7900, learning rate is 8e-05, taks 1.1129999160766602 seconds
2020-03-24 09:19:59,775 - RBF - INFO - train epoch 16 of total 5000 epoches
2020-03-24 09:20:00,894 - RBF - ERROR - loss 0.012522810759468579, in epoch 16, in step 199, in global step 8200, learning rate is 8e-05, taks 1.683000087738037 seconds
2020-03-24 09:20:02,009 - RBF - ERROR - loss 0.011667869093268076, in epoch 16, in step 399, in global step 8400, learning rate is 8e-05, taks 1.1150000095367432 seconds
2020-03-24 09:20:02,567 - RBF - INFO - train epoch 17 of total 5000 epoches
2020-03-24 09:20:03,685 - RBF - ERROR - loss 0.010489165815220237, in epoch 17, in step 199, in global step 8700, learning rate is 8e-05, taks 1.6760001182556152 seconds
2020-03-24 09:20:04,811 - RBF - ERROR - loss 0.009764877898853002, in epoch 17, in step 399, in global step 8900, learning rate is 8e-05, taks 1.1259996891021729 seconds
2020-03-24 09:20:05,365 - RBF - INFO - train epoch 18 of total 5000 epoches
2020-03-24 09:20:06,481 - RBF - ERROR - loss 0.008761100143966824, in epoch 18, in step 199, in global step 9200, learning rate is 8e-05, taks 1.6700003147125244 seconds
2020-03-24 09:20:07,597 - RBF - ERROR - loss 0.008142778264777393, in epoch 18, in step 399, in global step 9400, learning rate is 8e-05, taks 1.1159999370574951 seconds
2020-03-24 09:20:08,159 - RBF - INFO - train epoch 19 of total 5000 epoches
2020-03-24 09:20:09,280 - RBF - ERROR - loss 0.007285689173972001, in epoch 19, in step 199, in global step 9700, learning rate is 8e-05, taks 1.682999849319458 seconds
2020-03-24 09:20:10,391 - RBF - ERROR - loss 0.006758297618350605, in epoch 19, in step 399, in global step 9900, learning rate is 8e-05, taks 1.1110000610351562 seconds
2020-03-24 09:20:18,742 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 19. learning_rate is 8e-05, loss is 0.006504616821406027
2020-03-24 09:20:18,744 - RBF - INFO - train epoch 20 of total 5000 epoches
2020-03-24 09:20:22,383 - RBF - ERROR - loss 0.006028408926151719, in epoch 20, in step 199, in global step 10200, learning rate is 8e-05, taks 11.991999864578247 seconds
2020-03-24 09:20:25,253 - RBF - ERROR - loss 0.005580172436802422, in epoch 20, in step 399, in global step 10400, learning rate is 8e-05, taks 2.870000123977661 seconds
2020-03-24 09:20:26,714 - RBF - INFO - train epoch 21 of total 5000 epoches
2020-03-24 09:20:29,593 - RBF - ERROR - loss 0.004961352561265626, in epoch 21, in step 199, in global step 10700, learning rate is 8e-05, taks 4.340000152587891 seconds
2020-03-24 09:20:32,481 - RBF - ERROR - loss 0.004582262715353638, in epoch 21, in step 399, in global step 10900, learning rate is 8e-05, taks 2.888000011444092 seconds
2020-03-24 09:20:33,912 - RBF - INFO - train epoch 22 of total 5000 epoches
2020-03-24 09:20:36,805 - RBF - ERROR - loss 0.004063590561114447, in epoch 22, in step 199, in global step 11200, learning rate is 8e-05, taks 4.323999881744385 seconds
2020-03-24 09:20:39,691 - RBF - ERROR - loss 0.0037513053668639562, in epoch 22, in step 399, in global step 11400, learning rate is 8e-05, taks 2.885999917984009 seconds
2020-03-24 09:20:41,126 - RBF - INFO - train epoch 23 of total 5000 epoches
2020-03-24 09:20:44,021 - RBF - ERROR - loss 0.0033273790794269456, in epoch 23, in step 199, in global step 11700, learning rate is 8e-05, taks 4.329000234603882 seconds
2020-03-24 09:20:46,891 - RBF - ERROR - loss 0.003071627399316025, in epoch 23, in step 399, in global step 11900, learning rate is 8e-05, taks 2.869999885559082 seconds
2020-03-24 09:20:48,362 - RBF - INFO - train epoch 24 of total 5000 epoches
2020-03-24 09:20:51,240 - RBF - ERROR - loss 0.0027238546723660695, in epoch 24, in step 199, in global step 12200, learning rate is 8e-05, taks 4.348999738693237 seconds
2020-03-24 09:20:54,152 - RBF - ERROR - loss 0.002515204593439243, in epoch 24, in step 399, in global step 12400, learning rate is 8e-05, taks 2.9109997749328613 seconds
2020-03-24 09:20:55,595 - RBF - INFO - train epoch 25 of total 5000 epoches
2020-03-24 09:20:58,489 - RBF - ERROR - loss 0.0022373163365432356, in epoch 25, in step 199, in global step 12700, learning rate is 8e-05, taks 4.335999965667725 seconds
2020-03-24 09:21:01,397 - RBF - ERROR - loss 0.0020737523581116097, in epoch 25, in step 399, in global step 12900, learning rate is 8e-05, taks 2.9070000648498535 seconds
2020-03-24 09:21:02,835 - RBF - INFO - train epoch 26 of total 5000 epoches
2020-03-24 09:21:05,726 - RBF - ERROR - loss 0.0018553028160726147, in epoch 26, in step 199, in global step 13200, learning rate is 8e-05, taks 4.328000068664551 seconds
2020-03-24 09:21:08,618 - RBF - ERROR - loss 0.001724570196288024, in epoch 26, in step 399, in global step 13400, learning rate is 8e-05, taks 2.8910000324249268 seconds
2020-03-24 09:21:10,061 - RBF - INFO - train epoch 27 of total 5000 epoches
2020-03-24 09:21:12,938 - RBF - ERROR - loss 0.0015463746453197133, in epoch 27, in step 199, in global step 13700, learning rate is 8e-05, taks 4.319999933242798 seconds
2020-03-24 09:21:15,821 - RBF - ERROR - loss 0.001438431259090834, in epoch 27, in step 399, in global step 13900, learning rate is 8e-05, taks 2.883000135421753 seconds
2020-03-24 09:21:17,252 - RBF - INFO - train epoch 28 of total 5000 epoches
2020-03-24 09:21:20,134 - RBF - ERROR - loss 0.001295673542346368, in epoch 28, in step 199, in global step 14200, learning rate is 8e-05, taks 4.312999963760376 seconds
2020-03-24 09:21:23,126 - RBF - ERROR - loss 0.0012134557712287497, in epoch 28, in step 399, in global step 14400, learning rate is 8e-05, taks 2.990999937057495 seconds
2020-03-24 09:21:24,553 - RBF - INFO - train epoch 29 of total 5000 epoches
2020-03-24 09:21:27,175 - RBF - ERROR - loss 0.001104803497543965, in epoch 29, in step 199, in global step 14700, learning rate is 8e-05, taks 4.049000024795532 seconds
2020-03-24 09:21:29,791 - RBF - ERROR - loss 0.001036930378791392, in epoch 29, in step 399, in global step 14900, learning rate is 8e-05, taks 2.615000009536743 seconds
2020-03-24 09:21:31,122 - RBF - INFO - train epoch 30 of total 5000 epoches
2020-03-24 09:21:33,763 - RBF - ERROR - loss 0.0009383472904187903, in epoch 30, in step 199, in global step 15200, learning rate is 8e-05, taks 3.9720001220703125 seconds
2020-03-24 09:21:36,386 - RBF - ERROR - loss 0.0008743681838631367, in epoch 30, in step 399, in global step 15400, learning rate is 8e-05, taks 2.622999906539917 seconds
2020-03-24 09:21:37,712 - RBF - INFO - train epoch 31 of total 5000 epoches
2020-03-24 09:21:40,345 - RBF - ERROR - loss 0.0007816148978973637, in epoch 31, in step 199, in global step 15700, learning rate is 8e-05, taks 3.9590001106262207 seconds
2020-03-24 09:21:42,968 - RBF - ERROR - loss 0.0007215268761317763, in epoch 31, in step 399, in global step 15900, learning rate is 8e-05, taks 2.622999906539917 seconds
2020-03-24 09:21:44,290 - RBF - INFO - train epoch 32 of total 5000 epoches
2020-03-24 09:21:46,921 - RBF - ERROR - loss 0.0006312913476762424, in epoch 32, in step 199, in global step 16200, learning rate is 8e-05, taks 3.9519999027252197 seconds
2020-03-24 09:21:49,550 - RBF - ERROR - loss 0.0005665648191142136, in epoch 32, in step 399, in global step 16400, learning rate is 8e-05, taks 2.628999948501587 seconds
2020-03-24 09:21:50,888 - RBF - INFO - train epoch 33 of total 5000 epoches
2020-03-24 09:21:53,160 - RBF - ERROR - loss 0.00047132108378365495, in epoch 33, in step 199, in global step 16700, learning rate is 8e-05, taks 3.609999895095825 seconds
2020-03-24 09:21:55,427 - RBF - ERROR - loss 0.0004165563652499422, in epoch 33, in step 399, in global step 16900, learning rate is 8e-05, taks 2.267000198364258 seconds
2020-03-24 09:21:56,550 - RBF - INFO - train epoch 34 of total 5000 epoches
2020-03-24 09:21:58,804 - RBF - ERROR - loss 0.0003415274777654335, in epoch 34, in step 199, in global step 17200, learning rate is 8e-05, taks 3.376999855041504 seconds
2020-03-24 09:22:01,056 - RBF - ERROR - loss 0.00029482199580356473, in epoch 34, in step 399, in global step 17400, learning rate is 8e-05, taks 2.252000093460083 seconds
2020-03-24 09:22:02,186 - RBF - INFO - train epoch 35 of total 5000 epoches
2020-03-24 09:22:04,452 - RBF - ERROR - loss 0.00023150056064793147, in epoch 35, in step 199, in global step 17700, learning rate is 8e-05, taks 3.3949997425079346 seconds
2020-03-24 09:22:06,713 - RBF - ERROR - loss 0.00019431167013181524, in epoch 35, in step 399, in global step 17900, learning rate is 8e-05, taks 2.259999990463257 seconds
2020-03-24 09:22:07,838 - RBF - INFO - train epoch 36 of total 5000 epoches
2020-03-24 09:22:10,089 - RBF - ERROR - loss 0.00014694581500512857, in epoch 36, in step 199, in global step 18200, learning rate is 8e-05, taks 3.375999927520752 seconds
2020-03-24 09:22:12,340 - RBF - ERROR - loss 0.00012091685887863938, in epoch 36, in step 399, in global step 18400, learning rate is 8e-05, taks 2.250999927520752 seconds
2020-03-24 09:22:13,467 - RBF - INFO - train epoch 37 of total 5000 epoches
2020-03-24 09:22:15,711 - RBF - ERROR - loss 8.998122064194938e-05, in epoch 37, in step 199, in global step 18700, learning rate is 8e-05, taks 3.371000051498413 seconds
2020-03-24 09:22:17,969 - RBF - ERROR - loss 7.422912453661795e-05, in epoch 37, in step 399, in global step 18900, learning rate is 8e-05, taks 2.258000135421753 seconds
2020-03-24 09:22:19,096 - RBF - INFO - train epoch 38 of total 5000 epoches
2020-03-24 09:22:21,349 - RBF - ERROR - loss 5.626334076604268e-05, in epoch 38, in step 199, in global step 19200, learning rate is 8e-05, taks 3.379999876022339 seconds
2020-03-24 09:22:23,607 - RBF - ERROR - loss 4.745806161766144e-05, in epoch 38, in step 399, in global step 19400, learning rate is 8e-05, taks 2.257999897003174 seconds
2020-03-24 09:22:24,734 - RBF - INFO - train epoch 39 of total 5000 epoches
2020-03-24 09:22:26,983 - RBF - ERROR - loss 3.761654747744437e-05, in epoch 39, in step 199, in global step 19700, learning rate is 8e-05, taks 3.376000165939331 seconds
2020-03-24 09:22:29,240 - RBF - ERROR - loss 3.277689221514969e-05, in epoch 39, in step 399, in global step 19900, learning rate is 8e-05, taks 2.255999803543091 seconds
2020-03-24 09:22:36,290 - RBF - INFO - Model saved in path: ckpt_RBF in epoch 39. learning_rate is 8e-05, loss is 3.068291241180153e-05
2020-03-24 09:22:36,291 - RBF - INFO - train epoch 40 of total 5000 epoches
